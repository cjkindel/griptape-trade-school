{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"How we teach","text":""},{"location":"#projects","title":"Projects","text":"<p>We believe that the best learning experience is by creating with a clear goal. All our courses are project-based, meaning you're applying concepts in real-world scenarios, enhancing your understanding. </p>"},{"location":"#code-snippets","title":"Code Snippets","text":"<p>How can you learn coding without helpfuls snippets? We use actual code, with actual line numbers, highliting changes as you work your way through the class.</p> <pre><code># Run an agent\nagent.run(\"Teach me Griptape!\")\n</code></pre>"},{"location":"#text-video-whatever","title":"Text, Video, Whatever","text":"<p>Some concepts are taught best through text. Others through video. And still others require both.</p> <p>We're happy to provide all of it!</p>"},{"location":"#how-can-we-help","title":"How can we help?","text":"<p>We love any and all feedback!</p> <p>Do you have a new idea for a course? Drop us a line in our Discord, or log a request at Griptape Trade School Github!</p>"},{"location":"contributing/","title":"Contributions or Issues","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>We greatly appreciate contributions and help creating and maintaining courses and tutorials.</p>"},{"location":"contributing/#reports-and-issues","title":"Reports and Issues","text":"<p>The easiest way to contribute to these tutorials is through our public issue tracker. </p> <p>Feel free to submit bugs, request specific courses, or chat with us directly on Discord.</p>"},{"location":"courses/","title":"All Courses","text":""},{"location":"courses/#create-a-chatbot-using-griptape-rulesets","title":"Create a Chatbot using Griptape Rulesets","text":"<p>Take a deep dive into creating a conversational chatbot with an Agent using Griptape's Rulesets. Not only will our chatbot be able to engage in conversation, but it will also have the unique ability to embody different personalities.</p> <p> Take the course</p>"},{"location":"courses/#compare-movies-using-griptape-workflows","title":"Compare Movies using Griptape Workflows","text":"<p>Learn how to work with Griptape Workflow Structures to create flexible and powerful hierarchies of tasks. This course demonstrates these concepts by comparing movies, utilizing PromptTasks and ToolkitTasks to analyze text and search the web.</p> <p> Take the course</p>"},{"location":"courses/#image-generation-with-griptape-pipelines","title":"Image Generation with Griptape Pipelines","text":"<p>Explore Griptape Pipelines through the practical example of image generation. In this course, you'll learn how to seamlessly link together various tasks to create a consistent and repeatable pipeline.</p> <p> Take the course</p>"},{"location":"courses/#griptape-and-shotgrid-a-practical-approach-to-tool-integration","title":"Griptape and ShotGrid: A Practical Approach to Tool Integration","text":"<p>Discover the power of Griptape Tools in our dynamic course, where you'll learn to construct your own specialized ShotGrid Client. Through hands-on sessions, you'll transform chatbot commands into automated, practical tasks. Equip yourself with the skill to create and customize tools that enhance Language Learning Models' interaction with real-world data and APIs.</p> <p> Take the course</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>What is griptape-tools?</p> <p>Sometimes the videos will mention or demonstrate the instalation of <code>griptape-tools</code>. </p> <p>For example:</p> <pre><code>pip install griptape griptape-tools\n</code></pre> <p><code>griptape-tools</code> is no longer required. It was from an older version of Griptape where the tools were in a separate library. They are incorporated into the main Griptape repo now, so you don't need to install it separately.</p> <p>So if you see it, just use:</p> <pre><code>pip install griptape\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page will offer solutions to problems that people have run into. If the solution to your problem isn't here, please feel free to submit a bug, or chat with us on Discord.</p>"},{"location":"troubleshooting/#no-module-named-griptapecore","title":"No module named griptape.core","text":"<p>If you are seeing certain errors relating to Griptape modules not being available, it may be an issue with your Griptape installation. </p> <p></p> <p>To resolve this, try the following steps:</p> <ol> <li>Open a Terminal in your editor.</li> <li>Using <code>pip</code>, uninstall Griptape.     <pre><code>pip uninstall griptape -y\n</code></pre></li> <li>Reinstall Griptape.     <pre><code>pip install griptape -y\n</code></pre></li> </ol> <p>This should clean up any install issues and allow you to use Griptape with the latest version.</p>"},{"location":"courses/chatbot-rulesets/","title":"Building a Conversational Chatbot with Personality Using Griptape's Rulesets","text":"<p>Tip</p> <p>In the above video I demonstrate importing <code>griptape-tools</code>. This is no longer required. The correct command is simply:</p> <p><code>pip install griptape</code></p>"},{"location":"courses/chatbot-rulesets/#course-description","title":"Course Description","text":"<p>In this course, we will take a deep dive into creating a command-line interface (CLI) based conversational chatbot with an Agent using Griptape's Rulesets. Not only will our chatbot be able to engage in conversation, but it will also have the unique ability to embody different personalities, making the interaction more dynamic and interesting. </p> <p>You will get hands-on experience working with Griptape, understanding and implementing Rulesets, and using Agents to bring your chatbot to life. This course serves as an excellent introduction to these concepts and technologies.</p>"},{"location":"courses/chatbot-rulesets/#who-is-this-course-for","title":"Who is this course for?","text":"<p>This course is aimed at beginners to intermediate level Python developers who are interested in learning more about Griptape.</p>"},{"location":"courses/chatbot-rulesets/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this course, you will need:</p> <ul> <li>An OpenAI API Key (available here: https://beta.openai.com/account/api-keys){target=\"_blank\"}</li> <li>Python3.9+ installed on your machine</li> <li>An IDE (such as Visual Studio Code or PyCharm) to write and manage your code</li> </ul> <p>If you don't have those items available, it's highly recommended you go through the Griptape Setup - Visual Studio Code course to set up your environment.</p>"},{"location":"courses/chatbot-rulesets/#course-outline","title":"Course Outline","text":"<p>The course is designed to progressively build your understanding and skillset. We'll start with setting up your environment, then introduce you to the basics of Agents and Rulesets. We'll add more advanced features as the course progresses, including:</p> <ul> <li>Making your chatbot interactive</li> <li>Giving your chatbot a personality</li> <li>Enhancing chat aesthetics</li> <li>Enabling your chatbot to switch between multiple personas</li> <li>And more!</li> </ul> <p>By the end of this course, you'll have a versatile chatbot that can carry on engaging conversations with varying personas, right from your command line.</p>"},{"location":"courses/chatbot-rulesets/#useful-resources","title":"Useful Resources","text":"<p>These resources will provide additional information and context throughout the course:</p> <ul> <li>Griptape Documentation</li> <li>Python-dotenv Package</li> <li>Rich Library</li> <li>Visual Studio Code</li> <li>Python Environment Manager</li> </ul>"},{"location":"courses/chatbot-rulesets/#next-steps","title":"Next Steps","text":"<p>Head on to the first stage 01 - Setting Up Your Environment to get started!</p>"},{"location":"courses/chatbot-rulesets/01_setting_up_environment/","title":"Setup","text":"<p>Welcome to the first step of our journey into creating a conversational chatbot! In this section, we will be focusing on setting up our work environment, which is the first step to any coding project. </p>"},{"location":"courses/chatbot-rulesets/01_setting_up_environment/#prerequisites","title":"Prerequisites","text":"<p>Important</p> <p>Since this is an intermediate level course, please ensure you've gone through the Griptape Setup - Visual Studio Code course to set up your environment. We will be starting from the code at that point.</p> <ol> <li> <p>Code Editor: We recommend using Visual Studio Code for this course, due to its handy features and Python support. However, if you have another favorite IDE or text editor, feel free to use that! </p> </li> <li> <p>Python3.9+: Griptape requires Python 3.9+.</p> </li> <li> <p>Python Environment Manager (for VS Code users): This extension is not a hard requirement, but it does make managing your Python environments a lot easier. </p> </li> <li> <p>OpenAI API Key: Our chatbot will be powered by gpt-4, which requires an API key from OpenAI. You can get your key from OpenAI's website.</p> </li> </ol> <p>Got everything installed? Awesome! Now, let's get started setting up our project.</p>"},{"location":"courses/chatbot-rulesets/01_setting_up_environment/#create-a-project","title":"Create a Project","text":"<p>Following the instructions in Griptape Setup - Visual Studio Code  please:</p> <ol> <li>Create your project folder. Example: <code>griptape-chatbot-with-rulesets-cli</code></li> <li>Set up your virtual environment</li> <li>Ensure you <code>pip install griptape python-dotenv</code></li> <li>Create a <code>.env</code> file with your <code>OPENAI_API_KEY</code></li> <li>Create your <code>app.py</code> file with the following code:</li> </ol> <pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nload_dotenv() # Load your environment\n# Create an agent\nagent = Agent()\n# Run the agent\nagent.run(\"I'm ready to chat.\")\n</code></pre> <p>And there we have it, our coding environment is all set up! In the next section The Chat Utility, we'll look at one of the quickest ways of creating a Chatbot with Griptape.</p>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/","title":"The Chat Utility","text":""},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#make-agent-interactive-using-chat-utility","title":"Make Agent Interactive Using Chat Utility","text":"<p>Now that we have our agent up and running, it's time to make it truly interactive and engaging. We'll introduce the Chat utility from Griptape, which is a quick way to have dynamic conversations with our chatbot. Get ready to dive into the world of witty banter and Python-powered humor!</p>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#goal","title":"Goal","text":"<p>After completing this section, you'll be able to have lively and interactive conversations with your chatbot using the Chat utility.</p>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#chat-utility","title":"Chat Utility","text":""},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#import","title":"Import","text":"<p>To get started, we need to import the magical <code>Chat</code> utility from Griptape. This utility will be our ticket to engaging conversations with our chatbot. In your code, add the following import statement:</p> app.py<pre><code># ... previous code\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\n# ...\n</code></pre> <p>With the Chat utility at our disposal, we're armed with the power to unleash our chatbot's conversational prowess.</p>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#call-it","title":"Call It","text":"<p>It's time to unleash our chatbot's conversational skills and start the interactive chat session. Replace the previous <code>agent.run()</code> line with the following code:</p> <pre><code># ...\n# Begin Chatting\nChat(agent).start()\n</code></pre> <p>This simple line of code will open up a world of possibilities, allowing you to converse with your chatbot as if it were your witty Python companion.</p>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#current-code","title":"Current Code","text":"<p>Here is the full code: </p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat #   &lt;-- Added Chat\n# Load environment variables\nload_dotenv()\n# Create the agent\nagent = Agent()\n# Begin Chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#try-it","title":"Try it","text":"<p>It's time to play around with your chatbot. Ask it some questions, have a laugh, etc. Here's a quick example of a not-very-funny joke with the chatbot:</p> <pre><code>Q: Hello!\nprocessing...\n[07/20/23 06:37:45] INFO     Task 167f55dda2be46a7bc9002a48214dbf4                                                                                                                   \n                             Input: Hello!                                                                                                                                           \n[07/20/23 06:37:46] INFO     Task 167f55dda2be46a7bc9002a48214dbf4                                                                                                                   \n                             Output: Hello! How can I assist you today?                                                                                                              \nA: Hello! How can I assist you today?\nQ: Tell me a joke about python\nprocessing...\n[07/20/23 06:37:58] INFO     Task 167f55dda2be46a7bc9002a48214dbf4                                                                                                                   \n                             Input: Tell me a joke about python                                                                                                                      \n[07/20/23 06:38:00] INFO     Task 167f55dda2be46a7bc9002a48214dbf4                                                                                                                   \n                             Output: Why did the python programmer get bitten by a snake? Because they forgot to use a python exception handler!                                     \nA: Why did the python programmer get bitten by a snake? Because they forgot to use a python exception handler!\n</code></pre>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#exiting","title":"Exiting","text":"<p>Conversations must come to an end, even with the most entertaining chatbot. We want to gracefully exit the chat session when we're ready to bid our virtual friend farewell. To exit the chat, simply type <code>exit</code> as your input. The Chat utility will catch this magic word and gracefully end the conversation.</p> <p>So go ahead, chat away, exchange jokes, discuss Python's quirks, and when it's time to say goodbye, just type <code>exit</code> and gracefully conclude your interaction.</p> <pre><code>Q: exit\nexiting...\n</code></pre>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#code-review","title":"Code Review","text":"<p>Take a minute to check your code against the current version.</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat #   &lt;-- Added Chat\n# Load environment variables\nload_dotenv()\n# Create the agent\nagent = Agent()\n# Begin Chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/chatbot-rulesets/03_the_chat_utility/#next-steps","title":"Next Steps","text":"<p>In the next section: Hide The Logs, we'll hide those pesky but oh-so-helpful logs by using the <code>logging</code> library. This will make our chatbot much easier to understand and work with.</p>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/","title":"Hiding the Logs","text":"<p>In the previous section, we had a blast engaging with our chatbot, but there was one tiny detail that interrupted the flow of our conversations - those verbose logs cluttering our output. Fear not!  In this section, we'll show you how to turn off the logs and let your chatbot's brilliance shine without unnecessary distractions.</p>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#goal","title":"Goal","text":"<p>After completing this section, you'll be able to enjoy clean and clutter-free conversations with your chatbot by disabling the logs.</p>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#logging-utility","title":"Logging Utility","text":""},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#import","title":"Import","text":"<p>We'll begin by importing the logging library, which will give us the power to control the verbosity of our chatbot's output. Add the following import statement to your code:</p> <pre><code>import logging\n</code></pre> <p>Now we're ready to silence those logs and enjoy the tranquility of clean output.</p>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#add-to-agent","title":"Add to Agent","text":"<p>It's time to modify our agent to quiet those logs and allow our chatbot's brilliance to shine through. Adjust the code where the agent is created, like so:</p> <pre><code># Create the agent\nagent = Agent(\nlogger_level=logging.ERROR\n)\n</code></pre> <p>By specifying <code>logger_level=logging.ERROR</code>, we indicate that we only want to receive logs of the highest priority, suppressing the informational logs and leaving us with a cleaner output.</p> <p>Here is the code with the new lines highlighted:</p> <pre><code>from dotenv import load_dotenv\nimport logging                     \n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\n# Load environment variables\nload_dotenv()\n# Create the agent\nagent = Agent(\nlogger_level=logging.ERROR      \n)\n# Run the agent\nChat(agent).start()\n</code></pre>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#give-it-a-try","title":"Give it a try","text":"<p>Go ahead and execute the script and have a chat.</p> <pre><code>Q: Give me a haiku about python skateboarders\nprocessing...\nA: Python skateboarders\nGlide on wheels, swift and free\nThrilling tricks they show\nQ: \n</code></pre> <p>Success</p> <p>Ahh, isn't it refreshing? Now our conversations will flow seamlessly, without any distracting logs cluttering our chatbot's responses.</p>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#code-review","title":"Code Review","text":"<p>We've made valuable progress in this stage. Before proceeding, let's verify your code.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging                     \n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\n# Load environment variables\nload_dotenv()\n# Create the agent\nagent = Agent(\nlogger_level=logging.ERROR      \n)\n# Run the agent\nChat(agent).start()\n</code></pre>"},{"location":"courses/chatbot-rulesets/04_hide_the_logs/#next-steps","title":"Next Steps","text":"<p>In the next section: Personality With Rulesets, we'll unlock the true potential of your chatbot by giving it a vibrant personality with the help of Rulesets. Prepare to witness your chatbot's transformation as it takes on unique traits, behaviors, and even multiple personas. </p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/","title":"Personality","text":"<p>In our quest to create an extraordinary chatbot, we've arrived at a crucial moment: giving our agent a vibrant personality! With Griptape's Rules and Rulesets, we can define a set of rules that shape our chatbot's behavior, transforming it into a unique and charming character.</p> <p>Because I live in New Zealand, I've decided to give the chatbot a bit of a Kiwi personality - feel free to use whatever persona makes you happy.</p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#goal","title":"Goal","text":"<p>After completing this section, you'll be able to infuse your chatbot with a delightful Kiwi (or other) personality using Griptape's Rules and Rulesets.</p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#rules-and-rulesets","title":"Rules and Rulesets","text":""},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#importing","title":"Importing","text":"<p>To give your agent access to the <code>Rule</code> and <code>Ruleset</code> classes, we need to adjust our script to import them.</p> <p>Add the following line to the top of your script:</p> <pre><code>from griptape.rules import Rule, Ruleset\n</code></pre>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#rules","title":"Rules","text":"<p>Rules are the building blocks of our chatbot's personality. They allow us to define specific behaviors and traits. Each rule is typically focused on one important statement or characteristic. For example, we can create rules like:</p> <pre><code>Rule(\"You are an incredibly helpful kiwi tour guide.\")\nRule(\"You often forget where you kept your keys.\")\nRule(\"You speak in riddles, but not very clever ones.\")\n</code></pre> <p>The specific rules are really up to you, and you will most likely find yourself iterating on your rules in order to achieve the perfect output. </p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#rulesets","title":"Rulesets","text":"<p>Once we have defined our rules, we can group them together into a <code>Ruleset</code>. A Ruleset allows us to combine related rules, creating a cohesive set of behaviors for our chatbot. In our case, we'll create a ruleset called \"kiwi\" for our kiwi-inspired friend.</p> <pre><code># Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname=\"kiwi\",\nrules=[\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\n</code></pre> <p>Here, we use the Ruleset class from the griptape.rules module. </p> <p>This class allows us to create a ruleset by specifying a <code>name</code> for the ruleset and a list of <code>rules</code> that define the desired behavior. In our case, the ruleset is named \"kiwi\" and contains two rules: one indicating the chatbot's New Zealander identity and another highlighting its strong kiwi accent.</p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#add-to-the-agent","title":"Add to the Agent","text":"<p>With our rules and ruleset in place, it's time to create our kiwi chatbot! We'll assign the kiwi ruleset to the agent and let the magic unfold.</p> <p>We will update our instantiation of the Agent class and pass the kiwi_ruleset as a parameter to the rulesets argument. This associates the kiwi ruleset with our chatbot, infusing it with the desired kiwi personality traits. </p> <p>Info</p> <p>The Agent can handle multiple rulesets, which is why it's specified as a list. </p> <p>We'll demonstrate this in a later lesson.</p> <pre><code># Create the agent\nagent = Agent(\nrulesets=[kiwi_ruleset],  \nlogger_level=logging.ERROR\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#try-it","title":"Try it","text":"<p>Let's go ahead and chat with our chatbot. <pre><code>Q: Can you give me some kiwi slang?\nprocessing...\n\nA: Sure as, mate! Here are a few kiwi slang words and phrases for ya:\n1. Chur - It means thanks or cheers.\n2. Sweet as - It means something is good or all good.\n3. Jandals - It's what we call flip-flops.\n4. Dairy - It's a convenience store or a corner shop.\n5. Bach - It's a holiday home or a beach house.\n6. Chocka - It means something is full or crowded.\n7. Tiki tour - It means taking a scenic route or a detour.\n8. She'll be right - It means everything will be okay or no worries.\nHope that helps, bro!\n\nQ: I've heard people say \"yeah, nah\" - what does that mean?\nprocessing...\nA: Yeah, nah, that's a classic kiwi phrase! It's a way of expressing hesitation or disagreement. When someone says \"yeah, nah,\" it usually means they understand what you're saying, but they don't fully agree or they're not entirely convinced. It's a bit hard to explain, but you'll catch on to it when you're in New Zealand. It's just one of those quirky kiwi expressions!\n</code></pre></p> <p>Success</p> <p>Congratulations! You now have an extremely interesting chatbot!</p>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#code-review","title":"Code Review","text":"<p>We've delved into a key concept in this stage, and it's time to validate your understanding. Compare your code with the latest version.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\n# Create the agent\nagent = Agent(\nrulesets=[\nkiwi_ruleset\n],\nlogger_level=logging.ERROR\n)\n# Run the agent\nChat(agent).start()\n</code></pre>"},{"location":"courses/chatbot-rulesets/05_personality_with_rulesets/#next-steps","title":"Next Steps","text":"<p>In the next section: Custom Chat, we'll explore how to take charge of the way your chatbot behaves, by creating a custom chat function. </p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/","title":"Custom Chat","text":"<p>Tip</p> <p>There are some changes worth noting since the recording of this video.</p> <ol> <li> <p>The <code>Chat</code> utility has added a few new options. You can now provide <code>prompt_prefix</code>, <code>response_prefix</code>, <code>exit_keywords</code> and more.</p> <p>Review the <code>Chat Utility</code> reference guide for a full breakdown.</p> </li> <li> <p>Agent Output has changed from: </p> <p><code>agent_result.output_task.output.value</code> to <code>agent_result.output_task.output.value</code>.</p> <p>This change is reflected in the code in the course, but not in the video at this time.</p> </li> </ol> <p>While the chatbot is working, it's not very user-friendly yet. The <code>Q:</code> and <code>A:</code> prompts don't make for the most engaging for a user experience.</p> <p>In this step, we'll implement a manual chat experience, giving us more control over the conversation with our chatbot. We'll remove the Chat utility and create our own custom functions to facilitate interactive and dynamic conversations.</p> <p>Let's get started!</p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#remove-the-chat-utility","title":"Remove the Chat Utility","text":"<p>To implement our custom manual chat functionality, we'll remove the dependency on the Chat utility provided by Griptape. We'll no longer need the line <code>from griptape.utils import Chat</code> in our code.</p> <p>Update the code by commenting out or removing the following line:</p> <pre><code># from griptape.utils import Chat\n</code></pre> <p>Don't forget to remove or comment out the line where we use the Chat utility with the agent at the bottom of the script:</p> <pre><code># Run the agent\n# Chat(agent).start()\n</code></pre> <p>With the Chat utility out of the picture, we're ready to take charge and create our own chat function.</p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#create-our-chat","title":"Create our Chat","text":""},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#the-loop","title":"The Loop","text":"<p>Now that the old Chat function has been removed, we'll need to replace it with our own code. Let's start by with a simple loop that takes the user input until they type <code>exit</code>.</p> <pre><code># Keep track of when we're chatting\nis_chatting = True\nwhile is_chatting: # While chatting is still true\nuser_input = input(\"Chat with kiwi: \")\nif user_input == \"exit\":\nis_chatting = False\nelse:\nprint(f\"Kiwi: Hah! you said: {user_input}!\")\n</code></pre> <p>If you just run this code on it's own, you'll see that it allows the user to keep entering information over and over again until they type exit.</p> <p>It's not very amazing, and certainly doesn't interact with the agent yet, so let's modify the code to handle that.</p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#add-the-agent","title":"Add the Agent","text":"<p>After the <code>else:</code> statement, change the code to call <code>agent.run()</code>:</p> <pre><code>while is_chatting:\n# ... truncated for brevity ... #\nelse:\nagent_result = agent.run(user_input)\nprint (f\"Kiwi: {agent_result.output_task.output.value}\")\n</code></pre> <p>As you can see now, the agent runs, and we get the output stored in the variable agent_result. We can then print that output by using the <code>output.value</code> attribute.</p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#chat-function","title":"Chat Function","text":""},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#create","title":"Create","text":"<p>Let's clean this up a bit and define a custom <code>chat</code> function that will hold all this code instead of placing it at the end of our script.</p> <p>Here's the code for the <code>chat</code> function and the way we can call it:</p> <pre><code># Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_result = input(\"Chat with Kiwi: \")\nif user_result == \"exit\":\nis_chatting = False\nelse:           \n# Keep on chatting\nagent_result = agent.run(user_input)\nprint (f\"Kiwi: {agent_result.output_task.output.value}\")\n</code></pre>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#call","title":"Call","text":"<p>Once the chat function has been created, we can just call it and pass the agent. <pre><code># Run the agent\nchat(agent)\n</code></pre></p> <p>The <code>chat</code> function takes the <code>agent</code> as an argument.</p> <p>You shouldn't notice any difference to how you ran this before, it's just a bit cleaner.</p> <p>Engage in stimulating conversations, explore various topics, and enjoy the interactive experience as you communicate with your chatbot.</p>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#code-checkpoint","title":"Code Checkpoint","text":"<p>We made a lot of important changes in this stage. Before we move forward, let's compare code. Changed lines are highlighted.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\n# Create the agent\nagent = Agent(\nrulesets=[\nkiwi_ruleset,\n],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nif user_input == \"exit\":\nis_chatting = False\nelse:\n# Keep on chatting\nagent_result = agent.run(user_input)\nprint (f\"Kiwi: {agent_result.output_task.output.value}\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/06_adding_manual_chat/#next-steps","title":"Next Steps","text":"<p>Congratulations on implementing manual chat functionality and taking control of the conversation! In the next section Manners Maketh the Bot, we'll give the bot some manners and create our own Agent class to make working with the agent more consistent.</p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/","title":"Manners Maketh the Bot","text":"<p>Tip</p> <p>There is a change worth noting since the recording of this video.</p> <p>Agent Output has changed from: </p> <p><code>agent_response.output_task.output.value</code> to <code>agent_response.output_task.output.value</code>.</p> <p>This change is reflected in the code in the course, but not in the video at this time.</p> <p>This course covers two topics:</p> <ul> <li>Adding manners</li> <li>Making agent interaction more consistent by creating a <code>respond</code> method</li> </ul> <p>We'll start with manners, as that will clearly demonstrate our need to find a way to make our interaction with our agent more consistent.</p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#manners","title":"Manners","text":""},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#chatbot-can-you-hear-me","title":"Chatbot can you hear me?","text":"<p>It's always awkward to walk into the middle of a conversation and not have someone acknowledge your presence. Let's modify the code to have the chatbot introduce itself before you begin talking.</p> <p>Add a call to the agent to introduce itself before the <code># Run the agent</code> line:</p> <pre><code># Introduce the agent\nagent_response = agent.run(\"Introduce yourself to the user.\")\nprint(f\"Kiwi: {agent_response.output_task.output.value}\")\n# Run the agent\nchat(agent)\n</code></pre> <p>Now feel free to run the chat a few times. </p> <pre><code>Kiwi: Kia ora! G'day mate! I'm a conversational bot from Aotearoa, also known as New Zealand. How can I help you today?\n\nChat with the kiwi: Can I have a funny haiku about gumboots?\n\nKiwi:  Sure as, bro! Here's a funny haiku about gumboots:\nGumboots on my feet,\nSquishy mud, they can't be beat,\nKiwi fashion feat!\n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#repeating-ourselves","title":"Repeating ourselves","text":"<p>Just like it's not polite to ignore someone when they walk into a conversation, it's not great to repeat yourself over and over.</p> <p>Notice we're doing exactly that at the moment. </p> <pre><code># ...\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nif user_input == \"exit\":\nis_chatting = False\nelse:\n# Keep on chatting\nagent_result = agent.run(user_input)\nprint (f\"Kiwi: {agent_result.output_task.output.value}\")\n# Introduce the agent\nagent_response = agent.run(\"Introduce yourself to the user.\")\nprint(f\"Kiwi: {agent_response.output_task.output.value}\")\n# Run the agent\nchat(agent)\n</code></pre> <p>This is not a great programming practice because it means any changes we want to make to the output of our chat will have to be done in multiple places. It make maintaining the code way more difficult, and it doesn't adhere to the DRY principle (Don't Repeat Yourself).</p> <p>There are a number of ways we could approach this, including:</p> <ul> <li>Create a <code>respond</code> function</li> <li>Subclass the Agent and create a <code>respond</code> method.</li> </ul> <p>Both are valid solutions and it's worth looking at what it would feel like to work with each of them to see what feels best.</p> FunctionMethod <pre><code># Send a command to the agent\nagent.run(\"Can I have a haiku?\")\n# Run a command and print the result to the user\nrespond(agent, \"Can I have a haiku?\")\n</code></pre> <pre><code># Send a command to the agent\nagent.run(\"Can I have a haiku?\")\n# Run a command and print the result to the user\nagent.respond(\"Can I have a haiku?\")\n</code></pre> <p>Taking a look at both options, I think in the end it feels more consistent to use a method instead of a function due to the consistent feel of working with the agent: <code>agent.run()</code> and <code>agent.respond()</code>.</p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#adding-the-method","title":"Adding the Method","text":""},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#subclass-the-agent","title":"Subclass the Agent","text":"<p>First, we'll need to create a subclass for the Agent. This will allow us to create additional methods for the agent, and still inherit all the wonderful things Agent gives us.</p> <p>Add the following lines before <code>agent = Agent()</code> in your code:</p> <pre><code># Create a subclass for the Agent\nclass MyAgent(Agent):\n# Create the agent\n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#the-respond-method","title":"The <code>Respond</code> Method","text":"<p>Now, add the respond method to the MyAgent class. Use the same <code>agent_response = agent.run</code>, and print the commands you used earlier. </p> <pre><code># Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\nprint(f\"Kiwi: {agent_response.output_task.output.value}\") \n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#update-agent","title":"Update Agent","text":"<p>Next, replace the line where you create the agent:</p> <pre><code>agent = Agent()\n</code></pre> <p>with</p> <pre><code>agent = MyAgent()\n</code></pre> <p>to make sure we're now calling the new agent.</p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#update-calls-to-agent-response","title":"Update calls to agent response","text":"<p>Finally, replace the lines where we were previously getting the result of the <code>agent.run()</code> function with <code>agent.respond()</code>. At the moment this will be in two locations:</p> <ul> <li>Inside the <code>chat</code> function</li> <li>When the agent introduces itself</li> </ul> <p>Replace: <pre><code>agent_result = agent.run(user_input)\nprint(f\"Kiwi: {agent_result.output_task.output.value}\")\n</code></pre></p> <p>with:</p> <pre><code>agent.respond(user_input)\n</code></pre> <p>Warning</p> <p>Don't replace those lines inside the <code>respond</code> method. Only replace them outside the method.</p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#review","title":"Review","text":"<p>Since we just made some big changes, here are those alterations brought together, with new lines highlighted.</p> <pre><code># ...\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\nprint(f\"Kiwi: {agent_response.output_task.output.value}\")\n# ... truncated for brevity\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nif user_input == \"exit\":\nis_chatting = False\nelse:\nagent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#more-manners","title":"More Manners","text":""},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#dont-leave-without-saying-goodbye","title":"Don't leave without saying Goodbye","text":"<p>Let's give the chatbot a bit more social grace and have it say goodbye when the person stops the chat. Before setting <code>is_chatting = False</code>, add the following line:</p> <p><pre><code>agent.respond(\"The user is finished chatting. Say goodbye.\")\n</code></pre> This will tell the agent that the user is leaving the chat, and then print the output to the screen. Here's that section of the code in context:</p> <p>Here's an example of how that would play out: <pre><code>Chat with kiwi: exit\nKiwi: Good on ya, mate! Take care and have a ripper day!\n</code></pre></p>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#clean-up-the-output","title":"Clean up the output","text":"<p>Finally, let's enhance the readability of the chat by adding a bit more space around the output of the chat.</p> <p>This can be done by modifying the <code>respond</code> method to add two print statements.</p> <pre><code>class MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\nprint(\"\")\nprint(f\"Kiwi: {agent_response.output_task.output.value}\")\nprint(\"\")\n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#code-checkpoint","title":"Code Checkpoint","text":"<p>We made some major updates to the code in this section. Take a look:</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\nprint(\"\")\nprint(f\"Kiwi: {agent_response.output_task.output.value}\")\nprint(\"\")\n# Create the agent\nagent = MyAgent(\nrulesets=[\nkiwi_ruleset,\n],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nif user_input == \"exit\":\nagent.respond(\"The user is finished chatting. Say goodbye.\")\nis_chatting = False\nelse:\nagent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/07_manners_maketh_the_bot/#next-steps","title":"Next Steps","text":"<p>Congratulations on implementing manual chat functionality and taking control of the conversation! In the next section Adding Another Ruleset, we'll explore the world of output rulesets, unlocking the ability to control the chatbot's responses in different formats such as JSON, YAML, or even haiku.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/","title":"Rulesets for Output","text":"<p>Tip</p> <p>There is a change worth noting since the recording of this video.</p> <p>Agent Output has changed from: </p> <p><code>agent_response.output_task.output.value</code> to <code>agent_response.output_task.output.value</code>.</p> <p>This change is reflected in the code in the course, but not in the video at this time.</p> <p>Consider a situation where we have integrated the LLM (Large Language Module) into our code. It becomes crucial for us to receive the output in a specific format that aligns with our requirements, like JSON. By employing an output ruleset, we can precisely control the structure and format of the chatbot's responses.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#goal","title":"Goal","text":"<p>After completing this section, you'll be able to use output rulesets to get responses from the LLM in the way most useful for your application.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#new-ruleset","title":"New Ruleset","text":""},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#json-ruleset","title":"JSON Ruleset","text":"<p>To achieve our goal of formatting the response as JSON, we'll create a ruleset called \"json_ruleset.\" This ruleset will contain a single rule that tells the chatbot to use JSON when formulating its response. Place it after <code>kiwi_rulesest</code>:</p> <pre><code>json_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Use JSON when formulating your response.\")\n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#integration","title":"Integration","text":"<p>With <code>json_ruleset</code> in hand, it's time to integrate it into our Agent. By including it in the list of rulesets available to the Agent, we can harness its power to control the response format.</p> <pre><code># Create the agent\nagent = MyAgent(\nrulesets=[kiwi_ruleset, json_ruleset],\nlogger_level=logging.ERROR\n)\n</code></pre> <p>Here, we modify the <code>MyAgent</code> instantiation to include both <code>kiwi_ruleset</code> and <code>json_ruleset</code> in the <code>rulesets=[]</code> argument. This ensures that our chatbot possesses the kiwi personality traits while also adhering to the desired response format specified by <code>json_ruleset</code>.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#test","title":"Test","text":"<p>Prepare for an exciting conversation as we engage our chatbot in a quest for knowledge about Wellington's top tourist destinations. Let's dive in:</p> <pre><code>Q: \"Hey chatbot, what are the top three tourist destinations in Wellington? Can you give me a name and a description?\"\nKiwi: {\n\"message\": \"Absolutely, mate! Here are the top three tourist destinations in Wellington with a brief description:\",\n\"destinations\": [\n{\n\"name\": \"Te Papa Museum\",\n\"description\": \"New Zealand's national museum, known for its interactive and innovative exhibits.\"\n},\n{\n\"name\": \"Wellington Cable Car\",\n\"description\": \"An iconic Wellington attraction, offering stunning views of the city and harbour.\"\n},\n{\n\"name\": \"Zealandia Ecosanctuary\",\n\"description\": \"A unique protected natural area where you can see New Zealand's wildlife up close.\"\n}\n]\n}\n</code></pre> <p>Enjoy the beauty of Wellington's top tourist destinations, neatly presented in a JSON format, as our chatbot provides you with insightful reasons to visit each destination.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#using-it","title":"Using it","text":""},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#adding-keys","title":"Adding Keys","text":"<p>While this is an interesting example, let's use the ruleset in a way that helps control the way our application works.</p> <p>Currently, the user has to know to type \"exit\" to leave the chat. This is not a great user experience, as it's a hidden command. We are using a chat-interface... wouldn't it be great if we could simply tell the chatbot when we were done chatting and it would quit on its own?</p> <p>Turns out, we can do just that - by using the <code>json_ruleset</code>.</p> <p>Modify <code>json_ruleset</code> to look like the following:</p> <pre><code>json_ruleset = Ruleset(\nname='json_ruleset',\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that is your response to the user.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n</code></pre> <p>The first rule tells the chatbot to respond in JSON and specifies the keys. </p> <p>The second and third rules explain what the values for those keys should be. Notice the third one specifically says that if it sounds like the person is done chatting, set <code>continue_chatting</code> to <code>False</code>.</p> <p>Go ahead and run the example and notice the response.</p> <pre><code>Kiwi: {\n\"response\": \"G'day mate! I'm a bot from New Zealand, speaking with a strong kiwi accent. How can I assist you today?\",\n\"continue_chatting\": true\n}\nChat with Kiwi: see ya later\nKiwi: {\n\"response\": \"No worries, mate! Catch ya later!\",\n\"continue_chatting\": false\n}\n</code></pre> <p>See how <code>continue_chatting</code> returns false when it sounds like we're done talking?</p> <p>Let's now use this JSON output!</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#import-json","title":"Import JSON","text":"<p>First, we'll have to import the <code>json</code> library. To do that, add the following at the beginning of your script:</p> <pre><code>import json\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#load-json","title":"Load JSON","text":"<p>Next, we'll use the <code>json.loads()</code> function to take the output from the agent's response and convert it into JSON data.</p> <p>Modify the start of the <code>respond</code> method of the <code>MyAgent</code> class, to look like this:</p> <p><pre><code>    # ... truncated for brevity\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\n#...\n</code></pre> This creates two variables - <code>response</code> which will be the normal response from the chatbot, and <code>continue_chatting</code> which should be <code>True</code> or <code>False</code>.</p>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#update-print","title":"Update Print","text":"<p>Modify the print statement where we get the response from the chatbot to look like:</p> <pre><code>        print(f\"Kiwi: {response}\")\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#return-state","title":"Return State","text":"<p>And then return the <code>continue_chatting</code> at the end of the method. <pre><code>    # ...\ndef respond (self, user_input):\n# ...\nreturn continue_chatting\n#...\n</code></pre></p> <p>The whole class should look like:</p> <pre><code># Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nprint(\"\")\nprint(f\"Kiwi: {response}\")\nprint(\"\")\nreturn continue_chatting\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#simplify-chat","title":"Simplify Chat","text":"<p>Since we're returning <code>True</code> or <code>False</code> from the <code>agent.respond()</code> method, the entire <code>chat</code> function can now be simplified as: <pre><code># Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nis_chatting = agent.respond(user_input)\n</code></pre></p> <p>Give it a try and see how you can quit the chat simply by holding the conversation:</p> <pre><code>Kiwi: G'day mate! I'm a bot from New Zealand, speaking with a strong kiwi accent. How can I assist you today?\n\nChat with Kiwi: I'm good, how are you?\n\nKiwi: I'm doing great, thanks for asking! Anything else you'd like to chat about, mate?\n\nChat with Kiwi: Nah, I'm done for today.\n\nKiwi: No worries, mate! Have a good one. Don't hesitate to reach out if you need anything else.\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#code-review","title":"Code Review","text":"<p>By leveraging the power of output rulesets, we've demonstrated how you can guide your chatbot to deliver responses in any desired format. Take a moment to check your code.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Griptape Items\nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that is your response to the user.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nprint(\"\")\nprint(f\"Kiwi: {response}\")\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[kiwi_ruleset, json_ruleset],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/08_adding_another_ruleset_for_output/#next-steps","title":"Next Steps","text":"<p>In the next stage, Formatting Chat Output,   we'll make the chat interface more visually appealing and chat-like using the rich library. Get ready to add some style and flair to your conversations!</p>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/","title":"Formatting Output","text":""},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#rich-library","title":"Rich Library","text":"<p>To make the chatbot output look more chat-like, we'll use the <code>rich</code> library. This library provides advanced formatting and styling options for the console output. We'll modify the chatbot function to apply formatting to the agent's responses. </p>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#import","title":"Import","text":"<p>First, let's update the code to import the <code>rich</code> library. Include the following import statements in the import section of <code>app.py</code>.</p> <pre><code>from rich import print as rprint\nfrom rich.panel import Panel\n</code></pre> <p>The first line imports the <code>print</code> library from <code>rich</code> and assigns an alias: <code>rprint</code>. By using <code>rprint</code> as an alias, we can replace regular <code>print</code> statements in our code with <code>rprint</code> to utilize the enhanced capabilities of 'rich' for displaying formatted text.</p> <p>For example, instead of using <code>print(\"Hello, World!\")</code>, we can now use <code>rprint(\"Hello, World!\")</code> to leverage the formatting capabilities provided by <code>rich</code> when displaying the output.</p> <p>Tip</p> <p>Sometimes people will simply recommend overriding the standard print functionality by doing <code>from rich import print</code>, but that would actually replace other uses of <code>print</code> in your code. For this reason, I recommend importing it as <code>rprint</code> in order to ensure the behavior we expect. But in reality, it's totally up to you. Read the documentation for more information.</p> <p>The second line imports the Panel class from the <code>rich.panel</code> module. The Panel class represents a styled container that can be used to encapsulate and visually enhance content within a console output. It allows us to create panels with various styles, colors, and borders.</p>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#panel","title":"Panel","text":"<p>Next, we'll update our <code>respond</code> method to use the new <code>rprint</code> alias and the <code>Panel</code> class. This is a pretty simple change to start with, but you'll very quickly see how much nicer things look.</p> <p>Inside the <code>respond</code> method, replace the line that looks like:</p> <p><pre><code>print(f\"Kiwi: {response}\")\n</code></pre> with</p> <pre><code>rprint(Panel(f\"Kiwi: {response}\"))\n</code></pre> <p>As you can see, we've simply replaced <code>print</code> with <code>rprint</code>, and wrapped the string that was being submitted with <code>Panel()</code>.</p> <p>If you run this code you'll see a quick improvement. <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kiwi: Kia Ora! What can I do for you today?                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\nChat with Kiwi: \n</code></pre></p> <p>Much better, right? We're not done yet...</p>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#fitting-it-in","title":"Fitting it in","text":"<p>One of the nice things about <code>rich</code> is that it can control the width of the Panel automatically by using a <code>fit</code> function to fit the content.</p> <p>Modify the <code>Panel</code> line to include <code>.fit</code> <pre><code>rprint(Panel.fit(f\"Kiwi: {response}\"))\n</code></pre></p> <p>Try it out to see how it feels.</p> <pre><code>Chat with Kiwi: Say hello in 2 words as a kiwi\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kiwi: Kia ora, mate! \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#propper-width","title":"Propper width","text":"<p>Sometimes the response can be quite long and fill the terminal. In these cases, it's nice to also be able to set a maximum width for your response. You can do this by specifying the <code>width</code> parameter of <code>Panel.fit</code>. When <code>width</code> is specified, the resulting panel will be either the width of your content or the width you specified - whatever is smaller.</p> <p>Modify the prompt:</p> <pre><code>rprint(Panel.fit(f\"Kiwi: {response}\", width=80))\n</code></pre> <p>Now the panel will be at most 80 characters wide.</p> <pre><code>Chat with Kiwi: What's the best thing about the Wairarapa?\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kiwi: Oh, the Wairarapa, mate! It's a stunner. The best thing about it has   \u2502\n\u2502 to be the beautiful landscapes, from the rugged coastlines to the lush       \u2502\n\u2502 vineyards. It's a real treat for the eyes, I tell ya!                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#code-review","title":"Code Review","text":"<p>As you can see, this has already helped our readability a ton. Compare your code.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\n# Griptape \nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that is your response to the user.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nprint(\"\")\nrprint(Panel.fit(f\"Kiwi: {response}\", width=80))\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[kiwi_ruleset, json_ruleset],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/09_formatting_chat_output/#next-steps","title":"Next Steps","text":"<p>As a developer, you may be intersted in having your chatbot write code for you, or create some tables. In the next section: Markdown Madness, we'll take a look at the <code>Markdown</code> class in <code>rich</code>, and use it to ensure output looks as we expect.</p>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/","title":"Markdown Madness","text":"<p>In this stage, we'll enhance our chatbot's code display by harnessing the power of Markdown. With Markdown, we can beautifully format and highlight code snippets to make them more readable and visually appealing.</p>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#review","title":"Review","text":"<p>First, let's see why our current output doesn't work. Ask the chatbot to do something useful - like create a bash script that will create an alias to launch VS Code.</p> <pre><code>Chat with Kiwi: Can you create a bash script that will create an\nalias for me to launch visual studio code?\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kiwi: Kia ora! G'day mate! I can definitely help you with that. Here's a     \u2502\n\u2502 bash script that will create an alias for you to launch Visual Studio Code:  \u2502\n\u2502                                                                              \u2502\n\u2502 ```bash                                                                      \u2502\n\u2502 #!/bin/bash                                                                  \u2502\n\u2502                                                                              \u2502\n\u2502 echo \"alias code='open -a Visual\\ Studio\\ Code'\" &gt;&gt; ~/.bash_profile          \u2502\n\u2502 source ~/.bash_profile                                                       \u2502\n\u2502                                                                              \u2502\n\u2502 echo \"Alias created! You can now launch Visual Studio Code by typing 'code'  \u2502\n\u2502 in your terminal. Let me know if you need any further assistance!\"           \u2502\n\u2502 ```                                                                          \u2502\n\u2502                                                                              \u2502\n\u2502 Just copy and paste this script into a new file, save it with a `.sh`        \u2502\n\u2502 extension (e.g., `create_alias.sh`), and then run it in your terminal using  \u2502\n\u2502 `bash create_alias.sh`. Let me know if you have any questions or need        \u2502\n\u2502 further help!                                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>As you can see, the script is fine, but it doesn't look like a script. It looks like something you'd enter in a Markdown file that you'd expect to eventually be rendered as a script. We're going to make this look much nicer.</p>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#markdown","title":"Markdown","text":""},{"location":"courses/chatbot-rulesets/10_markdown_madness/#import","title":"Import","text":"<p>To get started, we need to update our imports by adding the <code>Markdown</code> class.</p> <pre><code>from rich.markdown import Markdown\n</code></pre> <p>The <code>Markdown</code> class for the <code>rich</code> library allows for rendering formatted Markdown text.</p>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#using-it","title":"Using it","text":"<p>Next, we'll modify the <code>respond</code> method to use the <code>Markdown</code> class. There are a few things we'll need to do. First, we'll take the chatbot's <code>response</code> and convert it into formatted Markdown text using the following line:</p> <pre><code>        # ...\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nformatted_response = Markdown(response)\n# ...\n</code></pre> <p>Then, we'll replace our <code>rprint</code> statement in the panel to use the <code>formatted_response</code> instead of the string we were sending earlier.</p> <pre><code>        # ...\nrprint(Panel.fit(formatted_response, width=80))\n# ...\n</code></pre> <p>Warning</p> <p>Make sure you don't do something like <code>rprint(Panel.fit(f\"Kiwi : {formatted_response}\", width=80))</code> because it will print out the object, not the data.</p> <p>Here's the new <code>respond</code> method in its entirety:</p> <pre><code># Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = self.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nformatted_response = Markdown(response)\nrprint(\"\")\nrprint(Panel.fit(formatted_response, width=80))\nrprint(\"\")\nreturn continue_chatting\n</code></pre>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#update-ruleset","title":"Update Ruleset","text":"<p>Finally, we'll change our <code>json_ruleset</code> to ensure the response works with Markdown.</p> <p>Modify the second rule in <code>json_ruleset</code> to specify that the response should be safely convertible to Markdown format.</p> <p><pre><code>        # ... previous code\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\n# ...\n</code></pre> And the result. I've added a screenshot so you can see how much better it looks.</p> <p></p> <p>To see the enhanced code display in action, run your chatbot and observe the beautifully formatted code snippets that were previously plain text. Try creating tables, CSV files, python scripts, task lists, etc. Enjoy the new level of elegance and readability brought by Markdown magic!</p>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#code-review","title":"Code Review","text":"<p>Before moving forward, make sure your code works as expected.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\n# Griptape\nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nformatted_response = Markdown(response)\nrprint(\"\")\nrprint(Panel.fit(formatted_response, width=80))\nrprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[kiwi_ruleset, json_ruleset],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = input(\"Chat with Kiwi: \")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/10_markdown_madness/#next-steps","title":"Next Steps","text":"<p>In the next section, Improving the Prompt, we'll continue making things better by improving the appearance of the prompt.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/","title":"Improving the Prompt","text":"<p>In this stage, we'll improve the chatbot experience by using colors with the <code>rich</code> library. This will allow us to distinguish the chatbot's response from our prompt.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#style-class","title":"Style Class","text":"<p>To add colors, we'll take advantage of the <code>Style</code> class from the <code>rich</code> library. This class allows you to use one of the 256 Standard Colors that are accepted in terminals, Hex values, or RGB values. It's pretty nice.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#import","title":"Import","text":"<p>To add it, update the <code>import</code> section of your code to include the <code>Style</code> class:</p> <pre><code>from rich.style import Style\n</code></pre>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#color","title":"Color","text":"<p>Let's demonstrate how this works by updating our <code>respond</code> method to add some color.</p> <p>Change the <code>rprint</code> line to include the <code>style</code> attribute:</p> <p><pre><code>class MyAgent(Agent):\ndef chatbot(agent, user_input):\n# ...\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=\"light_sea_green\"),\n))\n# ...\n</code></pre> Let's see how it looks:</p> <p></p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#prompt-class","title":"Prompt Class","text":"<p>We can also take advantage of the <code>Prompt</code> class in the <code>rich</code> library to make our prompt more readable by separating the color of the prompt from the text the user enters.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#import_1","title":"Import","text":"<p>First, import the <code>Prompt</code> class:</p> <pre><code>from rich.prompt import Prompt\n</code></pre>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#prompt","title":"Prompt","text":"<p>Then, change the <code>input</code> line in the <code>chat</code> function to use the <code>Prompt.ask()</code> method:</p> <pre><code>def chat(agent):\n# ...\nuser_input = Prompt.ask(\"[grey50]Chat with Kiwi:\")\n# ...\n</code></pre> <p>In the updated code, we replaced the standard <code>input</code> function with <code>Prompt.ask()</code> and passed it a color to create a more readable prompt. Of course, you can choose whatever color you want to make it stand out even more. </p> <p></p> <p>There are a few interesting options with the Prompt class that are worth exploring, including default values, a list of choices, and more. Check out the documentation for more goodness.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#try-it","title":"Try it","text":"<p>Engage in a conversation with Kiwi and enjoy the interactive and intuitive nature of the prompt. Respond to the prompt using natural language, and observe the chatbot's responses displayed in the familiar chat-like format.</p>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#code-review","title":"Code Review","text":"app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.style import Style\nfrom rich.prompt import Prompt\n# Griptape \nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create a ruleset for the agent\nkiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\nRule(\"You identify as a New Zealander.\"),\nRule(\"You have a strong kiwi accent.\")\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nformatted_response = Markdown(response)\nprint(\"\")\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=\"light_sea_green\"),\n))\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[kiwi_ruleset, json_ruleset],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = Prompt.ask(\"[grey50]Chat with Kiwi:\")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself to the user.\")\n# Run the agent\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/11_gleaming_the_chat/#next-steps","title":"Next Steps","text":"<p>In the next section, Multiple Personas, we'll dive into an explosion of personality by using Rulesets to create multiple personas to chat with.</p>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/","title":"Multiple Personas","text":"<p>In this exciting stage, we're going to give our chatbot multiple personalities to make conversations even more dynamic and engaging. Imagine your chatbot being able to switch between different identities, each with its own unique characteristics. Let's get started!</p>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#rulesets","title":"Rulesets","text":""},{"location":"courses/chatbot-rulesets/12_multiple_personas/#creating-personas","title":"Creating Personas","text":"<p>To give our chatbot multiple personas, we'll create separate rulesets for each identity. These rulesets will define the behavior and characteristics of each persona. Here, I've added two new rulesets: \"Zelda\" (my grandmother), and \"Dad\" (my dad). </p> <pre><code># Create rulesets for each persona\nkiwi_ruleset = Ruleset(\nname='Kiwi',\nrules=[\nRule('You identify only as a New Zealander.'),\nRule('You have a very strong Kiwi accent.')\n]\n)\nzelda_ruleset = Ruleset(\nname='Zelda',\nrules=[\nRule('You identify only as a grandmother.'),\nRule('You like to use Yiddish.')\n]\n)\ndad_ruleset = Ruleset(\nname='Dad',\nrules=[\nRule('You identify only as a dad.'),\nRule('You like to use dad jokes.')\n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#switching-personas","title":"Switching Personas","text":"<p>We can't just give the chatbot all these personas and expect it to know what to do. We need to provide some structure around it. So we're going to create another ruleset called the Switcher. This ruleset will understand how and when to switch personalities. There are some key rules for us to think of:</p> <ul> <li>We want the chatbot to be able to switch personalities when it makes sense to (either it thinks it needs to, or the user asks for it)</li> <li>We don't want it to identify as the \"Switcher\" or \"json_output\" rulesets. That wouldn't make any sense.</li> <li>When it does switch rulesets, it should only take on the new persona</li> <li>When it switches personas, it should remember the facts from the previous conversation, but not act like the previous identity.</li> </ul> <pre><code>switcher_ruleset = Ruleset(\nname='Switcher',\nrules=[\nRule(\"IMPORTANT: you have the ability to switch identities when you find it appropriate.\"),\nRule(\"IMPORTANT: You can not identify as 'Switcher' or 'json_output'.\"),\nRule(\"IMPORTANT: When you switch identities, you only take on the persona of the new identity.\"),\nRule(\"IMPORTANT: When you switch identities, you remember the facts from your conversation, but you do not act like your old identity.\"),\n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#add-the-rulesets","title":"Add the Rulesets","text":"<p>Let's now give the agent all these rulesets to work with. We'll simply add them to the list of <code>rulesets</code> in the <code>agent</code> instantiation.</p> <p>Tip</p> <p>Place the <code>switcher_ruleset</code> and <code>json_ruleset</code> before the identity rulesets to enforce the json response.</p> <pre><code># Create the agent\nagent = MyAgent(\nrulesets=[\nswitcher_ruleset, json_ruleset\nkiwi_ruleset, zelda_ruleset, dad_ruleset, \n],\nlogger_level=logging.ERROR\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#prompt-adjustment","title":"Prompt Adjustment","text":"<p>It doesn't make sense for us to keep prompting the user to \"Chat with Kiwi:\" if we might have multiple personalities, so let's modify the <code>Prompt</code> in the <code>chat</code> function:</p> <pre><code>def chat(agent):\n# ...\nuser_input = Prompt.ask(\"[grey50]Chat\")\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#chat","title":"Chat","text":"<p>Now your chatbot is ready to switch between different personalities and engage in exciting conversations with users! Go ahead and run the chatbot. Ask it how many personalities it has, ask it to switch them up, etc. See how it performs. </p> <p></p> <p>Notice in the above image we've got two personas talking, but it's difficult to tell them apart. We'll fix that in the next section.</p>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#code-review","title":"Code Review","text":"<p>We're making great progress. Review the code.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.style import Style\nfrom rich.prompt import Prompt\n# Griptape \nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create rulesets for each persona\nkiwi_ruleset = Ruleset(\nname='Kiwi',\nrules=[\nRule('You identify only as a New Zealander.'),\nRule('You have a very strong Kiwi accent.')\n]\n)\nzelda_ruleset = Ruleset(\nname='Zelda',\nrules=[\nRule('You identify only as a grandmother.'),\nRule('You like to use Yiddish.')\n]\n)\ndad_ruleset = Ruleset(\nname='Dad',\nrules=[\nRule('You identify only as a dad.'),\nRule('You like to use dad jokes.')\n]\n)\nswitcher_ruleset = Ruleset(\nname='Switcher',\nrules=[\nRule(\"IMPORTANT: you have the ability to switch identities when you find it appropriate.\"),\nRule(\"IMPORTANT: You can not identify as 'Switcher' or 'json_output'.\"),\nRule(\"IMPORTANT: When you switch identities, you only take on the persona of the new identity.\"),\nRule(\"IMPORTANT: When you switch identities, you remember the facts from your conversation, but you do not act like your old identity.\"),\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, continue_chatting.\"),\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\nformatted_response = Markdown(response)\nprint(\"\")\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=\"light_sea_green\"),\n))\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[\nswitcher_ruleset, json_ruleset, \nkiwi_ruleset, zelda_ruleset, dad_ruleset\n],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = Prompt.ask(\"[grey50]Chat\")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself.\")\n# Run the agent#\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/12_multiple_personas/#next-steps","title":"Next Steps","text":"<p>In the next stage: Colorful Personalities, we'll make it easier to differentiate between which chatbot you're speaking with.</p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/","title":"Colorful Personalities","text":"<p>In this step, we're going to add some flair to our chatbot by assigning different colors to each persona. This will visually distinguish the different personalities, making the conversation more engaging and fun! </p> <p>We'll do this by giving each persona a favorite color, then add another key to our <code>json_output</code> ruleset, and use that key in our <code>respond</code> method.</p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#updating-rulesets","title":"Updating Rulesets","text":""},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#favorite-colors","title":"Favorite Colors","text":"<p>To assign colors to each persona, we'll add new rules to each of our identity ruleset to give them all favorite colors. You're welcome to use Standard Colors, Hex, or RGB values. Whatever makes you happy.</p> <pre><code>kiwi_ruleset = Ruleset(\nname = \"kiwi\",\nrules = [\n# ... truncated for brevity\nRule(\"Favorite color: light_sea_green\")\n]\n)\nzelda_ruleset = Ruleset(\nname=\"Zelda\",\nrules=[\n# ...\nRule(\"Favorite color: light_pink3\")\n]\n)\ndad_ruleset = Ruleset(\nname=\"Dad\",\nrules=[\n# ... \nRule(\"Favorite color: light_steel_blue\")\n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#add-key","title":"Add Key","text":"<p>We also need to make changes to the <code>json_ruleset</code> to include the Favorite Color key. Modify the first rule to include that key:</p> <pre><code>json_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: response, favorite_color, continue_chatting.\"),\n# ... \n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#respond-method","title":"Respond Method","text":"<p>Next, we'll adjust the <code>respond</code> method get the favorite color, and use it properly.</p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#get-the-color","title":"Get the color","text":"<p>After the <code>continue_chatting = data[\"continue_chatting\"]</code> line, add one to get the color:</p> <pre><code>class MyAgent(Agent):\ndef respond(self, user_input):\n# ...\ncontinue_chatting = data[\"continue_chatting\"]\ncolor = data[\"favorite_color\"]\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#use-it","title":"Use it","text":"<p>Then, update the <code>style</code> line in the <code>rprint</code> statement to use <code>color</code> instead of specifying it directly as we were before:</p> <pre><code>class MyAgent(Agent):\ndef respond(self, user_input):\n# ...\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=color)\n))\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#try-it","title":"Try it","text":"<p>Run the code and notice how much nicer it is to be able to discern who is talking based on their color.</p> <p></p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#adding-a-name","title":"Adding a Name","text":"<p>We're not quite finished yet. We also can make things a bit easier to follow if we clarify the name of the persona we're chatting with.</p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#update-ruleset","title":"Update Ruleset","text":"<p>This will be a relatively quick fix. We just need to add another key to the <code>json_ruleset</code>, and then modify the <code>rprint</code> statement again.</p> <p>First, add the <code>name</code> key:</p> <pre><code>json_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\n# ...\nRule(\"Respond in plain text only with JSON objects that have the following keys: name, response, favorite_color, continue_chatting.\"),\n# ...\n]\n)\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#get-the-name","title":"Get the Name","text":"<p>Now get the <code>name</code> from the json data in the <code>respond</code> method of the <code>MyAgent</code> class:</p> <pre><code>class MyAgent(Agent):\ndef respond(self, user_input):\n# ...\ncolor = data[\"favorite_color\"]\nname = data[\"name\"]\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#use-it_1","title":"Use it","text":"<p>Then, add a <code>title</code> and <code>title_align</code> in the <code>rprint</code> function:</p> <pre><code>class MyAgent(Agent):\ndef respond(self, user_input):\n# ...\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=color),\ntitle=name,\ntitle_align=\"left\"\n))\n# ...\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#try-it_1","title":"Try it","text":"<p>Give it a try and see how much nicer it is!</p> <p></p>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#code-review","title":"Code Review","text":"<p>Lots of changes in this section, with some great usability enhancements! </p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.style import Style\nfrom rich.prompt import Prompt\n# Griptape \nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create rulesets for each persona\nkiwi_ruleset = Ruleset(\nname='Kiwi',\nrules=[\nRule('You identify only as a New Zealander.'),\nRule('You have a very strong Kiwi accent.'),\nRule(\"Favorite color: light_sea_green\")\n]\n)\nzelda_ruleset = Ruleset(\nname='Zelda',\nrules=[\nRule('You identify only as a grandmother.'),\nRule('You like to use Yiddish.'),\nRule(\"Favorite color: light_pink3\")\n]\n)\ndad_ruleset = Ruleset(\nname='Dad',\nrules=[\nRule('You identify only as a dad.'),\nRule('You like to use dad jokes.'),\nRule(\"Favorite color: light_steel_blue\")\n]\n)\nswitcher_ruleset = Ruleset(\nname='Switcher',\nrules=[\nRule(\"IMPORTANT: you have the ability to switch identities when you find it appropriate.\"),\nRule(\"IMPORTANT: You can not identify as 'Switcher' or 'json_output'.\"),\nRule(\"IMPORTANT: When you switch identities, you only take on the persona of the new identity.\"),\nRule(\"IMPORTANT: When you switch identities, you remember the facts from your conversation, but you do not act like your old identity.\"),\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: name, response, favorite_color, continue_chatting.\"),\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nagent_response = agent.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\ncolor = data[\"favorite_color\"]\nname = data[\"name\"]\nformatted_response = Markdown(response)\nprint(\"\")\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=color),\ntitle=name,\ntitle_align=\"left\"\n))\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[\nswitcher_ruleset, json_ruleset,  \nkiwi_ruleset, zelda_ruleset, dad_ruleset\n],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = Prompt.ask(\"[grey50]Chat\")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself.\")\n# Run the agent#\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/13_adding_personality_colors/#next-steps","title":"Next Steps","text":"<p>In the next stage: Quick Feedback, we'll make the chatbot feel a bit more responsive to user input by giving it a spinner so it doesn't feel like it's lagging while the LLM is fetching it's response.</p>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/","title":"Quick Feedback","text":""},{"location":"courses/chatbot-rulesets/14_making_it_quick/#ux-enhancement","title":"UX Enhancement","text":"<p>The UX of our application can be enhanced by letting the user know that the application is working after they execute a command. At the moment, it is processing, but it just doesn't let the user know. We'll use the Spinner functionality from the Rich library to make the application a little more user-friendly and  visually appealing.</p>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/#spinner","title":"Spinner","text":"<p>The <code>Console</code> class has a <code>status</code> method which will allow us to display a <code>Spinner</code> to the user while Griptape is waiting for the LLM response.</p> <p>Abstract</p> <p>There are lots of spinners available. You can check them out by running the following in your terminal:</p> <pre><code>python -m rich.spinner\n</code></pre> <p></p>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/#importing-the-console","title":"Importing the Console","text":"<pre><code>from rich.console import Console\n</code></pre> <p>Importing the Console class from the <code>rich</code> library is simple and straightforward, and should be familliar to you by this point in the lesson.</p>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/#modify-respond","title":"Modify Respond","text":"<p>We will add a spinner to our <code>respond</code> method in the <code>MyAgent</code> subclass. This will show an animated spinner in the console while our agent is processing the user's input. This makes the app feel more responsive.</p> <p>Update the <code>respond</code> method as follows:</p> <pre><code>class MyAgent(Agent):\ndef respond(self, user_input):\nconsole = Console()\nwith console.status(spinner=\"simpleDotsScrolling\", status=\"\"):\nagent_response = self.run(user_input)\n# ...\n</code></pre> <p>In the code above, <code>console.status(spinner=\"simpleDotsScrolling\", status=\"\")</code> starts an animated spinner in the console that will run until the block of code it is wrapping (the agent's processing of user input) completes. </p> <p>Note</p> <p>We've left <code>status</code> blank - because we don't really need to send any text. However, feel free to add some text here if you desire.</p> <p>Now when you run the chat, you'll notice the animated spinner right after you ask the chatbot a question!</p> <p></p>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/#code-review","title":"Code Review","text":"<p>Double-check your code to make sure the spinner is working as expected.</p> app.py<pre><code>from dotenv import load_dotenv\nimport logging\nimport json\n# Rich\nfrom rich import print as rprint\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.style import Style\nfrom rich.prompt import Prompt\nfrom rich.console import Console\n# Griptape \nfrom griptape.structures import Agent\nfrom griptape.rules import Rule, Ruleset\n# Load environment variables\nload_dotenv()\n# Create rulesets for each persona\nkiwi_ruleset = Ruleset(\nname='Kiwi',\nrules=[\nRule('You identify only as a New Zealander.'),\nRule('You have a very strong Kiwi accent.'),\nRule(\"Favorite color: light_sea_green\")\n]\n)\nzelda_ruleset = Ruleset(\nname='Zelda',\nrules=[\nRule('You identify only as a grandmother.'),\nRule('You like to use Yiddish.'),\nRule(\"Favorite color: light_pink3\")\n]\n)\ndad_ruleset = Ruleset(\nname='Dad',\nrules=[\nRule('You identify only as a dad.'),\nRule('You like to use dad jokes.'),\nRule(\"Favorite color: light_steel_blue\")\n]\n)\nswitcher_ruleset = Ruleset(\nname='Switcher',\nrules=[\nRule(\"IMPORTANT: you have the ability to switch identities when you find it appropriate.\"),\nRule(\"IMPORTANT: You can not identify as 'Switcher' or 'json_output'.\"),\nRule(\"IMPORTANT: When you switch identities, you only take on the persona of the new identity.\"),\nRule(\"IMPORTANT: When you switch identities, you remember the facts from your conversation, but you do not act like your old identity.\"),\n]\n)\njson_ruleset = Ruleset(\nname=\"json_ruleset\",\nrules=[\nRule(\"Respond in plain text only with JSON objects that have the following keys: name, response, favorite_color, continue_chatting.\"),\nRule(\"The 'response' value should be a string that can be safely converted to markdown format. Include line returns when necessary.\"),\nRule(\"If it sounds like the person is done chatting, set 'continue_chatting' to False, otherwise it is True\"),\n]\n)\n# Create a subclass for the Agent\nclass MyAgent(Agent):\ndef respond (self, user_input):\nconsole = Console()\nwith console.status(spinner=\"simpleDotsScrolling\", status=\"\"):\nagent_response = self.run(user_input)\ndata = json.loads(agent_response.output_task.output.value)\nresponse = data[\"response\"]\ncontinue_chatting = data[\"continue_chatting\"]\ncolor = data[\"favorite_color\"]\nname = data[\"name\"]\nformatted_response = Markdown(response)\nprint(\"\")\nrprint(Panel.fit(\nformatted_response, \nwidth=80, \nstyle=Style(color=color),\ntitle=name,\ntitle_align=\"left\"\n))\nprint(\"\")\nreturn continue_chatting\n# Create the agent\nagent = MyAgent(\nrulesets=[\nswitcher_ruleset, json_ruleset,  \nkiwi_ruleset, zelda_ruleset, dad_ruleset\n],\nlogger_level=logging.ERROR\n)\n# Chat function\ndef chat(agent):\nis_chatting = True\nwhile is_chatting:\nuser_input = Prompt.ask(\"[grey50]Chat\")\nis_chatting = agent.respond(user_input)\n# Introduce the agent\nagent.respond(\"Introduce yourself.\")\n# Run the agent#\nchat(agent)\n</code></pre>"},{"location":"courses/chatbot-rulesets/14_making_it_quick/#all-done","title":"All Done!","text":"<p>Success</p> <p>You did it!</p> <p>That's it! We've come a long way in this tutorial series and now you have a multi-persona chat application written with Griptape. Hopefully you've been able to see how using Rulesets can be used for both creative and structural control of your applications.</p> <p>Congratulations on making it through! We're thrilled you decided to join us for this course and we hope you've enjoyed it as much as we have. We'd love to hear your feedback, so please don't hesitate to let us know what you thought.</p> <p>More importantly, we wish you all the best as you continue your journey with Griptape and Python. Remember to have fun, experiment, and keep on learning. Happy coding! \ud83d\ude80</p>"},{"location":"courses/compare-movies-workflow/","title":"Learn Griptape Workflows through Cinematic Comparison","text":"<pre><code>graph TB\n    subgraph \" \"\n        direction TB\n        AA([\"\\n INPUT \\n\\n\"]):::output\n        A(Start Task):::main \n        B(\"Task 1a\")\n        C(\"Task 1b\"):::tool\n        I(\"End Task\"):::main\n        G(\"Task 2a\")\n        H(\"Task 2b\"):::tool\n        F(\"Task 3\")\n        J([\"\\n  Output \\n\\n\"]):::output\n        AA --&gt; A\n        A --&gt; B --&gt; C --&gt; I\n        A --&gt; G --&gt; H --&gt; I\n        A --&gt; F\n        I --&gt; J\n        F ---&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5\n    classDef output fill:#5552,stroke:#555\n</code></pre>"},{"location":"courses/compare-movies-workflow/#course-description","title":"Course Description","text":"<p>Griptape Workflows allow you to create complicated parent-child task relationships, where one task won't begin until all it's parent tasks have completed. Using movie narratives as our backdrop, you'll gain practical experience in establishing inter-task connections and seeing how they collaboratively weave a coherent story. Ideal for those keen on understanding the intricacies of Griptape's Workflows while engaging in a compelling thematic exploration.</p>"},{"location":"courses/compare-movies-workflow/#what-you-will-create","title":"What you will create","text":"<p>Below you can see a representation of the workflow graph we will create in the course, where you will pass rough descriptions of movies, then for each movie a series of tasks will be executed:</p> <ol> <li>Get the actual name of the movie.</li> <li>Search the web and get a very short description of the movie.</li> </ol> <p>Finally, once all tasks are finished, a final comparison task will be executed of the three movies and output the results.</p> <pre><code>graph TB\n    A[\"&lt;h4&gt;PromptTask: START&lt;/h4&gt;\n    Given some rough movie descriptions,\n    describe their similarities.\n    &lt;br&gt;\"] --&gt; AB([\"A boy finds an alien\"]):::Result\n    AB --&gt; B(\"&lt;b&gt;PromptTask&lt;/b&gt;:&lt;br&gt;Get Name\"):::PromptTask\n\n    A --&gt; AC([\"Black and white movie turns color\"]):::Result\n    AC --&gt; C(\"&lt;b&gt;PromptTask&lt;/b&gt;:&lt;br&gt;Get Name\"):::PromptTask\n\n    A --&gt; AD([\"Kid suddenly becomes big\"]):::Result\n    AD --&gt; D(\"&lt;b&gt;PromptTask&lt;/b&gt;:&lt;br&gt;Get Name\"):::PromptTask\n\n    K(\"&lt;b&gt;PromptTask&lt;/b&gt;:&lt;br&gt;END (Compare Movies)\"):::PromptTask\n    subgraph movie 1 [\" \"]\n    B --&gt; BE([E.T.]):::Result\n    BE --&gt; E(\"&lt;b&gt;ToolkitTask&lt;/b&gt;:&lt;br&gt;Get Summary\"):::ToolkitTask\n    E --&gt; HK([\"A troubled child summons \\nthe courage to help \\na friendly alien ...\"]):::Result\n    end\n\n    subgraph movie 2 [\" \"]\n    C --&gt; CF([Wizard of Oz]):::Result\n    CF --&gt; F(\"&lt;b&gt;ToolkitTask&lt;/b&gt;:&lt;br&gt;Get Summary\"):::ToolkitTask\n    F --&gt; IK([\"A classic film from \\n1939 in which young \\nDorothy Gale and her\\ndog Toto ...\"]):::Result\n\n    end\n    subgraph movie 3 [\" \"]\n    D --&gt; CG([Big]):::Result\n    CG --&gt; G(\"&lt;b&gt;ToolkitTask&lt;/b&gt;:&lt;br&gt;Get Summary\"):::ToolkitTask\n    G --&gt; JK([\"After wishing to be\\nmade big, a teenage boy\\nwakes to find ...\"]):::Result\n    end\n    HK ---&gt; K\n    IK ---&gt; K\n    JK ---&gt; K\n\n    K --&gt; L([\"\\nAll three movies:\n    &lt;i&gt;E.T. the Extra-Terrestrial&lt;/i&gt;, &lt;i&gt;The Wizard of Oz&lt;/i&gt;, and &lt;i&gt;Big&lt;/i&gt;, \n            share a common theme of fantastical journeys and adventures.    \n            They all involve characters who are thrust into extraordinary \n            circumstances that are far removed from their normal lives.\\n\\n\"]):::Result\n\n    classDef PromptTask stroke:#A00\n    classDef ToolkitTask stroke:#f06090\n    classDef Result fill:#5552,stroke:#555\n</code></pre>"},{"location":"courses/compare-movies-workflow/#who-is-this-course-for","title":"Who is this course for?","text":"<p>This course is aimed at intermediate level Python developers who are interested in learning about Griptape Workflows and how to handle parent/child task relationships. </p>"},{"location":"courses/compare-movies-workflow/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this course, you will need:</p> <ul> <li>An OpenAI API Key (available here: https://beta.openai.com/account/api-keys){target=\"_blank\"}</li> <li>Python3.9+ installed on your machine</li> <li>An IDE (such as Visual Studio Code or PyCharm) to write and manage your code</li> </ul> <p>If you don't have those items available, it's highly recommended you go through the Griptape Setup - Visual Studio Code course to set up your environment.</p>"},{"location":"courses/compare-movies-workflow/#course-outline","title":"Course Outline","text":"<p>The course will cover:</p> <ul> <li>Creating your first workflow</li> <li>Making it scalable</li> <li>Handling inputs with Jinja2 templates</li> <li>Using the WebScraper tool</li> <li>Understanding Workflow Outputs</li> </ul>"},{"location":"courses/compare-movies-workflow/#useful-resources","title":"Useful Resources","text":"<p>These resources will provide additional information and context throughout the course:</p> <ul> <li>Griptape Documentation</li> <li>Visual Studio Code</li> <li>Jinja2 Documentation</li> </ul>"},{"location":"courses/compare-movies-workflow/#next-steps","title":"Next Steps","text":"<p>Get yourself all setup and ready by moving on to Setup.</p>"},{"location":"courses/compare-movies-workflow/01_setup/","title":"Setup","text":"<p>As with any project, the first step is setting up your environment. Let's get started by ensuring you have a project structure ready to work with.</p>"},{"location":"courses/compare-movies-workflow/01_setup/#prerequisites","title":"Prerequisites","text":"<p>Important</p> <p>Since this is an intermediate level course, please ensure you've gone through the Griptape Setup - Visual Studio Code course to set up your environment. We will be starting from the code at that point.</p> <ol> <li> <p>Code Editor: We recommend using Visual Studio Code for this course, due to its handy features and Python support. However, if you have another favorite IDE or text editor, feel free to use that! </p> </li> <li> <p>Python3.9+: Griptape requires Python 3.9+.</p> </li> <li> <p>Python Environment Manager (for VS Code users): This extension is not a hard requirement, but it does make managing your Python environments a lot easier. </p> </li> <li> <p>OpenAI API Key: Our chatbot will be powered by gpt-4, which requires an API key from OpenAI. You can get your key from OpenAI's website.</p> </li> </ol> <p>Got everything installed? Awesome! Now, let's get started setting up our project.</p>"},{"location":"courses/compare-movies-workflow/01_setup/#create-a-project","title":"Create a Project","text":"<p>Following the instructions in Griptape Setup - Visual Studio Code  please:</p> <ol> <li>Create your project folder. Example: <code>griptape-compare-movies-workflow</code></li> <li>Set up your virtual environment</li> <li>Ensure you <code>pip install griptape python-dotenv</code></li> <li>Create a <code>.env</code> file with your <code>OPENAI_API_KEY</code></li> <li>Create your <code>app.py</code> file with the following code:</li> </ol> app.py<pre><code>from dotenv import load_dotenv\nload_dotenv() # Load your environment\n</code></pre>"},{"location":"courses/compare-movies-workflow/01_setup/#next-steps","title":"Next Steps","text":"<p>And there we have it, environment is all set up! In the next section Concepts, we'll dive deeper into understanding the concepts of Pipelines, Workflows, and Tasks.</p>"},{"location":"courses/compare-movies-workflow/02_concepts/","title":"Main Concepts","text":""},{"location":"courses/compare-movies-workflow/02_concepts/#understanding-workflows-and-pipelines","title":"Understanding Workflows and Pipelines","text":"<p>Frequently when creating applications you will want to execute a series of steps in a very specific order. Workflows and Pipelines are both structures that allow us to do that. They have many of the same features as Agents, but are more directable. Whereas Agents can be given behaviors and tools and will use them when prompted appropriately, Pipelines and Workflows utilize hieararchies of tasks in very specific ways.</p>"},{"location":"courses/compare-movies-workflow/02_concepts/#pipelines","title":"Pipelines","text":"<p>Pipelines are always a sequential series of steps - one task after another until it is finished. </p> <p>In this course we're going to be taking some rough descriptions of movies and getting their actual names, then getting the summaries from the web and comparing them. Doing this as a Pipeline might look something like:</p> <ol> <li>Get movie descriptions</li> <li>Get the actual name of the movie</li> <li>Look up the summary </li> </ol> <p>The flow of tasks would be:</p> <pre><code>graph LR\n    A(Movie Description) --&gt; C(Get Name ) --&gt; D(Get Summary)</code></pre> <p>This works great for our simple task, but the point of this course is to compare multiple movies. If we use a standard linear pipeline, it would mean:</p> <pre><code>graph LR\n    A(Movie Descriptions) --&gt; B(Get Name 1) --&gt; D(Get Summary 1) --&gt; E(Get Name 2) \n    E --&gt; F(Get Summary 2) --&gt; G(\"Get Name &lt;i&gt;n&lt;/i&gt;\" ):::dash --&gt; H(\"Get Summary &lt;i&gt;n&lt;/i&gt;\"):::dash \n    H --&gt; I(Compare)\n\n    classDef dash stroke-dasharray: 5 5\n</code></pre> <p>As you can tell, this could get quite unweildy. In addition, it doesn't make much sense for getting the name of the 4th movie to have to wait until the summary of the 3rd movie is figured out, as they're not really dependent on each other.</p> <p>Workflows are perfect for this sort of situation. They allow you to parallelize tasks that aren't dependent. Let's see how something like this might look.</p>"},{"location":"courses/compare-movies-workflow/02_concepts/#workflows","title":"Workflows","text":"<p>Workflows allow for complex interactions, resembling tree branches.</p> <p>Workflows are non-sequential and individual tasks can depend on multiple input tasks. This allows you to create a single task that waits for all other tasks to complete before it can begin.</p> <p>This is what a Workflow might look like for doing what we mentiond above. </p> <p>Note</p> <p>The graph is drawn top to bottom for this example because it's easier to understand the flow of data, but it can be drawn in either direction.</p> <pre><code>graph TB\n    A(Movie Descriptions) --&gt; B(Get Name 1) --&gt; D(Get Summary 1) --&gt; I(Compare)\n    A --&gt; E(Get Name 2) --&gt; F(Get Summary 2) --&gt; I\n    A --&gt; G(\"Get Name &lt;i&gt;n&lt;/i&gt;\" ):::dash\n    G --&gt; H(\"Get Summary &lt;i&gt;n&lt;/i&gt;\"):::dash \n    H --&gt; I\n    classDef dash stroke-dasharray: 5 5\n</code></pre> <p>Notice how the movies can be evaluated in parallel, but the Compare task will wait until all it's parent tasks are completed. </p>"},{"location":"courses/compare-movies-workflow/02_concepts/#tasks","title":"Tasks","text":"<p>Before we dive in and start setting up our own workflow, it's important to review the concepts of Tasks. With Griptape, there are many types of tasks you'll be working with, including:</p> Task Type Description Example PromptTask General purpose prompting to the LLM. <code>PromptTask(\"Tell me a story about skateboards\")</code> ToolkitTask Uses Griptape Tools to complete a task with Chain of Thought (CoT) reasoning. <code>ToolkitTask(\"Summarize griptape.ai\", tools=[WebScraper()])</code> TookTask Similar to ToolkitTask, but only uses a single tool and no CoT. <code>ToolTask(\"Give me the answer for 52-10\", tool=Calculator())</code> Extraction Tasks Various tasks associated with extracting information from text. See examples in the documentation. TextSummaryTask Summarizes text very efficiently <code>TextSummaryTask(\"Imagine this is a massive amount of text.\")</code> TextQueryTask Can be used to query large bodies of text, for example a vector database. See examples in the documentation <p>In this course we will be focusing mostly on Prompt Tasks and Toolkit Tasks. Both of these task types are used to work with the LLM. They both take an input as a prompt, can take arguments, use specific drivers, and have parent/child relationships. The main difference between them is that ToolkitTasks can also use tools like Calculator(), FileBrowser(), and more. View all the tools available with Griptape here.</p> <pre><code># Example PromptTask to get a movie name\n#\nmovie_task = PromptTask(\n\"What is this movie: {{ descr }}\",\ncontext = {                        \n\"descr\": \"princess and farmhand named Wesley\" \n},\nid=\"movie_id\"                      # task id can be referenced by other tasks\n)\n# This ToolkitTask works with the output of the previous task, and can use tools.\n#\ndescribe_task = ToolkitTask(\n\"Get the description of this movie: {{ parent_outputs['movie_id'] }}\",       \ntools = [                          \nWebScraper()\n],\nid='describe_id')\n</code></pre> <p>I have found that the best way to really understand how PromptTasks and ToolkitTasks work is to use them in context. So let's move on to the next section where we'll create our First Workflow, and get an understanding of the basics of how parent/child relationships can work.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/","title":"First Workflow","text":""},{"location":"courses/compare-movies-workflow/03_first_workflow/#overview","title":"Overview","text":"<p>In this section we're going to create the first workflow in our Movie Comparison application. By the end of this section you will have a workflow that lets you create a cursory comparison between two movies.</p> <p>For example, if you pass it these two descriptions:</p> <ul> <li>\"A boy discovers an alien in his back yard\"</li> <li>\"A shark attacks a beach\"</li> </ul> <p>It will come back with:</p> <p>Result</p> <p>Both E.T. the Extra-Terrestrial and Jaws are directed by Steven Spielberg.   They are also both iconic films that have had a significant impact on popular culture.</p> <p>The hierarchy we will create looks like the following:</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        B(Describe Workflow):::main --&gt; C(Movie 1) --&gt; E(Compare Task):::main\n        B --&gt; D(Movie 2) --&gt; E\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <p>As you can see, there is a <code>Workflow</code> Structure, and four tasks that will be created. The Start and End tasks (Describe Workflow and Compare Task), and two siblings (Movie 1 and Movie 2). Compare Task will be dependent on them to complete before it can execute.</p> <p>Tip</p> <p>Workflows must always have a Start and End task.</p> <p>To generate this structure, we will first create our Start and End tasks, and then insert the movie tasks. This will guarantee that our tasks exist in the workflow exactly where we want them. <pre><code>flowchart TB \n    subgraph Step 2 [\"Insert\"]\n        direction TB\n        C(Describe Workflow):::main --&gt; D(Movie 1) --&gt; F(Compare Task):::main\n        C --&gt; E(Movie 2) --&gt; F\n    end\n\n    subgraph Step 1 [\"Start &amp; End\"]\n        direction TB\n        A(Describe Workflow):::main --&gt; B(Compare Task):::main\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre></p> <p>Let's get started.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#importing-required-modules","title":"Importing Required Modules","text":"<p>Before starting, we need to import the necessary modules. Open the <code>app.py</code> file you created in the setup section and import the two Griptape classes you'll need: <code>Workflow</code> and <code>PromptTask</code>:</p> <pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask\nload_dotenv() # Load your environment\n</code></pre> <p>Note</p> <p>You might recall that <code>Agent</code> was also imported through <code>griptape.structures</code>. That's because <code>Agent</code>, <code>Workflow</code>, and <code>Pipeline</code> are all Griptape's ways of working with LLMs. </p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#create-workflow-structure","title":"Create Workflow Structure","text":""},{"location":"courses/compare-movies-workflow/03_first_workflow/#initialize-the-workflow","title":"Initialize the Workflow","text":"<p>Now, let's create the foundation for our Workflow. After the line <code>load_dotenv()</code>, create an instance of the Workflow class:</p> <pre><code># ... truncated for brevity\nload_dotenv() # Load your environment\n# Create the workflow object\nworkflow = Workflow()\n</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#create-a-start-task","title":"Create a Start task","text":"<p>First, we'll create our \"start\" task. This will be a simple <code>PromptTask</code> that lets the LLM know what we're going to do. </p> <p>After the <code>workflow</code> line, add: <pre><code># Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\n</code></pre></p> <p>There are two things that are important to point out in this task creation.</p> <ol> <li>Notice that we're using a <code>PromptTask</code>. That's because we don't need to use any tools for this particular task, we only want to use the LLM.</li> <li>We have given the task an <code>id</code>. This is so we can reference it later in the script. If you don't pass this value, the task will be given a random string as the id.</li> </ol> <p>Important</p> <p>Every task in a workflow must have a unique id. If two tasks have the same id, the workflow will fail.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#add-task-to-the-workflow","title":"Add Task to the Workflow","text":"<p>You have created the task, but it's not yet part of the workflow. In order to do that, we'll need to use the <code>add_task</code> method.</p> <p>After the PromptTask line, add:</p> <pre><code># Add tasks to workflow\nworkflow.add_task(start_task)\n</code></pre> <p>At this point, your workflow flow graph looks like:</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        B(PromptTask: START):::main\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <p>However if you execute your script, nothing will happen. That's because you need to tell the workflow graph to run.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#run-the-workflow","title":"Run the Workflow","text":"<p>To run a workflow, you simply need to call the method <code>run</code>:</p> <pre><code># Run the workflow\nworkflow.run()\n</code></pre> <p>Here's the result. Notice in the logs you can see the Task inputs and outputs: <pre><code>[11/15/23 13:05:49] INFO     PromptTask START                                                                                   Input: I will provide you a list of movies to compare.                                             [11/15/23 13:05:52] INFO     PromptTask START                                                                                   Output: Sure, please provide the list of movies you want me to compare.                            </code></pre></p> <p>As you can see, the LLM is ready to take a list of movies.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#add-the-end-task","title":"Add the end task","text":"<p>The next task we'll add will be the last task. This is a good place to create a task that summarizes what has been done, and then add it to the end of the workflow using the same <code>add_task</code> method.</p> <pre><code># Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\nend_task = PromptTask(\"How are the movies the same?\", id=\"END\")\n# Add tasks to workflow\nworkflow.add_task(start_task)\nworkflow.add_task(end_task)\n</code></pre> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        B(PromptTask: START):::main --&gt; C(PromptTask: END):::main\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <p>Tip</p> <p>This process has changed from versions of Griptape prior to v0.20.</p> <p>In previous versions, the <code>add_task</code> method would add tasks as siblings of the parent task. With versions greater than 0.20, they add them one after another. To add tasks as sibblings you will be inserting tasks.</p> <pre><code># Add tasks to workflow\nworkflow.add_task(start_task)\nworkflow.add_task(end_task)\n</code></pre> After Griptape 0.2.0Before Griptape 0.2.0 <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        B(PromptTask: START):::main --&gt; C(PromptTask: END):::main\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        B(PromptTask: START):::main\n        C(PromptTask: END):::main\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#add-tasks-into-workflow","title":"Add Tasks into Workflow","text":""},{"location":"courses/compare-movies-workflow/03_first_workflow/#create-the-first-movie-prompt-task","title":"Create the first Movie Prompt task","text":"<p>Now it's time to create the first task asking the LLM to identify a movie. This will be a <code>PromptTask</code>.</p> <p>In your code, after the <code>end_task</code>, add:</p> <pre><code># Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\nend_task = PromptTask(\"How are the movies the same?\", id=\"END\")\n# Create movie tasks\nmovie_1_task = PromptTask(\"What movie is this: boy finds alien in backyard.\", id=\"movie_1\")\n</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#insert-the-task-into-the-workflow","title":"Insert the Task into the Workflow","text":"<p>You have created the task, but it's not yet part of the workflow. In order to do that, we'll need to use the <code>insert_tasks</code> method.</p> <p>The <code>insert_tasks</code> method takes a couple of arguments. It looks like this: <pre><code>workflow.insert_tasks(task_a, [task_c, task_d], task_b)\nworkflow.insert_tasks(task_c, [task_e, task_f], task_b)\n</code></pre></p> <p>Notice the second argument is a <code>list</code> of tasks. This method will take two tasks that already have a parent/child relationship, and insert whatever tasks are listed in that second argument between them. </p> <p>The graph above would look something like:</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(task_a)\n        B(task_b)\n        C(task_c)\n        D(task_d)\n        E(task_e)\n        F(task_f)\n        A --&gt; B --&gt; D\n        A --&gt; C --&gt; E --&gt; D\n        C --&gt; F --&gt; D\n    end\n</code></pre> <p>We'll see this in more detail shortly, but for now let's just add the single task.</p> <p>In your script, after the <code>add_task</code> lines, add:</p> <pre><code># Add tasks to workflow\nworkflow.insert_tasks(start_task, [movie_1_task], end_task)\n</code></pre> <p>At this point, your workflow flow graph looks like:     <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(PromptTask: START):::main\n        B(PromptTask: movie_1_task)\n        C(PromptTask: END):::main\n        A --&gt; B --&gt; C\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre></p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#run-the-workflow_1","title":"Run the Workflow","text":"<p>Run the script to see the output.</p> <p>Here's the result. Notice the tasks being executed, and the summary where it tries to compare the results:</p> <pre><code>[11/15/23 14:10:59] INFO     PromptTask START                                                                                   Input: I will provide you a list of movies to compare.                                             [11/15/23 14:11:00] INFO     PromptTask START                                                                                   Output: Sure, please provide the list of movies you want me to compare.                            INFO     PromptTask movie_1                                                                                 Input: What movie is this: boy finds alien in backyard.                                            [11/15/23 14:11:02] INFO     PromptTask movie_1                                                                                 Output: The movie you are referring to is likely \"E.T. the Extra-Terrestrial\" directed by Steven    Spielberg.                                                                                         INFO     PromptTask END                                                                                     Input: How are the movies the same?                                                                [11/15/23 14:11:06] INFO     PromptTask END                                                                                     Output: As an AI, I need specific movies to compare in order to provide similarities. Please       provide the names of the movies you want to compare.                                               </code></pre> <p>The LLM is unable to compare the results for two reasons - first, we only passed a single movie. Second, we didn't pass the information about the movie back to the LLM so it doesn't know what we were talking about. We'll take care of these one at a time.</p> <p>First, we'll add a second movie.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#second-movie-task","title":"Second Movie Task","text":"<p>Just below the first movie PromptTask, add a second one with another description.</p> <pre><code># ...\n# Create tasks\nmovie_1_task = PromptTask(\"What movie is this: boy finds alien in backyard.\", id=\"movie_1\")\nmovie_2_task = PromptTask(\"What movie is this?: a shark attacks a beach.\", id=\"movie_2\")\n# ...\n</code></pre> <p>Important</p> <p>Don't forget to add the id to the second task and make sure it's unique from the first task.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#add-second-task-to-workflow","title":"Add Second Task to Workflow","text":"<p>Just like before, we need to insert <code>movie_2_task</code> to <code>workflow</code> with the <code>insert_tasks</code> method. Modify the previous insert_tasks line to include both movie tasks.</p> <pre><code># ...\n# Add tasks to workflow\nworkflow.insert_tasks(start_task, [movie_1_task, movie_2_task], end_task)\n# ...\n</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#test","title":"Test","text":"<p>Go ahead and run the code and notice that the two movie tasks executed in parallel:</p> <pre><code># ... truncated for brevity\n[11/15/23 14:14:32] INFO     PromptTask START                                                                                   Input: I will provide you a list of movies to compare.                                             [11/15/23 14:14:34] INFO     PromptTask START                                                                                   Output: Sure, I am ready to help you compare the movies. Please provide the list.                   INFO     PromptTask movie_2                                                                                 Input: What movie is this?: a shark attacks a beach.                                               INFO     PromptTask movie_1                                                                                 Input: What movie is this: boy finds alien in backyard.                                            [11/15/23 14:14:38] INFO     PromptTask movie_2                                                                                 Output: This could refer to several movies as shark attacks are a common theme in many films.      However, the most iconic one is \"Jaws\" directed by Steven Spielberg.                               INFO     PromptTask movie_1                                                                                 Output: This could refer to several movies, but the most famous one is probably \"E.T. the          \n                             Extra-Terrestrial\" directed by Steven Spielberg.                                                   INFO     PromptTask END                                                                                     Input: How are the movies the same?                                                                [11/15/23 14:14:41] INFO     PromptTask END                                                                                     Output: As an AI, I need more specific details to provide a comparison. Please provide the names of\n                             the movies you want to compare.                                                        </code></pre> <p>Hmm. It doesn't look like the <code>compare</code> task knows what we're talking about. The workflow evaluated both we sent it, we can see that in the logs above, but the compare task has no knowledge of them. </p> <p>That's because we need to pass the results of the previous task to the current task. This is a very important feature, as it allows us to be very specific about what data is sent to the LLM.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#pass-the-data","title":"Pass the Data","text":"<p>In order to send the data to the PromptTask, we need to somehow feed the result of the previous task's execution to the prompt.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#jinja2","title":"Jinja2","text":"<p>Griptape uses the Jinja2 template engine, which allows you to insert data into the prompt. There's a lot of power available with Jinja templates, but in this course we'll keep our focus rather small.</p> <p>Jinja templates access variables using the <code>{{ }}</code> syntax. Tasks have a property <code>parent_outputs</code> that tell us what objects are coming into the node.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#update-the-prompt","title":"Update the Prompt","text":"<p>In order to update the prompt, we want to tell it what tasks to be looking at. If you check your code, you can see that we used the <code>id</code> property earlier when we were creating the tasks:</p> <pre><code>movie_1_task = PromptTask(\"What movie is this?: A boy discovers an alien in his back yard\", id=\"movie_1\")\nmovie_2_task = PromptTask(\"What movie is this?: a shark attacks a beach.\", id=\"movie_2\")\n</code></pre> <p>So <code>movie_1</code> and <code>movie_2</code> are the two ids we can use in our Jinja template. They can be specified like this: <code>{{ parent_outputs['movie_1'] }}</code> and <code>{{ parent_outputs['movie_2'] }}</code></p> <p>Update the <code>END</code> task to specify the particular ids of the parent_outputs. Note - I'm using <code>\"\"\"</code> in order to allow us to use multiple lines for the PromptTask string.</p> <pre><code>end_task = PromptTask(\"\"\"\n    How are these movies the same:\n    {{ parent_outputs['movie_1'] }}\n    {{ parent_outputs['movie_2'] }}\n    \"\"\",\nid=\"compare\")\n</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#test_1","title":"Test","text":"<p>When you run the script now, you should see a much better Input:</p> <pre><code>[11/15/23 14:19:24] INFO     PromptTask END        Input:                                                                                             How are these movies the same:                                                                 This could be referring to \"E.T. the Extra-Terrestrial\" directed by Steven Spielberg.          This could be referring to several movies as shark attacks are a common theme in films.        However, the most iconic movie featuring a shark attack on a beach is \"Jaws\" directed by Steven    Spielberg.                                                                                         [11/15/23 14:19:26] INFO     PromptTask END\n                             Output: These movies are the same in that they are both directed by Steven Spielberg.\n</code></pre> <p>The code works but it's if you look closely at the <code>END</code> task input, you'll see that it's using the full string of the response from the prompts:</p> <pre><code>How are these movies the same:                                                    That sounds like the movie \"E.T. the Extra-Terrestrial\".                          That could be several movies, but the most famous one is probably \"Jaws\". </code></pre> <p>What we really want is just the name of the movie, not any commentary. We can fix that by adjusting the prompt in the initial query.</p>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#fix-the-prompt","title":"Fix the Prompt","text":"<p>Change the movie PromptTasks so we ask for just the name: <pre><code>movie_1_task = PromptTask(\n\"What movie is this? Return only the movie name: A boy discovers an alien in his back yard\", \nid=\"movie_1\")\nmovie_2_task = PromptTask(\n\"What movie is this? Return only the movie name: a shark attacks a beach.\", \nid=\"movie_2\")\n</code></pre></p> <p>After running the response input task should be much cleaner:</p> <pre><code>How are these movies the same: E.T. the Extra-Terrestrial                  Jaws   </code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#code-review","title":"Code Review","text":"<p>We covered quite a lot of ground creating your first workflow. Double-check your script and make sure you've got it working as expected:</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask\nload_dotenv() \n# Create the workflow object\nworkflow = Workflow()\n# Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\nend_task = PromptTask(\n\"\"\"\n    How are these movies the same: \n    {{ parent_outputs['movie_1'] }}\n    {{ parent_outputs['movie_2'] }}\n    \"\"\",\nid=\"END\",\n)\n# Create movie tasks\nmovie_1_task = PromptTask(\n\"What movie is this? Return only the movie name: A boy discovers an alien in his back yard\",\nid=\"movie_1\",\n)\nmovie_2_task = PromptTask(\n\"What movie is this? Return only the movie name: a shark attacks a beach.\",\nid=\"movie_2\",\n)\n# Add tasks to workflow\nworkflow.add_task(start_task)\nworkflow.add_task(end_task)\n# Add tasks to workflow\nworkflow.insert_tasks(start_task, [movie_1_task, movie_2_task], end_task)\n# Run the workflow\nworkflow.run()\n</code></pre>"},{"location":"courses/compare-movies-workflow/03_first_workflow/#next-step","title":"Next Step","text":"<p>In the next section we are going to make our script a bit more flexible by making it possible to compare as many movie descriptions as we want. Check out Adding Flexibility when you're ready to continue.</p>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/","title":"Adding Flexibility","text":""},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#overview","title":"Overview","text":"<p>In the previous section you created your first workflow. It works well for two movie descriptions, however if you want to expand to more movies it could be a bit difficult for a few reasons.</p> <ol> <li>We're creating the tasks and adding them to the workflow one at a time.</li> <li>In the comparison task we target the specific ids of the movie tasks.</li> <li>We're repeating our prompt \"What movie is this? Return only the name\" over and over again.</li> </ol> <p>So in this section, we'll make our application more flexible by defining a list of movie descriptions, and then iterate through that list to create PromptTasks and add them to the workflow.</p>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#movie-description-list","title":"Movie Description List","text":"<p>Locate the section of your code where you create the list of movie tasks: <pre><code># ...\n# Create movie tasks\nmovie_1_task = PromptTask(\n\"What movie is this? Return only the movie name: A boy discovers an alien in his back yard\", \nid=\"movie_1\")\nmovie_2_task = PromptTask(\n\"What movie is this? Return only the movie name: a shark attacks a beach.\", \nid=\"movie_2\")\n# ...\n</code></pre></p> <p>We're going to replace this entire section with a <code>descriptions</code> list instead. This will be a list of python dictionaries with an \"id\" and a \"descriptoin\".</p> <p>It should look something like: <pre><code># Create a list of movie descriptions\nmovie_descriptions = [\n\"A boy discovers an alien in his back yard\",\n\"A shark attacks a beach\"\n]\n</code></pre></p>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#iterate-through-list","title":"Iterate through list","text":"<p>Now to create our PromptTasks, we'll iterate through the list of movie_descriptions.</p> <p>Locate the <code>insert_task</code> code where we inserted the tasks into the workflow:</p> <pre><code># Add tasks to workflow\nworkflow.insert_tasks(start_task, [movie_1_task, movie_2_task], end_task)\n</code></pre> <p>We will replace this with a for loop where we create the PromptTask then insert it.</p> <pre><code># ...\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }}\",\ncontext = {\n\"description\": description\n})\nworkflow.insert_tasks(start_task, [movie_task], end_task)\n# ...\n</code></pre> <p>As you can see, we:</p> <ol> <li>Iterate through each <code>description</code> in the list of <code>movie_descriptions</code>. </li> <li>Create a <code>PromptTask</code> and pass that <code>description</code> to the <code>context</code> into a variable also called <code>description</code>.</li> <li>Use that variable via Jinja2 templates in the prompt itself: <code>{{ description }}</code>.</li> <li>Once the <code>PromptTask</code> is created, we insert it to the workflow using the <code>insert_tasks</code> method.</li> </ol>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#update-end-task","title":"Update End Task","text":"<p>There's one final step we need to take before we can run this. In our <code>end_task</code>, we're specifically identifying <code>movie_1</code> and <code>movie_2</code> in the prompt:</p> <pre><code>end_task = PromptTask(\"\"\"\n    How are these movies the same:\n    {{parent_outputs['movie_1']}}\n    {{parent_outputs['movie_2']}}\n    \"\"\",\nid=\"compare\")\n</code></pre> <p>This will no longer work because we are not defining the ids when we create the PromptTask - we just let it come up with it's own unique identifiers. Also, we don't know exactly how many movies we might be comparing, so it doesn't make much sense to define and add each one individually.</p> <p>Luckily, intead of specifically specifying the items via id, we can just say \"hey - give me all the input items\" using <code>{{ parent_outputs }}</code>. This will return the entire <code>python dictionary</code> of items that are input to the task.</p> <p>Replace the two lines:</p> <pre><code>    {{parent_outputs['movie_1']}}\n{{parent_outputs['movie_2']}}   \n</code></pre> <p>with:</p> <pre><code>    {{ parent_outputs }}\n</code></pre> <p>The <code>compare_task</code> section should now look like:</p> <pre><code>compare_task = PromptTask(\"\"\"\n    How are these movies the same:\n    {{ parent_outputs }}\n    \"\"\",\nid=\"compare\")\n</code></pre>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#test","title":"Test","text":"<p>Let's run the code and see what we get.</p> <pre><code>[08/13/23 10:08:28] INFO     Task compare                                                                                                                     Input:                                                               How are these movies the same:{'74bd46cfd17a4ccaa92308029b508751': 'E.T. the                  \n                             Extra-Terrestrial', '90ed4594b9af4ad9ac2fe45cd53c7889': 'Jaws'}                                                             [08/13/23 10:08:31] INFO     Task compare                                                                                                                     Output: Both 'E.T. the Extra-Terrestrial' and 'Jaws' are iconic movies directed by Steven Spielberg. They are known for their    memorable storylines and have had a significant impact on popular culture.                                                       </code></pre> <p>We get the proper output for our task - it compares ET and Jaws as we expect. But notice the input.</p> <pre><code>Input:                                                                                                                           How are these movies the same:                                                                                               {'74bd46cfd17a4ccaa92308029b508751': 'E.T. the Extra-Terrestrial', '90ed4594b9af4ad9ac2fe45cd53c7889': 'Jaws'}                                                             </code></pre> <p>Instead of passing just the names of the movies, it's passing the entire dictionary of items. It works but it's extra data. Don't worry, there's a way to clean this up using Jinja2 for loops.</p>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#iterate-through-item-values","title":"Iterate through item values","text":"<p>Jinja2 has a for loop structure that looks like: <pre><code>{% for value in list.values() %}\n{{ value }}\n{% endfor %}\n</code></pre></p> <p>We can use this inside our PromptTask to iterate through the items and just output the names.</p> <p>Replace the <code>{{ parent_outputs }}</code> section of the <code>PromptTask</code> with a for loop that will get the key/value pairs (id, movie name) and output just the value.</p> <p>Tip</p> <p>For Jinja2 to iterate through the values of dict, you need to use <code>parent_outputs.values()</code>.</p> <pre><code># ... \nend_task = PromptTask(\"\"\"\n    How are these movies the same:\n    {% for value in parent_outputs.values() %}\n    {{ value }}\n    {% endfor %}\n    \"\"\",\nid=\"END\")\n# ...\n</code></pre>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#test_1","title":"Test","text":"<p>Run the script again and let's see how it looks.</p> <pre><code>INFO     Task END\n            Input:\n                How are these movies the same:\n                E.T. the Extra-Terrestrial\n                Jaws\n</code></pre> <p>Much better. Go ahead and add a third movie to the structure and run it again. Everything should work as expected. I added \"A princess and a man named Wesley\" (from the movie The Princess Bride) and got the following result:</p> <p>Result</p> <p>All three movies, E.T. the Extra-Terrestrial, Jaws, and The Princess Bride, are iconic films   from the late 20th century. They all fall under the genre of adventure and have elements of fantasy.   Additionally, they have been highly influential in popular culture and have received critical acclaim.  </p>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#code-review","title":"Code Review","text":"<p>There was not as much work in this section, but we did cover some important concepts. </p> <ul> <li>We made our code more flexible by using a list of descriptions to create PromptTasks instead of creating them one at a time.</li> <li>We used a Jinja2 template for loop to iterate through each incoming item.</li> </ul> <p>Review your code with the current state to make sure everything is working as expected.</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape \nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask\n# Load environment variables\nload_dotenv()\n# Create a Workflow\nworkflow = Workflow()\n# Create a list of movie descriptions\nmovie_descriptions = [\n\"A boy discovers an alien in his back yard\",\n\"A shark attacks a beach\",\n\"A princess and a man named Wesley\"\n]\nend_task = PromptTask(\"\"\"\n    How are these movies the same:\n    {% for value in parent_outputs.values()%}\n    {{ value }}\n    {% endfor %}\n    \"\"\",\nid=\"END\")\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }} \",\ncontext={\"description\": description})\nworkflow.insert_tasks(start_task, [movie_task], end_task)\n# Run the workflow\nworkflow.run()\n</code></pre>"},{"location":"courses/compare-movies-workflow/04_adding_flexibility/#next-step","title":"Next Step","text":"<p>Our code works, but the descriptions of the movies aren't as detailed as they could be. It would be better if we could search the web for detailed information about the movies, and use those results for a more comprehensive comparison.</p> <p>In the next section we will add to our workflow by adding a ToolkitTask that uses the <code>WebScraper</code> tool to get more detailed information. Jump to Using Tools when you're ready to continue.</p>"},{"location":"courses/compare-movies-workflow/05_using_tools/","title":"Using Tools","text":""},{"location":"courses/compare-movies-workflow/05_using_tools/#overview","title":"Overview","text":"<p>We added flexibility in the last section to allow our application to handle an undefined number of movies. The workflow hierarchy looks like:</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        I(\"PromptTask: End\"):::main\n        A --&gt; B --&gt; I\n        A --&gt; G --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n</code></pre> <p>However, the comparisons coming back don't feel very deep and meaningful. We'd like to get a more detailed analysis of the film comparisons by getting a better summary of each film from the web. </p> <p>To do that we'll use add a <code>ToolkitTask</code> to our workflow for each movie. This will result in the following chart.</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        C(\"ToolkitTask: Summary Task 1\"):::tool\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        H(\"ToolkitTask: Summary Task &lt;i&gt;n&lt;/i&gt;\" ):::tool-dash\n        I(\"PromptTask: End\"):::main\n        A --&gt; B --&gt; C --&gt; I\n        A --&gt; G --&gt; H --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5</code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#import","title":"Import","text":"<p>The three new classes we'll need to import are <code>ToolkitTask</code>, <code>TaskMemoryClient</code>, and <code>WebScraper</code>.</p> <p>ToolkitTask is a task just like PromptTask, except it allows you to specify the use of Tools. </p> <p>TaskMemoryClient is a way to handle data used in a task. It allows you to control where information is sent, keeping it off-prompt and away from the LLM when required. Note: in this course we'll be setting <code>off-prompt</code> to <code>False</code>, allowing the LLM to see the task results. In future courses we'll discuss ways to keep the data private.</p> <p>WebScraper is a specific tool that allows the LLM to scrape the web for information. We'll use this to get a better summary of each movie.</p> <p>In the top of your application, modify the import statements to include ToolkitTask, TaskMemoryClient, and WebScraper.</p> <pre><code>from dotenv import load_dotenv\n# Griptape \nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask, ToolkitTask\nfrom griptape.tools import WebScraper, TaskMemoryClient\n</code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#summary-toolkittask","title":"Summary ToolkitTask","text":"<p>Now we'll add the <code>ToolkitTask</code> to the section of our code where we iterate through each movie description.</p> <p>We will call it the same way we do PromptTask, except the ToolkitTask takes a list of tools. In this example, you can see that it's using two tools - WebScraper and TaskMemoryClient</p> <pre><code>summary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ }}\", \ntools = [WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\n</code></pre> <p>When we call the <code>ToolkitTask</code> we'll need to pass the output of the previous task (the movie_task) to it. There are a few options we can use to do this, depending on the needs of our application.</p>"},{"location":"courses/compare-movies-workflow/05_using_tools/#option-1-all-incoming-items","title":"Option 1: All Incoming Items","text":"<p>If you recall from the previous section, using the Jinja Template <code>{{ parent_outputs }}</code> will give you a list of dicts from all incoming tasks. </p> <p>Example:  <pre><code>    \"Use metacritic to get a summary of this movie: {{ parent_outputs }}\"\n</code></pre></p> <p>In this case, the return would look something like: <pre><code>Input: Get a summary of the movie: {'4aca083cdc5a4b76bb7ee7b91f0ec358': 'The Princess Bride'}                                                                       \n</code></pre></p> <p>While this works, it does provide some extraneous information. We know that there is only one item coming in - so it's not necessary to use this list of dicts. Jinja2 provides filters to reduce this.</p>"},{"location":"courses/compare-movies-workflow/05_using_tools/#option-2-filter-for-one-item","title":"Option 2: Filter for One Item","text":"<p>Jinja2 allows you to use filters to return specific information. The format with Jinja2 is to use a <code>|</code> notation to add a filter.</p> <p>For example, we can use <code>{{ parent_outputs.values() | list }}</code>to return a <code>list</code> of values, and then also get just the <code>last</code> item in the list. That would look like: <code>{{ parent_outputs.values()|list|last }}</code>:</p> <pre><code>    \"Use metacritic to get a summary of this movie: {{ parent_outputs.values()|list|last }}\"\n</code></pre> <p>And the result would be:</p> <pre><code>Input: Get a summary of the movie: The Princess Bride                      </code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#compare-all-options","title":"Compare all options","text":"<p>As you can see, there are multiple ways to get the result we're looking for. Review the options below to see how they are unique. </p> All ItemsFilter For One <pre><code># code\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\n# result\n{'4aca083cdc5a4b76bb7ee7b91f0ec358': 'The Princess Bride'} \n</code></pre> <pre><code># code\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs.values()|list|last }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\n# result\nThe Princess Bride\n</code></pre> <p>As you can see, Jinja filters are extremely powerful. Let's use the second option as it gives us exactly the result we are looking for: just the name of the movie.</p>"},{"location":"courses/compare-movies-workflow/05_using_tools/#add-toolkittask","title":"Add ToolkitTask","text":"<p>Inside the <code>for description in movie_descriptions:</code> loop, add the <code>summary_task</code> after the <code>movie_task</code> but before the call to the <code>insert_tasks</code> method of <code>workflow.</code></p> <pre><code># ...\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }} \",\ncontext={\"description\": description})\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs.values()|list|last  }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\nworkflow.insert_tasks(start_task, [movie_task], end_task)\n# ...\n</code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#insert-summary-task","title":"Insert Summary Task","text":"<p>At the moment we've created the Summary Task for each movie, but we haven't inserted them into the workflow.</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        C(\"ToolkitTask: Summary Task 1\"):::tool\n        H(\"ToolkitTask: Summary Task &lt;i&gt;n&lt;/i&gt;\" ):::tool-dash\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        I(\"PromptTask: End\"):::main\n        A --&gt; B --&gt; I\n        A --&gt; G --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5</code></pre> <p>To insert them, we'll need to use another <code>insert_tasks</code> method call, this time telling it to insert between the <code>movie_task</code> and the <code>end_task</code>.</p> <p>Inside the <code>movie_description</code> for loop, after <code>workflow.insert_tasks(start_task, [movie_task], end_task)</code> modify the code to look like:</p> <pre><code># ...\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\n# ...\nworkflow.insert_tasks(start_task, [movie_task], end_task)\nworkflow.insert_tasks(movie_task, [summary_task], end_task)\n# ...\n</code></pre> <p>Now the workflow graph looks like we expect:</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        C(\"ToolkitTask: Summary Task 1\"):::tool\n        H(\"ToolkitTask: Summary Task &lt;i&gt;n&lt;/i&gt;\" ):::tool-dash\n        I(\"PromptTask: End\"):::main\n        A --&gt; B --&gt; C --&gt; I\n        A --&gt; G --&gt; H --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5</code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#test","title":"Test","text":"<p>Execute the code and let's review the output logs.</p> <p>Note</p> <p>I've removed the timestamps from the logs to make it easier to read. Yours will most likely still have them.</p> <pre><code>INFO Task END                                  Input:                                                                                                  How are these movies the same:                                                                      The movie \"E.T. the Extra-Terrestrial\" is about a troubled child who summons the courage to help a  friendly alien escape from Earth and return to his home planet.                                         \"Jaws\" is a movie about a killer shark that unleashes chaos on a beach community off Cape Cod. It's \n    up to a local sheriff, a marine biologist, and an old seafarer to hunt the beast down. The shark        \n    terrorizes the community, affecting the number of tourists that usually flock to the island. After many \n    attempts, the shark won't go away, leading the sheriff, the marine biologist, and the seafarer to decide\n    to go after the shark and kill it.                                                                      The movie \"The Princess Bride\" is about a bedridden boy's grandfather who reads him the story of a  farmboy-turned-pirate. This farmboy encounters numerous obstacles, enemies, and allies in his quest to  be reunited with his true love. The movie is known for its satirical humor, great dialogue, and fun     adventure scenes. It is whimsical and romantic while also poking fun at the conventions of the fairy    tale genre. INFO Task END                                  Output: While these three movies, \"E.T. the Extra-Terrestrial\", \"Jaws\", and \"The Princess Bride\", seem  very different in terms of plot and genre, they do share some similarities. All three films involve a   central conflict that requires the main characters to overcome significant challenges. In \"E.T.\", the   child must help the alien return home, in \"Jaws\", the characters must hunt down a dangerous shark, and  in \"The Princess Bride\", the farmboy-turned-pirate must overcome obstacles to reunite with his love.    Each movie also explores themes of courage, friendship, and determination. Furthermore, they are all    iconic films that have left a significant impact on popular culture.                                    </code></pre> <p>As you can see, the <code>END</code> task has a lot more detail in it now. We're getting great summaries of the films, and therefore the output is even more detailed and valuable.</p> <p>Experiment</p> <p>You could enhance this output by providing more detail to the prompt compare prompt. For example, instead of just asking how they're the same, some options:</p> <ul> <li>\"Act as a movie critic. Why are these movies relevant to society?\"</li> <li>\"Act as a film studies professor. What are common themes in these movies?\"</li> </ul> <p>Hot Tip</p> <p>Instead of modifying the prompt, try using Rules and Rulesets to give your workflow more specific behavior.</p> <p>You can learn about Rulesets in the Multi Persona Chatbot course. </p>"},{"location":"courses/compare-movies-workflow/05_using_tools/#code-review","title":"Code Review","text":"<p>We added some of helpful functionality in this section, mainly getting wonderful descriptions of these films from the web by using the <code>WebScraper</code> tool and <code>ToolkitTasks</code>.</p> <p>Review your code.</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask, ToolkitTask\nfrom griptape.tools import WebScraper, TaskMemoryClient\nload_dotenv()\n# Create the workflow object\nworkflow = Workflow()\n# Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\nend_task = PromptTask(\n\"\"\"\n    How are these movies the same:\n     {% for value in parent_outputs.values() %} \n     {{ value }}\n     {% endfor %}\n    \"\"\",\nid=\"END\",\n)\n# Create a list of movie descriptions\nmovie_descriptions = [\n\"A boy discovers an alien in his back yard\",\n\"A shark attacks a beach\",\n\"A princess and a man named Wesley\",\n]\n# Add tasks to workflow\nworkflow.add_task(start_task)\nworkflow.add_task(end_task)\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }}\",\ncontext={\"description\": description},\n)\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs.values() | list |last }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\nworkflow.insert_tasks(start_task, [movie_task], end_task)\nworkflow.insert_tasks(movie_task, [summary_task], end_task)\n# Run the workflow\nworkflow.run()\n</code></pre>"},{"location":"courses/compare-movies-workflow/05_using_tools/#next-step","title":"Next Step","text":"<p>Congratulations, we've got a working movie comparison application! We can add a list of movies to compare, and the result is a detailed comparison that provides valuable insight as to how these movies can impact society.</p> <p>However, we're currently only viewing the results in the logs. If we want to use this data inside an application, we need to get the output of the workflow.</p> <p>In the next section, we'll learn how Workflows handle the output of their tasks and grab just the value of the summary task. Saunter over to Workflow Outputs when you're ready.</p>"},{"location":"courses/compare-movies-workflow/06_workflow_outputs/","title":"Workflow Outputs","text":""},{"location":"courses/compare-movies-workflow/06_workflow_outputs/#overview","title":"Overview","text":"<p>In the previous section we added a <code>ToolkitTask</code> that used the <code>WebScraper</code> and <code>TaskMemoryClient</code> tools to get detailed information about the movies presented.</p> <p>In this section, we'll add the ability to get the <code>output</code> from the <code>workflow</code> in order to integrate it with whatever application we may be building.</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        C(\"ToolkitTask: Summary Task 1\"):::tool\n        H(\"ToolkitTask: Summary Task &lt;i&gt;n&lt;/i&gt;\" ):::tool-dash\n        I(\"PromptTask: End\"):::main\n        J([\"\\n  Incredible movie insights. \\n\\n\"]):::output\n        A --&gt; B --&gt; C --&gt; I --&gt; J\n        A --&gt; G --&gt; H --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5\n    classDef output fill:#333,stroke:#555\n</code></pre>"},{"location":"courses/compare-movies-workflow/06_workflow_outputs/#workflow-output_task","title":"Workflow Output_Task","text":"<p>Looking at our current workflow, you can see that there's one last task - the <code>End</code> task. Ideally we can run the workflow and get the output of this last task.</p> <p>Every task in Griptape has an attribute on it called <code>output_task</code>. If you took the Converational Chatbot course, you would have seen it when customizing the output of the agent.</p> <p>We can use this <code>output_task</code> of the <code>workflow</code> to get the final output value.</p> <pre><code>#...\n# Run the workflow\nworkflow.run()     \nprint(workflow.output_task.output.value)\n</code></pre>"},{"location":"courses/compare-movies-workflow/06_workflow_outputs/#test","title":"Test","text":"<p>Execute the code and let's review the output.</p> <pre><code>While these movies - \"E.T. the Extra-Terrestrial\", \"Jaws\", \nand \"The Princess Bride\" - have different plots and settings, \nthey share some common elements. All three films involve \ncharacters facing significant challenges and overcoming them. \nThey also all involve elements of adventure and suspense. \nAdditionally, they were all released in the 20th century and \nhave become iconic films in American cinema.\n</code></pre>"},{"location":"courses/compare-movies-workflow/06_workflow_outputs/#code-review","title":"Code Review","text":"<p>In this final section we learned out to get the <code>output</code> from the <code>workflow</code> in order to be able to integrate this workflow into our application.</p> <p>Review your code.</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Workflow\nfrom griptape.tasks import PromptTask, ToolkitTask\nfrom griptape.tools import WebScraper, TaskMemoryClient\nload_dotenv()\n# Create the workflow object\nworkflow = Workflow()\n# Create tasks\nstart_task = PromptTask(\"I will provide you a list of movies to compare.\", id=\"START\")\nend_task = PromptTask(\n\"\"\"\n    How are these movies the same:\n     {% for value in parent_outputs.values() %} \n     {{ value }}\n     {% endfor %}\n    \"\"\",\nid=\"END\",\n)\n# Create a list of movie descriptions\nmovie_descriptions = [\n\"A boy discovers an alien in his back yard\",\n\"A shark attacks a beach\",\n\"A princess and a man named Wesley\",\n]\n# Add tasks to workflow\nworkflow.add_task(start_task)\nworkflow.add_task(end_task)\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }}\",\ncontext={\"description\": description},\n)\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs.values() | list |last }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\n)\nworkflow.insert_tasks(start_task, [movie_task], end_task)\nworkflow.insert_tasks(movie_task, [summary_task], end_task)\n# Run the workflow\nworkflow.run()\n# View the output\nprint(workflow.output_task.output.value)\n</code></pre>"},{"location":"courses/compare-movies-workflow/06_workflow_outputs/#next-step","title":"Next Step","text":"<p>But wait.. don't stop yet!</p> <p>There's new bonus material we've recently added that helps you understand the structure of your workflow!</p> <p>Head over to the next section: Workflow Display Graphs to learn how to understand the structure of your graph while you create it.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/","title":"Workflow Displaying the Graph","text":""},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#overview","title":"Overview","text":"<p>Throughout the course you've been creating Workflows by adding and inserting various tasks.</p> <p>We've been displaying those workflow structures in this documentation by using the extremely helpful Mermaid javascript libray.</p> <pre><code>graph TB \n    subgraph \" \"\n        direction TB\n        A(\"PromptTask: Start\"):::main \n        B(\"PromptTask: Movie Task 1\")\n        G(\"PromptTask: Movie Task &lt;i&gt;n&lt;/i&gt;\" ):::dash\n        C(\"ToolkitTask: Summary Task 1\"):::tool\n        H(\"ToolkitTask: Summary Task &lt;i&gt;n&lt;/i&gt;\" ):::tool-dash\n        I(\"PromptTask: End\"):::main\n        J([\"\\n  Incredible movie insights. \\n\\n\"]):::output\n        A --&gt; B --&gt; C --&gt; I --&gt; J\n        A --&gt; G --&gt; H --&gt; I\n    end\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5\n    classDef output fill:#333,stroke:#555\n</code></pre> <p>While this is handy to help visualize Workflows while we discuss them, it would certainly be helpful to be able to get a better understanding of Workflows while you create them.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#the-to_graph-method","title":"The to_graph method","text":"<p>The Workflow class has a method on it called <code>to_graph</code>. This method outputs the graph you created as a Python dict.</p> <p>Let's modify our code slightly to print out the dictionary.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#displaying-the-graph","title":"Displaying the graph","text":""},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#import-rich-rprint","title":"Import rich rprint","text":"<p>Since we're going to be printing a dict, it would be nice to make it relatively easy to read. We can use the <code>rich</code> library's <code>rprint</code> function to do this.</p> <p>At the top of your script, add the following import statement: <pre><code>from dotenv import load_dotenv\nfrom rich import print as rprint\n# ...\n</code></pre></p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#comment-out-workflowrun","title":"Comment out workflow.run()","text":"<p>In order to see the graph hierarchy, you don't need to run the workflow. So let's temporarily comment it out in our code. Find the <code>workflow.run()</code> line at the bottom of your script and comment it out.</p> <pre><code># ...\n# Run the workflow\n# workflow.run()\n</code></pre>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#use-the-to_graph-method","title":"Use the to_graph method","text":"<p>After the commented out <code>workflow.run()</code> line, add the following lines:</p> <pre><code># ...\n# workflow.run()\n# use the to_graph method to return the graph\ngraph = workflow.to_graph()\n# print the graph\nrprint(graph)\n</code></pre>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#test","title":"Test","text":"<p>Run your code to see the result. It should look something like: <pre><code>{\n'START': set(),\n    '31d300f8678c41f7ad31ff62cc58d95a': {'START'},\n    '4072265abb64464f816fd15383c82020': {'31d300f8678c41f7ad31ff62cc58d95a'},\n    'aea3bb1b14d74298bf32fa91e9ad2815': {'START'},\n    '8549fa7954014b0eb13099a6a0612517': {'aea3bb1b14d74298bf32fa91e9ad2815'},\n    'acf4926d80f14a0f84d813ceef1ff3c0': {'START'},\n    '7224e9aef92e40728828d7e9a2304ef2': {'acf4926d80f14a0f84d813ceef1ff3c0'},\n    'END': {'7224e9aef92e40728828d7e9a2304ef2', '8549fa7954014b0eb13099a6a0612517', '4072265abb64464f816fd15383c82020'}\n}\n</code></pre></p> <p>Now this probably isn't what you were expecting - it's not super clear what the node hierarchy is, and those numbers don't give a lot of context.</p> <p>Essentially what you're looking at is a list of <code>task ids</code> and their <code>parent task ids</code>.</p> <p>For example, this line: <code>'acf4926d80f14a0f84d813ceef1ff3c0': {'START'},</code> says that the Task with id <code>acf4926d80f14a0f84d813ceef1ff3c0</code> has a parent of the  task with the id <code>START</code>.</p> <p>Notice the <code>END</code> task has 3 nodes that are it's parent: <code>'7224e9aef92e40728828d7e9a2304ef2', '8549fa7954014b0eb13099a6a0612517', '4072265abb64464f816fd15383c82020'</code>.</p> <p>Still not making sense? That's okay, let's clean up these task id names and things will become a little clearer.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#clean-up-the-node-ids","title":"Clean up the node IDs","text":"<p>The first thing we'll want to do is make sure that each Task has a unique ID that's a litte clearer to understand. This means we'll be adding an <code>id</code> attribute to the <code>movie_task</code> and the <code>summary_task</code>.</p> <p>Find the section of the code where we create the <code>movie_task</code>. We're going to add an <code>id</code> attribute to it. However, we can't just give it a value of \"movie_task\" - or each movie PromptTask will have the same id. This is not allowed with Workflows - each task needs to be unique.</p> <p>We could label the tasks something like \"movie_task_1\", \"movie_task_2\", etc.. but it might be nicer to make it a little clearer what each one does.</p> <p>So what if we used a bit of the description to describe the task? Something like:</p> <ul> <li><code>TITLE: A princes...</code></li> <li><code>TITLE: A shark at...</code></li> </ul> <p>So we can tell just by glancing at what each task represents.</p> <pre><code># ...\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\nmovie_task = PromptTask(\n\"What movie title is this? Return only the movie name: {{ description }}\",\ncontext={\"description\": description},\nid=f\"TITLE: {description[:10]}..\", # Use the first 10 characters of the description\n)\n# ...\n</code></pre> <p>Execute that and look at the result:</p> <pre><code>{\n'START': set(),\n    'TITLE: A princess...': {'START'},\n    'c9ce1d1f7da54fa299dba9a84ebe7ccb': {'TITLE: A princess...'},\n    'TITLE: A shark at...': {'START'},\n    '69c2b414649d42e690a505981ef4979f': {'TITLE: A shark at...'},\n    'TITLE: A boy disc...': {'START'},\n    '08ef43cfda28416c91fedf2d3b43cdd5': {'TITLE: A boy disc...'},\n    'END': {'c9ce1d1f7da54fa299dba9a84ebe7ccb', '69c2b414649d42e690a505981ef4979f', '08ef43cfda28416c91fedf2d3b43cdd5'}\n}\n</code></pre> <p>Notice how it's a little easier to understand? Let's do the same for the <code>summary_task</code>. Modify that ToolkitTask to have an id as well, and this time use the same description so we can see how the tasks are related:</p> <pre><code># ...\n# Iterate through the movie descriptions\nfor description in movie_descriptions:\n# ...\nsummary_task = ToolkitTask(\n\"Use metacritic to get a summary of this movie: {{ parent_outputs.values() | list |last }}\",\ntools=[WebScraper(), TaskMemoryClient(off_prompt=False)],\nid=f\"SUMMARY: {description[:10]}...\"\n)\n# ...\n</code></pre> <p>The results are definitely clearer:</p> <pre><code>{\n'START': set(),\n    'TITLE: A princess...': {'START'},\n    'SUMMARY: A princess...': {'TITLE: A princess...'},\n    'TITLE: A shark at...': {'START'},\n    'SUMMARY: A shark at...': {'TITLE: A shark at...'},\n    'TITLE: A boy disc...': {'START'},\n    'SUMMARY: A boy disc...': {'TITLE: A boy disc...'},\n    'END': {'SUMMARY: A boy disc...', 'SUMMARY: A shark at...', 'SUMMARY: A princess...'}\n}\n</code></pre> <p>So looking at this, you can see that <code>START</code> is the first item because it has no parents (identified with: <code>set()</code>).</p> <p>The three <code>TITLE: ...</code> tasks are a parent of <code>START</code> and the <code>SUMMARY</code> tasks are children of their respective <code>TITLE</code> tasks.</p> <p>The <code>END</code> task has 3 parents - the <code>SUMMARY</code> tasks.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#display-with-nodes","title":"Display with nodes","text":"<p>This is fine for quick cases, but wouldn't it be better if you could actually display the graph in an easier to read way - similar to how we're using mermaid.js in this course?</p> <p>That's exactly what we're going to do. We'll create a utility we can use on Workflows to display the nodes just like we would with mermaid.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#create-a-display_graphpy-file","title":"Create a display_graph.py file","text":"<p>Save the following Python file as <code>display_graph.py</code> in the same directory as your <code>app.py</code>.</p> <pre><code>\"\"\"\nMermaid Graph Display Utility\nThis utility allows for the visualization of Workflow Graphs\nusing Mermaid.js. It generates an HTML page with a Mermaid graph based on a\ngiven graph data structure and opens it in the default web browser.\nUsage:\n    from display_graph import display_graph\n    display_graph(your_data)\nRequirements:\n    - Internet connection for Mermaid.js CDN.\n    - A web browser to view the generated graph.\nAuthor: jason@griptape.ai\nDate: Nov 15, 2023\nVersion: 1.0\n\"\"\"\nimport webbrowser\nimport os\nimport string\nfrom typing import Dict, Set\n# Create unique identifiers for each node in the graph\ndef generate_identifiers(nodes):\nid_generator = iter(string.ascii_uppercase)\nreturn {node: next(id_generator) for node in nodes}\n# Convert the graph data to mermaid format\ndef convert_to_mermaid(data: Dict[str, Set[str]], identifiers: Dict[str, str]) -&gt; str:\nmermaid_graph = \"graph TD\\n\"\nfor child, parents in data.items():\nchild_id = identifiers[child]\nif not parents:\nmermaid_graph += f'    {child_id}(\"{child}\")\\n'\nfor parent in parents:\nparent_id = identifiers[parent]\nmermaid_graph += f'    {parent_id}(\"{parent}\") --&gt; {child_id}(\"{child}\")\\n'\nreturn mermaid_graph\n# Create the HTML content for the graph\ndef html_content(mermaid_graph: str) -&gt; str:\nreturn f\"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Mermaid Graph&lt;/title&gt;\n        &lt;script src=\"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\"&gt;&lt;/script&gt;\n        &lt;script&gt;mermaid.initialize({{ theme: 'dark', startOnLoad: true }});&lt;/script&gt;\n        &lt;style&gt;\n            body {{\n        background-color: rgb(30, 33, 41);\n        color: rgba(226, 228, 233, 0.82);\n}}\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div class=\"mermaid\"&gt;\n{mermaid_graph}\n        &lt;/div&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n# Display the graph in a web browser\ndef display_graph(data: Dict[str, Set[str]]):\nidentifiers = generate_identifiers(data.keys())\nmermaid_graph = convert_to_mermaid(data, identifiers)\nfile_path = \"graph.html\"\nwith open(file_path, \"w\") as file:\nfile.write(html_content(mermaid_graph))\nwebbrowser.open(\"file://\" + os.path.realpath(file_path))\n</code></pre>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#use-display_graph-to-display-your-workflow-graph","title":"Use display_graph to display your workflow graph","text":"<p>Inside your <code>app.py</code>, you will need to first <code>import</code> the <code>display_graph</code> function.</p> <p>At the top of your script, add the following import: <pre><code>from display_graph import display_graph\n</code></pre></p> <p>Now at the bottom of your script, instead of using <code>rprint</code> to print out your graph, use <code>display_graph</code></p> <pre><code># ...\n# workflow.run()\n# use the to_graph method to return the graph\ngraph = workflow.to_graph()\n# print the graph\ndisplay_graph(graph)\n</code></pre> <p>Execute your script and you should see an html page appear with your graph!</p> <p></p> <p>Feel free to use this any time you need to quickly display your graph as it's being built.</p>"},{"location":"courses/compare-movies-workflow/07_workflow_display_graph/#finished","title":"Finished","text":"<p>Success</p> <p>Congratulations! You have created a successful Griptape Workflow!</p> <p>Well done, you've successfully created a Griptape Workflow that allows you to execute complex and interesting dependency graphs.</p> <p>You have learned how to:</p> <ul> <li>Create tasks that can handle prompts and tools.</li> <li>Learned a bit about Jinja2 templates.</li> <li>Create parent/child relationships.</li> <li>Create tasks that are depending on multiple incoming tasks.</li> <li>Get the output from a workflow for integration with other applications.</li> <li>Understand the graph being created by displaying it with various methods.</li> </ul> <p>We hope you enjoyed this course, and look forward to seeing what you're able to create with these new skills.</p>"},{"location":"courses/create-image-pipeline/","title":"Image Generation Pipeline","text":""},{"location":"courses/create-image-pipeline/#course-description","title":"Course Description","text":"<pre><code>graph TB\n    direction TB\n    AA([\"\\n INPUT \\n\\n\"]):::output\n    B(\"Prompt Task\")\n    C(\"Image Generation Task\"):::tool\n    I(\"View Image Task\"):::main\n    AA --&gt; B --&gt; C --&gt; I\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5\n    classDef output fill:#5552,stroke:#555\n</code></pre> <p>Welcome to our course on Griptape Pipelines, where we'll be exploring this powerful feature through the practical example of image generation. In this course, you'll learn how to use Griptape Pipelines to seamlessly link together various tasks to create a cohesive workflow.</p> <p>Our focus will be on how to set up a pipeline that can take a concept, apply a specific style, and incorporate a description to generate an image. Plus, we'll show you how to create a Griptape Tool to display the image after it's created.</p> <p>This course is designed to be approachable and informative, ideal for anyone looking to understand the fundamentals of Griptape Pipelines. Whether you're a developer, a hobbyist, or just curious about how pipelines can enhance your projects, this course will provide you with the practical skills and knowledge needed to get started. So let's jump in and explore the exciting possibilities that Griptape Pipelines have to offer!</p>"},{"location":"courses/create-image-pipeline/#who-is-this-course-for","title":"Who is this course for","text":"<p>This course is aimed at intermediate level Python developers who are interested in learning about Griptape Pipelines and how to handle parent/child task relationships, Griptape Tools, and image generation. </p>"},{"location":"courses/create-image-pipeline/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this course, you will need:</p> <ul> <li>An OpenAI API Key (available here: OpenAI)</li> <li>Python3.9+ installed on your machine</li> <li>An IDE (such as Visual Studio Code or PyCharm) to write and manage your code</li> </ul> <p>If you don't have those items available, it's highly recommended you go through the Griptape Setup - Visual Studio Code course to set up your environment.</p> <p>It's also recommended to view the Compare Movies Workflow course if you haven't viewed it before, as it contains some similar concepts to the Pipeline course.</p>"},{"location":"courses/create-image-pipeline/#image-generation-engines","title":"Image Generation Engines","text":"<p>The course will cover some of the Image Generation Engines available for Griptape, including OpenAI DALL\u00b7E 3, Leonardo.AI, and Image Generation Engines running on Amazon Bedrock </p>"},{"location":"courses/create-image-pipeline/#dalle-3","title":"DALL\u00b7E 3","text":"<ul> <li>DALL\u00b7E 3 is available with an OpenAI API key.</li> </ul>"},{"location":"courses/create-image-pipeline/#leonardoai","title":"Leonardo.ai","text":"<ul> <li>Sign up for a Leonardo.Ai account</li> <li>Save your <code>LEONARDO_API_KEY</code> in your <code>.env</code> file.</li> </ul>"},{"location":"courses/create-image-pipeline/#amazon-bedrock","title":"Amazon Bedrock","text":"<ul> <li>Ensure you have an AWS account</li> <li>Ensure you have access to the appropriate model by following the Amazon Documentation</li> <li>Add the following environment variables to your <code>.env</code> file:<ul> <li><code>AWS_REGION_NAME</code></li> <li><code>AWS_ACCESS_KEY_ID</code></li> <li><code>AWS_SECRET_ACCESS_KEY</code></li> </ul> </li> </ul>"},{"location":"courses/create-image-pipeline/#course-outline","title":"Course Outline","text":"<p>The course will cover:</p> <ul> <li>Creating Griptape Pipelines</li> <li>Creating Griptape Tasks</li> <li>Investigate Image Generation Engines</li> <li>Building a Tool to display the resulting image</li> </ul>"},{"location":"courses/create-image-pipeline/#useful-resources-and-links","title":"Useful Resources and Links","text":"<ul> <li>Griptape Documentation</li> <li>Visual Studio Code</li> <li>Jinja2 Documentation</li> <li>Amazon Image Generation Documentation</li> <li>Leonardo.Ai</li> <li>Compare Movies Workflow</li> </ul>"},{"location":"courses/create-image-pipeline/#next-steps","title":"Next Steps","text":"<p>Get yourself all set up and ready by moving on to Setup.</p>"},{"location":"courses/create-image-pipeline/01_setup/","title":"Setup","text":"<p>As with any project, the first step is setting up your environment. Let's get started by ensuring you have a project structure ready to work with.</p> <p>Important</p> <p>Since this is an intermediate-level course, please ensure you've gone through the Griptape Setup course to set up your environment. We will be starting from the code at that point.</p>"},{"location":"courses/create-image-pipeline/01_setup/#create-a-project","title":"Create a Project","text":"<p>Following the instructions in Griptape Setup - Visual Studio Code  please:</p> <ol> <li>Create your project folder. Example: <code>griptape-image-pipeline</code></li> <li>Set up your virtual environment</li> <li>Ensure you <code>pip install griptape python-dotenv</code></li> <li> <p>Create a <code>.env</code> file with your <code>OPENAI_API_KEY</code></p> <p>Tip</p> <p>If you are using Leonardo.Ai or Stable Diffusion on Amazon Bedrock, be sure to set the appropriate environment variables in the <code>.env</code> file as well.</p> </li> <li> <p>Create your <code>app.py</code> file with the following code:</p> </li> </ol> app.py<pre><code>from dotenv import load_dotenv\nload_dotenv() # Load your environment\n</code></pre>"},{"location":"courses/create-image-pipeline/01_setup/#next-steps","title":"Next Steps","text":"<p>Your environment is all set up! In the next section, we will dive into the concepts of Griptape Pipelines.</p>"},{"location":"courses/create-image-pipeline/02_concepts/","title":"Main Concepts","text":""},{"location":"courses/create-image-pipeline/02_concepts/#understanding-pipelines-and-workflows","title":"Understanding Pipelines and Workflows","text":"<p>Pipelines and Workflows are both Griptape Structures that execute a series of tasks. </p>"},{"location":"courses/create-image-pipeline/02_concepts/#pipelines","title":"Pipelines","text":"<p>Pipelines are always a sequential series of steps - one task after another until it is finished. </p> <p>In this course, we're going to be taking a topic to draw, and then execute a consistent series of tasks until we have the image. Every time the Pipeline is run, it will always:</p> <ol> <li>Use an LLM to generate an Image Generation prompt.<ul> <li>If the input given is \"a butterfly\", the result of this task might be a text string \"Create a watercolor painting of a butterfly.\".</li> <li>This will allow us to ensure the output from this task will always be in the correct format for an Image Generation Engine.</li> </ul> </li> <li>Generate an image<ul> <li>Using the output from the previous step, we'll give that to an Image Generation Model</li> </ul> </li> <li>View the image<ul> <li>Once the image is generated, we'll want to do something with it. In this case, we can open the image to view it.</li> </ul> </li> </ol> <p>The flow of tasks will look like:</p> <pre><code>graph LR\n    A((Get Topic)) --&gt; B(Generate Prompt) --&gt; C(Generate Image) --&gt; D(Show Image)</code></pre>"},{"location":"courses/create-image-pipeline/02_concepts/#workflows","title":"Workflows","text":"<p>Workflows allow for complex interactions, resembling tree branches.</p> <p>Workflows are non-sequential, and individual tasks can depend on multiple input tasks. This allows you to create a single task that waits for all other tasks to complete before it can begin.</p> <p>If we wanted to generate multiple images, perhaps in different styles we'd be able to set up a workflow like the following:</p> <p>Note</p> <p>The graph is drawn top to bottom for this example because it's easier to understand the flow of data, but it can be drawn in either direction.</p> <pre><code>graph TB\n    A((Get Topic)) --&gt; B(Generate Prompt 1) --&gt; D(Generate Image 1) --&gt; I(Show Images)\n    A --&gt; E(Generate Prompt 2) --&gt; F(Generate Image 2) --&gt; I\n    A --&gt; G(\"Generate Prompt &lt;i&gt;n&lt;/i&gt;\" ):::dash\n    G --&gt; H(\"Generate Image &lt;i&gt;n&lt;/i&gt;\"):::dash \n    H --&gt; I\n    classDef dash stroke-dasharray: 5 5\n</code></pre> <p>Notice how the images can be generated in parallel, but the Show Images task will wait until all its parent tasks are completed. Workflows always require a start task and an end task.</p>"},{"location":"courses/create-image-pipeline/02_concepts/#tasks","title":"Tasks","text":"<p>Before we dive in and start setting up our own Pipeline, it's important to review the concepts of Tasks. With Griptape, there are many types of tasks you'll be working with, including:</p> Task Type Description Example PromptTask General purpose prompting to the LLM. <code>PromptTask(\"Tell me a story about skateboards\")</code> ToolkitTask Uses Griptape Tools to complete a task with Chain of Thought (CoT) reasoning. <code>ToolkitTask(\"Summarize griptape.ai\", tools=[WebScraper()])</code> TookTask Similar to ToolkitTask, but only uses a single tool and no CoT. <code>ToolTask(\"Give me the answer for 52-10\", tool=Calculator())</code> Extraction Tasks Various tasks associated with extracting information from text. See examples in the documentation. TextSummaryTask Summarizes text very efficiently <code>TextSummaryTask(\"Imagine this is a massive amount of text.\")</code> TextQueryTask Can be used to query large bodies of text, for example a vector database. See examples in the documentation ImageGenerationTask Can be used to generate images. <code>ImageGenerationTask(\"watercolor butterfly\"), image_generation_engine=image_engine</code> <p>In this course, we will be focusing mostly on Prompt Tasks, Toolkit Tasks, and Image Generation Tasks. </p> <pre><code># Example PromptTask to create a Image Generation Prompt\n#\nimage_prompt_task = PromptTask(\n\"Create a prompt for an image generation engine that will make a watercolor painting of: {{ topic }}\",\ncontext = {                        \n\"topic\": \"butterfly\" \n},\nid=\"image_prompt_task\"   # task id can be referenced by other tasks\n)\n# This Image Generation task works with the output of the parent task.\n#\nimage_generation_task = ImageGenerationTask(\n\"{{ parent_output }}\", # The output of the parent task\nimage_generation_engine=ImageGenerationEngine(\nimage_generation_driver=OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n),\n),\noutput_dir=\"./images\",\nid=\"image_generation_task\"\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/02_concepts/#next-steps","title":"Next Steps","text":"<p>Let's move on to the next section where we'll create our First Pipeline, and get an understanding of the basics of how parent/child relationships can work.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/","title":"First pipeline","text":""},{"location":"courses/create-image-pipeline/03_first_pipeline/#overview","title":"Overview","text":"<p>In this section, we're going to create a \"pseudocode\" pipeline for our image generation application. When finished you will have a pipeline that walks through each step of the image generation process, without actually generating an image. </p> <p>For example, if you pass the topic: \"a skateboard\"</p> <p>It will do the following steps:</p> <ol> <li>Take a topic as an input.</li> <li>Create an image generation prompt based on the topic in a particular style.</li> <li>Pretend to generate the image</li> <li>Pretend to display the image</li> </ol> <p>The pipeline we will create looks like the following:</p> <pre><code>graph TB\n    direction TB\n    AA([\"\\n INPUT \\n\\n\"]):::output\n    B(\"Prompt Task\")\n    C(\"Fake Image Generation Task\")\n    I(\"Fake View Image Task\")\n    AA --&gt; B --&gt; C --&gt; I\n\n    classDef main fill:#4274ff1a, stroke:#426eff\n    classDef dash stroke-dasharray: 5 5\n    classDef tool stroke:#f06090\n    classDef tool-dash stroke:#f06090,stroke-dasharray: 5 5\n    classDef output fill:#5552,stroke:#555\n</code></pre> <p>As you can see, there is a <code>Pipeline</code> Structure and three tasks that will be created. The two final \"Fake\" tasks will be replaced with real ones in future sections.</p> <p>To generate this structure, we create the Pipeline and then add tasks one at a time.</p> <p>Let's get started.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#importing-required-modules","title":"Importing Required Modules","text":"<p>Before starting, we need to import the necessary modules. Open the <code>app.py</code> file you created in the setup section and import the two Griptape classes you'll need: <code>Pipeline</code> and <code>PromptTask</code>:</p> <pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask\nload_dotenv() # Load your environment\n</code></pre> <p>Note</p> <p>You might recall that <code>Agent</code> was also imported through <code>griptape.structures</code>. That's because <code>Agent</code>, <code>Workflow</code>, and <code>Pipeline</code> are all Griptape's ways of working with LLMs. </p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#create-pipeline-structure","title":"Create Pipeline Structure","text":""},{"location":"courses/create-image-pipeline/03_first_pipeline/#initialize-the-pipeline","title":"Initialize the Pipeline","text":"<p>Now, let's create the foundation for our Pipeline. After the line <code>load_dotenv()</code>, create an instance of the Pipeline class:</p> <pre><code># ... truncated for brevity\nload_dotenv() # Load your environment\n# Create the pipeline object\npipeline = Pipeline()\n</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#create-our-first-task","title":"Create our first task","text":"<p>First, we'll create our \"create prompt\" task. This will be a <code>PromptTask</code> that tells the LLM to generate a prompt for an image generation model in a particular style.</p> <p>After the <code>pipeline</code> line, add:</p> <pre><code># ...\n# Create tasks\ncreate_prompt_task = PromptTask(\n\"\"\"\n    Create a prompt for an Image Generation pipeline for the following topic: \n    {{ args[0] }}\n    in the style of {{ style }}.\n    \"\"\",\ncontext = {\n\"style\": \"a 1970s polaroid\"\n},\nid=\"Create Prompt Task\")\n</code></pre> <p>Quite a few things are happening in this <code>PromptTask</code> generation that are important to point out.</p> <p>The initial prompt contains two variables that are being replaced in the text. <code>{{ args[0] }}</code> and <code>{{ style }}</code>.</p> <p>Tip</p> <p>Griptape uses the Jinja2 template engine, which allows you to insert data into the prompt. There's a lot of power available with Jinja templates, but in this course, we'll keep our focus rather small. Jinja templates access variables using the <code>{{ }}</code> syntax. Tasks can take advantage of this.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#understanding-args0","title":"Understanding <code>{{ args[0] }}</code>","text":"<p><code>{{ args[0] }}</code> will always be the initial input sent to the <code>Pipeline</code>. If we were to call the pipeline with:</p> <pre><code>```python\npipeline.run(\"cow\")\n```\n\nThe `{{ args[0] }}` would be replaced with \"cow\".\n</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#additional-context","title":"Additional context","text":"<p>The <code>context</code> argument allows you to pass more variables to the prompt. In this case, we used <code>{{ style }}</code> to specify \"a 1970s polaroid\". You can add as many items as you like to the <code>context</code> to make your prompt as interesting as possible.</p> <p>Here is an example of setting a few context variables:</p> <p>example contexts<pre><code>context = {\n'style': 'a 1970s polaroid',\n'color': 'lime green',\n'additional_items': 'car, apple, sheep'\n}\n</code></pre> When using it in a prompt, you would simply substitute the <code>key</code> between <code>{{ }}</code>. For example:</p> <pre><code>prompt = \"\"\"\n    Generate an image to look like {{ style }}. \n    It should have a {{ color }} hue, and add some of \n    these items in it: {{ additional_items }}. \"\"\"\n</code></pre> <p>This would generate: <pre><code>    Generate an image to look like a 1970s polaroid.\n    It should have a lime green hue, and add some of\n    these items in it: car, apple, sheep.\n</code></pre> Based on these substitutions in our actual example, the prompt sent to the LLM would be:</p> <pre><code>Create a prompt for an Image Generation pipeline for the following topic:\ncow\nin the style of a 1970s polaroid.\n</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#add-task-to-the-pipeline","title":"Add Task to the Pipeline","text":"<p>You have created the task, but it's not yet part of the pipeline. To do that, we'll need to use the <code>add_task</code> method.</p> <p>After the PromptTask line, add:</p> <pre><code># ...\n# Add tasks to pipeline\npipeline.add_task(create_prompt_task)\n</code></pre> <p>At this point, your pipeline flow graph looks like:</p> <pre><code>graph TB \n    direction TB\n    B(Create Prompt Task):::main\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <p>However, if you execute your script, nothing will happen. That's because you need to tell the pipeline graph to run.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#run-the-pipeline","title":"Run the Pipeline","text":"<p>To run a pipeline, you simply need to call the method <code>run</code>, and give it a prompt:</p> <pre><code># ...\n# Run the pipeline\npipeline.run(\"a cow\")\n</code></pre> <p>Here's the result. Notice in the logs you can see the Task inputs and outputs: <pre><code>[12/16/23 05:02:05] INFO    PromptTask Create Prompt Task\n                            Input:\n                                Create a prompt for an Image Generation pipeline for the following topic:\n                                a cow\n                                in the style of a 1970s polaroid.\n\n[12/16/23 05:02:09] INFO    PromptTask Create Prompt Task\n                            Output: \"Generate an image of a cow, styled and framed as if it was taken with a 1970s Polaroid camera.\"\n</code></pre></p> <p>The fun thing about this task is that you can ensure the text leading to the Image Generation task will be formatted in a way that will provide the best results. You can experiment with different types of prompts, and see how the LLM will turn them into a proper prompt.</p> <p>Here are a few examples:</p> <ul> <li> <p>A Cow: \"Generate an image of a cow, styled and framed as if it were taken with a 1970s Polaroid camera\"</p> </li> <li> <p>An ice cream cone on a hot day: \"Generate an image of an ice cream cone on a hot day, capturing the essence of a 1970s polaroid photograph. The image should evoke nostalgia and the unique aesthetic of the 70s era, with its warm, faded colors and soft focus\"      </p> </li> <li> <p>laughter: \"Generate an image that encapsulates the theme of 'laughter', styled and framed as if it was taken with a 1970s Polaroid camera. The image should evoke a sense of nostalgia and joy, capturing a candid moment of genuine laughter.\"</p> </li> </ul> <p>At the moment, this isn't a very exciting pipeline - it only has a single task. To make this a true pipeline, we need to add more tasks for it to execute, and send the output of the previous tasks \"downstream\" - i.e. to the successive task.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#create-the-first-fake-task","title":"Create the first \"Fake Task\"","text":"<p>The next two tasks we create will be \"fake\" ones - meaning they are simply there as placeholders until we create the actual tasks They're like scaffolding, allowing us to build the pipeline to ensure it works before replacing them with the real image generation and image display tasks.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#fake-image-generation","title":"Fake Image Generation","text":"<p>The fake image generation task will be another <code>PromptTask</code> that will tell the LLM to \"pretend\" to generate an image. It will take the <code>output</code> from the parent task, and feed it to this task using the Jinja2 <code>{{ }}</code> syntax. If you've taken the Compare Movies - Workflows course you've seen this before.</p> <p>Create the task in your <code>app.py</code> file by inserting the following code after the <code>create_prompt_task</code> but before the section of the code where you add the tasks to the pipeline.</p> <pre><code># ...\n# Create tasks\ncreate_prompt_task = PromptTask(\n# ...\n)\ngenerate_image_task = PromptTask(\n\"\"\"\n    Pretend to create an image using this prompt, \n    and return the filename of the generated image: \n    {{ parent_output }}\n    \"\"\",\nid=\"Generate Image Task\",\n)\n# Add tasks to pipeline\n# ...\n</code></pre> <p>Notice we're using <code>{{ parent_output }}</code> to give the LLM the output from the parent task. This is a very handy way to feed data from one task to the next.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#add-to-the-pipeline","title":"Add to the Pipeline","text":"<p>If we run the pipeline at the moment, this new task won't be run. We need to add it to the pipeline.</p> <p>Find the <code>add_task</code> line in your code. We're going to modify it to add multiple tasks at once, and then provide all the tasks.</p> <p>Modify this line:</p> <pre><code>pipeline.add_task(create_prompt_task)\n</code></pre> <p>Turn it to: <pre><code>pipeline.add_tasks(create_prompt_task, generate_image_task)\n</code></pre></p> <p>Notice we have switched <code>add_task</code> to <code>add_tasks</code>, and provided tasks in the order we want them to evaluate.</p> <p>Here's the full code for our <code>app.py</code> so far.</p> <pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask\nload_dotenv()  # Load your environment\n# Create the pipeline object\npipeline = Pipeline()\n# Create tasks\ncreate_prompt_task = PromptTask(\n\"\"\"\n    Create a prompt for an Image Generation pipeline for the following topic: \n    {{ args[0] }}\n    in the style of {{ style }}.\n    \"\"\",\ncontext={\"style\": \"a 1970s polaroid\"},\nid=\"Create Prompt Task\",\n)\ngenerate_image_task = PromptTask(\n\"\"\"\n    Pretend to create an image using this prompt, \n    and return the filename of the generated image: \n    {{ parent_output }}\n    \"\"\",\nid=\"Generate Image Task\",\n)\n# Add tasks to pipeline\npipeline.add_tasks(create_prompt_task, generate_image_task)\n# Run the pipeline\npipeline.run(\"a cow\")\n</code></pre> <p>This is the current pipeline:</p> <pre><code>graph TB \n    direction TB\n    B(Create Prompt Task):::main\n    C(Generate Image Task):::main\n    B --&gt; C\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre> <p>As you can see, it contains the two tasks we specified, in the order we added them to the pipeline.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#test-it-out","title":"Test it out","text":"<p>Run your app.py, and review the output. <pre><code>[12/16/23 05:26:45] INFO    PromptTask Create Prompt Task\n                            Input:\n                                Create a prompt for an Image Generation pipeline for the following topic:\n                                a cow\n                                in the style of a 1970s polaroid.\n\n[12/16/23 05:26:49] INFO    PromptTask Create Prompt Task\n                            Output: \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera.\"\n                    INFO    PromptTask Generate Image Task              \n                            Input:\n                                Pretend to create an image using this prompt, \n                                and return the filename of the generated image:\n                                \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera\"\n\n[12/16/23 05:26:51] INFO    PromptTask Generate Image Task\n                            Output: \"1970s_Polaroid_Style_Cow_Image.jpg\"\n</code></pre></p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#review-the-output","title":"Review the output","text":"<p>Notice there are two <code>PromptTask</code>s that are run - both have an <code>Input</code> and an <code>Output</code>. Let's review them individually.</p> <p>First the <code>Create Prompt Task</code> - notice the input where we take the topic and the style and ask it to generate the prompt to use for image generation. The <code>Output</code> shows that new prompt.</p> Create Prompt Task<pre><code>[12/16/23 05:26:45] INFO    PromptTask Create Prompt Task\n                            Input:\n                                Create a prompt for an Image Generation pipeline for the following topic:\n                                a cow\n                                in the style of a 1970s polaroid.\n\n[12/16/23 05:26:49] INFO    PromptTask Create Prompt Task\n                            Output: \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera.\"\n                    INFO    PromptTask Generate Image Task              \n                            Input:\n                                Pretend to create an image using this prompt, \n                                and return the filename of the generated image:\n                                \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera\"\n\n[12/16/23 05:26:51] INFO    PromptTask Generate Image Task\n                            Output: \"1970s_Polaroid_Style_Cow_Image.jpg\"\n</code></pre> <p>Now let's look at the <code>Generate Image Task</code>, where it takes the output from the parent task and uses it to return the name of the \"generated\" image.</p> Generate Image Task<pre><code>[12/16/23 05:26:45] INFO    PromptTask Create Prompt Task\n                            Input:\n                                Create a prompt for an Image Generation pipeline for the following topic:\n                                a cow\n                                in the style of a 1970s polaroid.\n\n[12/16/23 05:26:49] INFO    PromptTask Create Prompt Task\n                            Output: \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera.\"\n                    INFO    PromptTask Generate Image Task              \n                            Input:\n                                Pretend to create an image using this prompt, \n                                and return the filename of the generated image.:\n                                \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera\"\n\n[12/16/23 05:26:51] INFO    PromptTask Generate Image Task\n                            Output: \"1970s_Polaroid_Style_Cow_Image.jpg\"\n</code></pre> <p>You're making great progress. Let's continue by adding the next task to display the image.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#create-second-fake-task","title":"Create Second \"Fake Task\"","text":"<p>In this task, we'll \"display\" the image to the user. Later in the course, we'll create our own Griptape Tool to do this and we'll swap that into the pipeline.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#fake-view-image","title":"Fake View Image","text":"<p>The fake view image task will also be a PromptTask that tells the LLM to pretend to display the image to the viewer. Just like before, it will take the <code>output</code> from the parent task, and feed it to this one.</p> <p>Update the <code>app.py</code> file by inserting a new <code>display_image_task</code> after the previous <code>generate_image_task</code>.</p> <pre><code># ...\n# Create tasks\ncreate_prompt_task = PromptTask(\n# ...\n)\ngenerate_image_task = PromptTask(\n# ...\n)\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{ parent_output }}.\n    \"\"\",\nid=\"Display Image Task\"\n)\n# Add tasks to pipeline\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#add-to-the-pipeline_1","title":"Add to the Pipeline","text":"<p>Just as before, if we run the pipeline at the moment, this new task won't be run. We need to add it to the pipeline.</p> <p>Add the new task to the line where we <code>add_tasks</code> to the pipeline.</p> <pre><code># ...\n# Add tasks to the pipeline\npipeline.add_tasks(create_prompt_task, generate_image_task, display_image_task)\n# ...\n</code></pre> <p>Again, let's review the new pipeline:</p> <pre><code>graph TB \n    direction TB\n    B(Create Prompt Task):::main\n    C(Generate Image Task):::main\n    D(Display Image Task):::main\n    B --&gt; C --&gt; D\n\n\n    classDef main fill:#4274ff1a, stroke:#426eff</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#test","title":"Test","text":"<p>Run the code and let's look at the new output:</p> Display Image Task<pre><code>[12/16/23 12:54:13] INFO    PromptTask Create Prompt Task\n                            Input:\n                                Create a prompt for an Image Generation pipeline for the following topic:\n                                a cow\n                                in the style of a 1970s polaroid.\n\n[12/16/23 12:54:17] INFO    PromptTask Create Prompt Task\n                            Output: \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera.\"\n                    INFO    PromptTask Generate Image Task              \n                            Input:\n                                Pretend to create an image using this prompt, \n                                and return the filename of the generated image.:\n                                \"Generate an image of a cow, styled as if it was taken with a 1970s Polaroid camera\"\n\n[12/16/23 12:54:18] INFO    PromptTask Generate Image Task\n                            Output: \"1970s_Polaroid_Style_Cow_Image.jpg\"\n\n[12/16/23 12:54:20] INFO    PromptTask Display Image Task \n                            Output: [Displaying Image: \"1970s_Polaroid_Style_Cow_Image.png\"]\n</code></pre> <p>Notice now we have three distinct tasks, one that generates a prompt, one that creates an image, and one that displays the image. I mean, they don't actually create and display the image yet - we'll start adding those tasks shortly. But for now, our scaffolding is working beautifully.</p>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#code-review","title":"Code Review","text":"<p>We created the scaffolding for our application. Let's review the code and make sure it's working as expected.</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask\nload_dotenv()  # Load your environment\n# Create the pipeline object\npipeline = Pipeline()\n# Create tasks\ncreate_prompt_task = PromptTask(\n\"\"\"\n    Create a prompt for an Image Generation pipeline for the following topic: \n    {{ args[0] }}\n    in the style of {{ style }}.\n    \"\"\",\ncontext={\"style\": \"a 1970s polaroid\"},\nid=\"Create Prompt Task\",\n)\ngenerate_image_task = PromptTask(\n\"\"\"\n    Pretend to create an image using this prompt, \n    and return the filename of the generated image: \n    {{ parent_output }}\n    \"\"\",\nid=\"Generate Image Task\",\n)\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{ parent_output }}.\n    \"\"\",\nid=\"Display Image Task\",\n)\n# Add tasks to pipeline\npipeline.add_tasks(create_prompt_task, generate_image_task, display_image_task)\n# Run the pipeline\npipeline.run(\"a cow\")\n</code></pre>"},{"location":"courses/create-image-pipeline/03_first_pipeline/#next-step","title":"Next Step","text":"<p>In the next section, we are going to replace our fake Image Generation task with a real one. Check out Creating Images when you're ready to continue.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/","title":"Creating Images","text":""},{"location":"courses/create-image-pipeline/04_creating_images/#overview","title":"Overview","text":"<p>Image Generation via Griptape is handled via a few components.</p> <ul> <li>Image Generation Driver - Determines the model to be used. For example, OpenAI DALL\u00b7E 3 or Leonardo.AI.</li> <li>Image Generation Engines - The engine that facilitates the use of the Driver.</li> <li>Image Generation Task or Image Generation Tool. The Task or Tool is what will be provided to the Griptape Structure. Pipelines and Workflows can use <code>ImageGenerationTask</code> directly. You can provide an <code>ImageGenerationTool</code> to an Agent, to a ToolTask, or to a ToolkitTask.</li> </ul> <p>For example, to create an image with OpenAI DALL\u00b7E 3 as a task you could do something like:</p> <pre><code># Create an Image Generation Driver\ndriver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n)\n# Create an Image Generation Engine\nengine = ImageGenerationEngine( image_generation_driver=driver )\n# Create an Image Generation Task\ntask = ImageGenerationTask(\n\"Create a drawing of a pineapple\",\nimage_generation_engine=engine,\noutput_dir=\"./images\"\n)\n</code></pre> <p>Once you generate the task, you would add it to the pipeline or workflow.</p> <p>You can also use the <code>ImageGenerator</code> tool and assign it to an Agent. It takes many of the same arguments. If you had previously created the <code>driver</code> and <code>engine</code> as specified above, you would do something like:</p> <pre><code>agent = Agent(\ntools=[ImageGenerator(\nimage_generation_engine=engine,\noutput_dir=\"./images\",\noff_prompt=False,\n)]\n)\n</code></pre> <p>The main thing to be aware of is that you must use both components - Driver and Engine. You choose the model with the Driver, use the Engine to facilitate the use of the model, and then access the engine with either a Task or a Tool.</p> <p>In this course, because we're focusing on image generation as part of a Pipeline, we'll generate images using a Task.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#the-image-task","title":"The Image Task","text":"<p>To get started, we'll begin by replacing the Fake Image Generation task with a real one, using OpenAI DALL\u00b7E 3. We'll start with the basics, and adjust settings in a future step. For now, we just want to get things working.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#imports","title":"Imports","text":"<p>To use the Driver, Engine, and Task we'll need to add them to our <code>imports</code> section in <code>app.py</code>. You'll modify <code>griptape.tasks</code> to inlude <code>ImageGenerationTask</code>, and add imports for the Driver and Engine.</p> <pre><code># ...\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask, ImageGenerationTask\nfrom griptape.drivers import OpenAiDalleImageGenerationDriver\nfrom griptape.engines import ImageGenerationEngine\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#create-the-driver","title":"Create the Driver","text":"<p>Now we'll create our image generation driver. We'll dive into detail about some of the settings on the driver later, but first we'll get everything hooked up and working. Remember, the Driver controls what Image Generation Model we'll be using.</p> <p>In <code>app.py</code>, create the driver before you create the pipeline.</p> <pre><code># ...\nload_dotenv()  # Load your environment\n# Create the driver\nimage_driver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n)\n# Create the pipeline object\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#create-the-engine","title":"Create the Engine","text":"<p>The engine facilitates the use of the particular model. It will be what we pass to the task or tool. After the creation of the driver, create the engine:</p> <pre><code># ...\n# Create the driver\nimage_driver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n)\n# Create the engine\nimage_engine = ImageGenerationEngine(image_generation_driver=image_driver)\n# Create the pipeline object\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#replace-the-imagetask","title":"Replace the ImageTask","text":"<p>Next, we'll replace our fake image generation task with a real image generation task. Find the section of the code where we're creating the image task with <code>generate_image_task</code> and replace it withis <code>ImageGenerationTask</code>.</p> <pre><code># ...\ngenerate_image_task = ImageGenerationTask(\n\"{{ parent_output }}\",\nimage_generation_engine=image_engine,\noutput_dir=\"./images\",\nid=\"Generate Image Task\",\n)\n# ...\n</code></pre> <p>Notice we're giving it the <code>image_generation_engine</code> we defined earlier as <code>image_engine</code>. We're also specifying an <code>output_dir</code> of <code>./images</code>. This will ensure the image is generated in that directory. </p> <p>Tip</p> <p>With the ImageGenerationTask, if you want to save the file to disk you must specify specify either the output file name (<code>output_file</code>) or the directory you want the images to appear in (<code>output_dir</code>). If you don't, the image generated will only exist in the <code>ImageArtifact</code>. </p> <p>I recommend saving the file using <code>output_dir</code>, as we'll be able to retrieve the name of the image artifact in the next task.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#test","title":"Test","text":"<p>Give your application a test run. In the results you will see an ImageGenerationTask getting run, and then information on the image size and where it's written out. Here's a section of the resulting log. I've highlighted the log information of the file being written and the Output. </p> <p>Info</p> <p>Notice the image name is not in the <code>Output</code> text. It's part of the INFO, but not in Output - therefore not getting passed back from the Image Generation Task. I'll demonstrate how to get it later in this section.</p> <pre><code>[12/16/23 17:58:27] INFO     PromptTask Create Prompt Task                                                                            \n                             Output: \"Generate an image of a cow, styled and framed as if it were taken with a 1970s Polaroid camera.\"\n                    INFO     ImageGenerationTask Generate Image Task                                                                  \n                             Input: \"Generate an image of a cow, styled and framed as if it were taken with a 1970s Polaroid camera.\" \n[12/16/23 17:58:41] INFO     Saving [Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes] to                           \n                             /Users/jason/Documents/courses/griptape-image-pipeline/images/image_artifact_231216175841_iuy3.png       \n                    INFO     ImageGenerationTask Generate Image Task                                                                  \n                             Output: Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes                               \n</code></pre> <p>As you can see, the image has been written to the <code>./images</code> directory. Let's take a look at it!</p> <p></p> <p>Beautiful! </p>"},{"location":"courses/create-image-pipeline/04_creating_images/#the-display-image-task","title":"The Display Image Task","text":"<p>At the moment if you look at the output from the <code>Display Image task</code>, we're using <code>{{ parent_output }}</code> to get the data from the <code>ImageGenerationTask</code>. However, looking at the logs you can see the information does not contain the information we want - the path to the actual file. I've highlighted the <code>Output</code> from the <code>ImageGenerationTask</code>, and the <code>input</code> for the <code>Display Image Task</code>. Notice the image name isn't there.</p> <pre><code>[12/17/23 05:16:32] INFO    Saving [Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes] to\n                            /Users/jason/Documents/courses/griptape-image-pipeline/images/image_artifact_231217051632_wazr.png\n                    INFO    ImageGenerationTask Generate Image Task\n                    Output: Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes\n                    INFO    PromptTask Display Image Task\n                    Input:\n                        Pretend to display the image to the user.\n                        Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes.     \n\n[12/17/23 05:16:35] INFO    PromptTask Display Image Task                         \n                    Output: [Displaying Image]   \n                    Image Details:\n                        - Dimensions: 1024x1024\n                        - Type: image/png  \n                        - Size: 3147861 bytes                                  \n</code></pre> <p>So how do we get the name of the image? </p> <p>Fortunately, there is more information you can get from the <code>parent</code> task in a pipeline.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#pipeline-context","title":"Pipeline Context","text":"<p>Take a look at the Context section of the Griptape Pipeline documentation. It points out that Pipelines have access to a few context variables:</p> <ul> <li><code>parent_output</code> : output from the parent. We've been using this one.</li> <li><code>parent</code> : parent task.</li> <li><code>child</code> : child task.</li> </ul> <p>We know the <code>parent_output</code> doesn't include the information we want - but what about the <code>parent</code>? What attributes are available in the task itself?</p> <p>In order to discover that, we need to know what kind of <code>Artifact</code> the task outputs. This will tell us the attributes we can get. For example, the <code>BaseArtifact</code> contains attributes like <code>id</code>, <code>name</code>, <code>value</code>, and <code>type</code>. This means any type of artifact based on the <code>BaseArtifact</code> will have those attributes, and you can get them by using something like <code>{{ parent.output.value }}</code>, <code>{{ parent.output.id}}</code>, <code>{{parent.output.name}}</code>, etc.</p> <p>Tip</p> <p>Artifacts are used for passing different types of data between Griptape components. </p> <p>However, if we do this with our code you'll see that the <code>value</code> being passed back from the ImageGenerationTask are the raw bytes of the image. It's way too big for the LLM, and isn't what we want anyway. </p> <p>To demonstrate (and so you don't need to do it yourself), I'm going to replace the <code>{{ parent_output }}</code> in the <code>display_image_task</code> with <code>{{ parent.output.value }}</code> and show the results.</p> <pre><code># ...\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{ parent.output.value }}\n    \"\"\",\nid=\"Display Image Task\",\n)\n# ...\n</code></pre> <p>The result is a giant wall of text like:</p> <pre><code>02\\x03\\x02\\x02\\xfb\\xfd\\xfc\\xfc\\xfb\\x01\\x01\\x02\\xff\\x04\\x06\\x02\\x01\\x00\\x01\\xff\\x00\\xff\\xff\\xfb\\xfb\\x03\\x06\\x05\\xff\\xfc\\x01\\xfd\\x02\\xfd\\n\\x06\\x08\\xef\\xf2\\xf3\\x0b\\x0b\\x07\\xff\\xff\n\\x02\\xfb\\xfb\\xfc\\x05\\x06\\x03\\xfa\\xfc\\xff\\xf8\\xf9\\xfb\\x06\\x07\\x06\\x02\\x00\\x00\\xfb\\xfb\\xfc\\x03\\x04\\x04\\xfe\\xff\\xfe\\x02\\x03\\x03\\xff\\xfb\\xfc\\xff\\x00\\x00\\x03\\x05\\x02\\x02\\x01\\x00\\xfa\n\\xf7\\xfd\\xff\\x01\\x02\\xfb\\xfe\\xfe\\x07\\x08\\x04\\xfa\\xfc\\xfe\\x01\\xff\\x02\\x03\\x01\\xfc\\xfe\\xfa\\xfb\\x00\\x05\\x06\\xfe\\x00\\x01\\x02\\x00\\x02\\xff\\xfd\\xff\\xfa\\xfb\\xfc\\x01\\x04\\x02\\xee\\xf3\\xf6\n\\x01\\x04\\x04\\xfc\\xff\\x01\\xf7\\xf9\\xf9\\x01\\x01\\x03\\x05\\x03\\x03\\t\\n\\x06\\x01\\xff\\xfe\\x03\\x01\\x02\\x01\\xfe\\xff\\x04\\x02\\x00\\x0b\\x06\\x04\\x00\\x01\\xff\\xff\\xfe\\xfe\\x04\\x04\\x04\\xf9\\xfa\\xfd\n\\xfd\\xfe\\xff\\x02\\x03\\x00\\xff\\x01\\x02\\xf8\\xfb\\xfa\\x02\\xff\\x03\\xfe\\xff\\xfe\\xff\\x00\\x00\\xf8\\xfd\\xff\\x04\\x02\\x01\\x03\\xfc\\x00\\x01\\x01\\x00\\xf6\\xfb\\xfb\\x0c\\x0c\\t\\x01\\x03\\xfe\\xfb\\xfa\\x\nff\\xfb\\xfb\\xfc\\x01\\x00\\x01\\xf5\\xf9\\xfb\\t\\x0e\\x0b\\xef\\xf8\\xf8\\xf0\\xf0\\xf9\\xf5\\xf8\\xfa\\xfe\\x01\\x05\\xf8\\xfe\\xfc\\xfd\\xfe\\x00\\xf8\\xf8\\xfc\\xf9\\xf9\\xfc\\x07\\n\\x07\\xf6\\xf7\\xfc\\xfd\\x01\\x\nff\\xf7\\xfa\\xfc\\x01\\x02\\x01\\x02\\x04\\x07\\xf9\\xfb\\xfb\\xff\\xff\\xfe\\x01\\x04\\x03\\xfe\\x00\\xfe\\xff\\xfe\\x00\\x05\\x04\\x05\\x01\\xff\\xff\\xfa\\xf8\\xfc\\t\\t\\x03\\x02\\xff\\x00\\xf8\\xfa\\xfc\\x02\\x01\\x\n03\\x06\\x05\\x01\\x01\\x00\\x00\\xfb\\xfb\\xff\\x05\\x02\\xff\\r\\x07\\x01\\x08\\x06\\x00\\x04\\xfb\\xff\\n\\x08\\x03\\x01\\xfe\\xfe\\xfd\\x00\\x01\\x01\\x01\\xff\\x04\\x03\\x02\\xfd\\xfc\\xff\\x00\\x05\\x03\\x00\\x01\\x\n01\\xf8\\xf8\\xff\\xf4\\xfa\\xff\\x06\\x02\\x00\\x05\\x03\\x02\\x03\\x01\\xfd\\xfa\\xfb\\xfc\\x02\\x03\\x04\\xf9\\xf8\\xfd\\x07\\x0b\\t\\xf9\\xfc\\xfa\\xfa\\xfd\\x01\\xff\\xff\\x00\\x06\\x08\\x06\\xfa\\xf9\\xf9\\x01\\x01\n\\x01\\xf9\\xfb\\xfb\\x08\\x06\\x06\\xff\\xfd\\xfc\\r\\x10\\t\\xfa\\xf8\\xfa\\x04\\x00\\x00\\xfb\\xf8\\xfc\\x04\\x07\\x06\\x02\\x03\\xff\\x05\\x02\\x03\\r\\n\\x07\\xf4\\xf2\\xf8\\x05\\x04\\x01\\x01\\x02\\x00\\xf8\\xf9\\xfc\n</code></pre> <p>So obviously the <code>.value</code> isn't what we want in this case.</p> <p>But what other attributes are available?</p> <p>To discover this, we need to navigate our code and view what Artifact the <code>ImageGenerationTask</code> outputs.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#imagegenerationtask-artifact","title":"ImageGenerationTask Artifact","text":"<p>In Visual Studio Code, you can learn more about components of your code by Navigating to it. </p> <p>To do this, hover over <code>ImageGenerationTask</code> use the Keyboard shortcut Cmd on Mac, or Ctrl on Windows and click on it. Additionally, you can just click on <code>ImageGenerationTask</code> with the Right Mouse Button and choose Go to Definition</p> <p></p> <p>This will open the class definition <code>ImageGenerationTask</code> in your editor (<code>image_generation_task.py</code>).</p> <p>If you scroll down in the code until you find the section where the <code>run</code> method is defined, you'll see the output artifact:</p> <pre><code># ...\ndef run(self) -&gt; ImageArtifact:\nimage_artifact = self.image_generation_engine.generate_image(\nprompts=[self.input.to_text()], rulesets=self.all_rulesets, negative_rulesets=self.negative_rulesets\n)\n# ...\n</code></pre> <p>As you can see, it is an <code>ImageArtifact</code>. </p> <p>Navigate to this definition (again, using Cmd click, Ctrl click, or <code>RMB --&gt; Go to Definition</code>).</p> <p>At the top of the class you'll see the attributes being defined:</p> image_artifact.py<pre><code># ...\nclass ImageArtifact(BlobArtifact):\n\"\"\"ImageArtifact is a type of BlobArtifact that represents an image.\n    Attributes:\n        value: Raw bytes representing the image.\n        name: Artifact name, generated using creation time and a random string.\n        mime_type: The mime type of the image, like image/png or image/jpeg.\n        width: The width of the image in pixels.\n        height: The height of the image in pixels.\n        model: Optionally specify the model used to generate the image.\n        prompt: Optionally specify the prompt used to generate the image.\n    \"\"\"\n# ...\n</code></pre> <p>Remember previously I tried replacing <code>{{ parent_output }}</code> with <code>{{ parent.output.value}}</code>. As you can see from the definition, the <code>value</code> is the \"Raw bites representing the image\".</p> <p>But what other attributes do you see available that might be useful?</p> <p>How about that <code>name</code> attribute? It says it's the name of the artifact, generated using creation time and a random string. Let's swap that in and give it a try.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#parentoutputname","title":"parent.output.name","text":"<p>Navigate back to your <code>app.py</code> in Visual Studio Code.</p> <p>Inside the <code>display_image_task</code> section, replace <code>{{ parent_output }}</code> with <code>{{ parent.output.name }}</code>.</p> app.py<pre><code># ...\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{ parent.output.name }}\n    \"\"\",\nid=\"Display Image Task\",\n)\n# Add tasks to pipeline\n# ...\n</code></pre> <p>Note</p> <p>It's important to note that it's not <code>{{ parent_output_name }}</code>. We're grabbing an attribute of <code>parent</code> task. We need to use <code>.</code>, not <code>_</code>.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#test_1","title":"Test","text":"<p>Run the code and in the logs take a look at the <code>Input</code> to the <code>Display Image Task</code>.</p> <pre><code>[12/17/23 06:03:36] INFO    Saving [Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes] to\n                            /Users/jason/Documents/courses/griptape-image-pipeline/images/image_artifact_231217060336_570j.png             \n                    INFO    ImageGenerationTask Generate Image Task\n                            Output: Image, dimensions: 1024x1024, type: image/png, size: 3147861 bytes\n                    INFO    PromptTask Display Image Task \n                            Input:\n                                Pretend to display the image to the user.\n                                image_artifact_231217060336_570j.png \n\n[12/17/23 06:03:39] INFO    PromptTask Display Image Task\n                            Output: [Displaying Image: image_artifact_231217060336_570j.png]\n</code></pre> <p>See how it now gives us the name of the image? This is exactly what we need, except it's not the full path. Remember in the <code>ImageGenerationTask</code> we're specifying the <code>output_dir</code>. We should be sure to include this as well.</p> <p>Let's add some more context to the task, providing the <code>output_dir</code>. We'll also create a variable earlier in our code for the <code>output_dir</code> so we only need to define it once.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#define-output_dir","title":"Define <code>output_dir</code>","text":"<p>In <code>app.py</code>, right after <code>load_dotenv()</code>, let's create a section for any variables we might want. At the moment it's just <code>output_dir</code>, but it's always good to define these in a single place.</p> app.py<pre><code># ...\nload_dotenv() # Load your environment\n# Variables\noutput_dir = \"./images\"\n# Create the driver\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#replace-in-generate_image_task","title":"Replace in <code>generate_image_task</code>","text":"<p>Now go down to the <code>generate_image_task</code> and use the <code>output_dir</code> variable in the <code>ImageGenerationTask</code>.</p> app.py<pre><code># ...\ngenerate_image_task = ImageGenerationTask(\n\"{{ parent_output }}\",\nimage_generation_engine=image_engine,\noutput_dir=output_dir,\nid=\"Generate Image Task\",\n)\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#create-context-in-display_image_task","title":"Create context in <code>display_image_task</code>","text":"<p>Finally, back to the <code>display_image_task</code>, we'll create a <code>context</code>, provide the <code>output_dir</code>, and use it in our prompt.</p> app.py<pre><code># ...\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{output_dir}}/{{ parent.output.name }}\n    \"\"\",\ncontext={\"output_dir\": output_dir},\nid=\"Display Image Task\",\n)\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#test_2","title":"Test","text":"<p>Run the code again and let's check the Input to the <code>Display Image Task</code>: <pre><code>                    INFO    PromptTask Display Image Task\n                    Input:\n                            Pretend to display the image to the user.\n                            ./images/image_artifact_231217061650_zrmz.png \n</code></pre></p> <p>Perfect! That's exactly what we need to be able to give to the real display image step - the path of the file that's been generated.</p>"},{"location":"courses/create-image-pipeline/04_creating_images/#code-review","title":"Code Review","text":"<p>You can now generate an image using the prompt. Excellent work! Let's review the current state of our applicaiton:</p> app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask, ImageGenerationTask\nfrom griptape.drivers import OpenAiDalleImageGenerationDriver\nfrom griptape.engines import ImageGenerationEngine\nload_dotenv()  # Load your environment\n# Variables\noutput_dir = \"./images\"\n# Create the driver\nimage_driver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n)\n# Create the engine\nimage_engine = ImageGenerationEngine(image_generation_driver=image_driver)\n# Create the pipeline object\npipeline = Pipeline()\n# Create tasks\ncreate_prompt_task = PromptTask(\n\"\"\"\n    Create a prompt for an Image Generation pipeline for the following topic: \n    {{ args[0] }}\n    in the style of {{ style }}.\n    \"\"\",\ncontext={\"style\": \"a 1970s polaroid\"},\nid=\"Create Prompt Task\",\n)\ngenerate_image_task = ImageGenerationTask(\n\"{{ parent_output }}\",\nimage_generation_engine=image_engine,\noutput_dir=output_dir,\nid=\"Generate Image Task\",\n)\ndisplay_image_task = PromptTask(\n\"\"\"\n    Pretend to display the image to the user. \n    {{output_dir}}/{{ parent.output.name }}\n    \"\"\",\ncontext={\"output_dir\": output_dir},\nid=\"Display Image Task\",\n)\n# Add tasks to pipeline\npipeline.add_tasks(create_prompt_task, generate_image_task, display_image_task)\n# Run the pipeline\npipeline.run(\"a cow\")\n</code></pre>"},{"location":"courses/create-image-pipeline/04_creating_images/#next-step","title":"Next Step","text":"<p>Our next task is to replace our fake Display Image with a real one. There are a few ways we can achieve this within a Griptape Pipeline. </p> <ol> <li>Tasks - Create a new type of Task that just displays an image.</li> <li>Tools - Create a Tool that displays an image, and then use <code>ToolTaask</code> or <code>ToolkitTask</code> to integrate it into the Pipeline.</li> <li>Plain ol' Python - Because we're running a Pipeline in Python, we can just ignore adding anything to our structure and just display the output of the Image Generation task as we want.</li> </ol> <p>All three of these methods are valid, but in the context of this course we're going to look at creating our own Tool to display the image. The reason for this is flexibility with integration in future workflows. Imagine creating images with an Agent through a chat experience. If you have a Tool, you can simply add it to the Agent and ask it to display the image whenever it's ready. You can insert it into a Pipeline or Workflow by using <code>ToolTask</code> or <code>ToolkitTask</code>. The possibilities are numerous.</p> <p>In the near future we'll be creating a course specifically around creating and sharing Tools. For now, we're going to re-purpose material from the Shotgrid Client course where we discuss creating tools. The next two sections of this course are taken from there. They give a detailed understanding of tools, and help you create your first tool.</p> <p>If you already have created tools in the past, and have a deep understanding of how to create them, feel free to skip ahead to the Display Image Tool section. Othewise, let's dive in and learn more about how Griptape Tools work.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/","title":"Understanding Tools - DateTime","text":""},{"location":"courses/create-image-pipeline/05_understanding_tools/#overview","title":"Overview","text":"<p>In this module, we will explore the DateTime Tool within Griptape, demonstrating its use with a <code>Pipeline</code>, break down how <code>Activities</code> work, and integrate via <code>ToolTask</code> and <code>ToolkitTasks</code>.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#what-is-a-griptape-tool","title":"What is a Griptape Tool?","text":"<p>Griptape Tools are like additional helpers when dealing with tasks that a Large Language Model (LLM) can't handle by itself. They expand the capabilities of a system, allowing it to connect with external applications and use specific Python functionalities that aren't part of the LLM's standard toolkit. Whether it's for an automated workflow, a data processing pipeline, or an interactive agent, Griptape Tools provides the extra abilities needed to tackle a wider range of problems and tasks, enhancing the overall functionality and efficiency of the system.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#setting-up-the-pipeline","title":"Setting up the Pipeline","text":"<p>Let's create a new application called <code>test_tool.py</code>. We'll use this to test working with the Tool in a way that doesn't impact our current application.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#create-test_toolpy","title":"Create <code>test_tool.py</code>","text":"<p>In your project directory, create a new file called <code>test_tool.py</code>. It should look like the start of every other <code>app.py</code> we've created throughout these courses:</p> test_tool.py<pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#add-a-pipeline-and-prompttask","title":"Add a Pipeline and PromptTask","text":"<p>Next, let's set up a basic Pipeline and some task functionality in our application. Make sure you're modifying <code>test_tool.py</code>, and not <code>app.py</code>.</p> <p>Let's add the lines to import the <code>Pipeline</code> and the <code>PromptTask</code> classes.</p> test_tool.py<pre><code># ... shortened for brevity\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask\n# ...\n</code></pre> <p>Then we'll instantiate the Pipeline, add a task, and run it with a simple question: \"What day is it?\".</p> test_tool.py<pre><code># ...\n# Create the pipeline\npipeline = Pipeline()\n# Create task\ntask = PromptTask(\"{{ args[0] }}\", id=\"Task\")\n# Add task to the pipeline\npipeline.add_task(task)\n# Run the pipeline\npipeline.run(\"What day is it?\")\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#test-it","title":"Test it","text":"<p>If you run the application you can see in the output that the task doesn't know what day it is:</p> <pre><code>[12/17/23 17:18:12] INFO    PromptTask Task\n                            Input: What day is it?\n[12/17/23 17:18:15] INFO    PromptTask Task\n                            Output: As an AI, I don't have real-time capabilities to provide the current date. Please check your device for the current date.\n</code></pre> <p>Luckily - Griptape provides a tool to tell the LLM what day it is! The DateTime Tool!</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#adding-tools","title":"Adding Tools","text":"<p>Griptape Tools allow you to add functionality that Griptape Structures (Agents, Pipelines, Workflows) can use. We'll use the DateTime Tool to give the pipeline the ability to figure out the current time. </p> <p>Adding a Tool is a straightforward process. You <code>import</code> it, configure it if necessary, and then give it to the Agent, Pipeline, or Workflow. If adding to a Pipeline or Workflow, you'll add it as a Task. Some Tools are more complicated than others, which is why we're getting started with a nice simple one.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#include-datetime","title":"Include DateTime","text":"<p>Modify the import statements to include the DateTime Tool:</p> <pre><code># ...\nfrom griptape.tools import DateTime\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#include-toolkittask","title":"Include ToolkitTask","text":"<p>Now we need to add a Task that can handle tools. PromptTask isn't able to take a tool, so you will need to use either <code>ToolTask</code> or <code>ToolkitTask</code>. The main difference between the two is that <code>ToolkitTask</code> uses Chain-of-Thought to figure out what steps to take, and can use multiple tools. <code>ToolTask</code> just executes a single tool without Chain-of-Thought.</p> <p>In this case, we will use <code>ToolkitTask</code>, so add it to the line in your <code>import</code> section where you are importing the <code>PromptTask</code>.</p> <pre><code># ...\nfrom griptape.tasks import PromptTask, ToolkitTask\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#use-the-toolkittask","title":"Use the ToolkitTask","text":"<p>Let's replace the <code>PromptTask</code> in our code with the <code>ToolkitTask</code>. ToolkitTasks take a list of tools, so we will specify the <code>DateTime</code> as one of them.</p> test_tool.py<pre><code># ...\n# Create task\ntask = ToolkitTask(\"{{ args[0] }}\", tools=[DateTime(off_prompt=False)], id=\"Task\")\n# ...\n</code></pre> <p>What is \"off_prompt\"?</p> <p>Important Note: Griptape directs outputs from Tool activities into short-term TaskMemory, keeping them 'off_prompt' and separate from the LLM. This makes it easy to work with big data securely and with low latency. To change this default for more direct interaction with the LLM, set the <code>off_prompt</code> parameter to <code>False</code>. This allows the LLM to access and respond to Tool outputs directly.</p> <p>DateTime</p> <p>For more information on the DateTime Tool, you can visit the DateTime Tool Documentation. </p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#try-it-again","title":"Try it again","text":"<p>Run the application, and let's review the output:</p> <pre><code>[12/17/23 18:26:39] INFO    ToolkitTask Task                         \n                            Input: What day is it?\n[12/17/23 18:26:42] INFO    Subtask 63e83a8363884dc8a7809e55fbb44487\n                            Thought: I need to use the DateTime action to get the current date and time.\n                            Action: {\"name\": \"DateTime\", \"path\": \"get_current_datetime\", \"input\": {}}\n                    INFO    Subtask 63e83a8363884dc8a7809e55fbb44487\n                            Response: 2023-12-17 18:26:42.195060\n\n[12/17/23 18:26:44] INFO    ToolkitTask Task\n                            Output: Today is December 17, 2023.   \n</code></pre> <p>Notice the highlighted section above. This is the <code>subtask</code>, where the Task is using Chain-of-Thought to figure out what to do. It recognizes the need to use one of its activities - in this case, <code>get_current_datetime</code> to get the result.</p> <p>Take a look at the <code>Action</code>:</p> <pre><code>Action:\n{           \"name\": \"DateTime\", \"path\": \"get_current_datetime\",\n\"input\": {}   }                   </code></pre> <p>It's using the <code>DateTime</code> tool, with a method <code>get_current_datetime</code>, and no <code>inputs</code> (parameters).</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#tool-classes","title":"Tool Classes","text":""},{"location":"courses/create-image-pipeline/05_understanding_tools/#the-datetime-class","title":"The DateTime Class","text":"<p>Let's take a look at the <code>DateTime</code> class itself and see if we can determine what's happening.</p> <ul> <li> <p>Find the line in your code where you <code>import</code> <code>DateTime</code>:</p> <pre><code>from griptape.tools import DateTime\n</code></pre> </li> <li> <p>Hover over <code>DateTime</code> and <code>Ctrl+Click</code> (<code>Cmd+Click</code> on Mac). This will open the DateTime class for Griptape in your editor.</p> <p>Tip</p> <p>In Visual Studio Code, you can navigate to the Definition of a class by using <code>Ctrl+Click</code> (<code>Cmd+Click</code> on Mac). See the documentation to learn more about Visual Studio Code tips for code navigation.</p> <p></p> <p>As you can see in the editor, this is the DateTime class, ready for you to inspect. Jumping around between definitions of classes and functions you use is a very handy way to learn more about how Tools are implemented. 10 stars - would highly recommend.</p> </li> </ul>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#tool-structure","title":"Tool Structure","text":"<p>In Griptape, a \"Tool\" is a <code>Class</code>. It is a blueprint that defines the properties and behaviors the Tool will have.</p> <p>Each Tool has <code>activities</code> and <code>methods</code>.</p> <pre><code># Example of a very simple class with an activity and method\nclass SayHello():\n@activity(config={\n\"description\": \"Can be used to say Hello!\"\n}\n)\ndef say_hello():\nreturn TextArtifact(\"Hello!\")\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#methods","title":"Methods","text":"<p>Methods define the actions that the Tool can perform. They are implemented as Python functions in the class. In the case of the <code>DateTime</code> Tool, it has a few methods - <code>get_current_datetime</code> and <code>get_relative_datetime</code>. They define specific actions it can perform.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#activities","title":"Activities","text":"<p>Activities tell the LLM what the action does and when it might want to use it - kind of like attaching a label or instruction. They are implemented as a decorator above the Python method. For example, the <code>@activity</code> decorator in <code>DateTime</code> describes what the <code>get_current_datetime</code> method does (\"Can be used to return current date and time\"), and how it should behave.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#datetime-structure","title":"DateTime Structure","text":"<p>Let's look specifically at the DateTime structure. I'll comment out details so we can keep it simple.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\n# ...\nexcept Exception as e:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English...\n): str\n}\n),\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\ntry:\n# ...\nexcept Exception as e:\n# ...\n</code></pre> <p>Notice there are two <code>methods</code>: <code>get_current_datetime</code> and <code>get_relative_datetime</code>.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n# ...\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\n</code></pre> <p>And each <code>method</code> has its associated <code>activity</code>.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n# ...\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\n</code></pre> <p>The LLM uses the description of the activities to figure out what it can do, and what the appropriate method is to call.</p> <p>In our earlier example, the Action taken was <code>get_current_datetime</code>:</p> <pre><code>Action:\n{           \"name\": \"DateTime\", \"path\": \"get_current_datetime\",\n\"input\": {}   }\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#methods_1","title":"Methods","text":""},{"location":"courses/create-image-pipeline/05_understanding_tools/#basic-structure","title":"Basic Structure","text":"<p>Let's use the <code>get_current_datetime</code> to understand the structure of a method.</p> <pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <ul> <li><code>get_current_datetime</code>: This is the name of the method we are defining. </li> <li> <p><code>(self, _: dict)</code>: These are the parameters the method can take. <code>self</code> refers to the object itself (common in class methods), and <code>_</code> is a placeholder for a parameter that is a dictionary (<code>dict</code>), but this dictionary is not actively used in the method.</p> <p>Tip</p> <p>Neither of these are used in this particular method, but they're there because it's good practice to include them.</p> </li> <li> <p><code>-&gt; BaseArtifact</code>: This indicates that the method will return an object of type <code>BaseArtifact</code>. Griptape provides various artifacts, including Text, List, Blob, etc. You can learn more about them in the documentation. </p> </li> </ul> <p>Since we're not using <code>self</code>, or <code>_</code> in this method, and Python is a dynamically typed language, we don't need to specify what a function will return. We could probably write this method as:</p> <pre><code>def get_current_datetime():\n</code></pre> <p>However, including type hints in method definitions is good practice as it enhances the overall quality and maintainability of our code.</p> <p>In summary, he's a great way to understand the <code>def</code> line:</p> Item What it's used for <code>def</code> Let's define a method! <code>get_current_datetime</code> That's the name of my method! <code>(self, _: dict)</code> Some stuff we're passing to the method! <code>--&gt; BaseArtifact:</code> The stuff I want to get back from the method!"},{"location":"courses/create-image-pipeline/05_understanding_tools/#try-except","title":"Try / Except","text":"<p>Moving further into the method, you'll see the <code>try</code> and <code>except</code> block. </p> <pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <ul> <li><code>try</code> Block:<ul> <li>The <code>try</code> keyword starts a block of code Python will attempt to execute. In this case, it's trying to get the current date and return it as a <code>TextArtifact</code> (more on text artifacts in the documentation). </li> <li>Think of it as saying \"Hey - give this a shot and see if it works?\"</li> </ul> </li> <li><code>except</code> Block:<ul> <li>Code doesn't always work as expected, and the <code>except</code> block is what happens if <code>try</code> encounters an error.</li> <li><code>Exception as e</code> part catches any error and stores it in a variable <code>e</code>.</li> <li>Simply put, the <code>except</code> block says \"If there was a problem in <code>try</code>, let's do this instead.</li> </ul> </li> </ul> <p>Using <code>try/except</code> is always a good practice, especially with Tools in Griptape. One of the benefits of using this is that <code>ErrorArtifacts</code> get passed back to Griptape. This means Griptape can evaluate the error, and try again - often fixing mistakes the LLM made in its query!</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#return","title":"Return","text":"<pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <p>Finally, the <code>return</code> statements. Whatever is in these will be returned to the subtask in order to continue. As mentioned in the <code>try/except</code> section above, <code>ErrorArtifacts</code> are important to return because they will allow Griptape to try again.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#activities_1","title":"Activities","text":"<p>As mentioned previously, <code>activities</code> add information and certain features to methods. With Griptape Tools, they can provide simple information (like a description), or even schemas defining what kind of parameters should be passed.</p> <p>For the <code>get_current_datetime</code> method, there are no parameters, so the activity itself is quite simple - it's just a description that tells the LLM when to use it.</p> <pre><code>@activity(config={\"description\": \"Can be used to return current date and time.\"})\n</code></pre> <p>As you can see, any time the LLM determines the task is to return the current date and/or time, it will use this method.</p> <p>Notice with the <code>get_relative_datetime</code> method (the other method in the DateTime class) the activity is different - it says to return a relative date and time and also has a <code>schema</code> involved. We'll dive into this detail shortly - for now, let's just understand that any time the LLM thinks that its task is to return something about the current date and time, it will use the <code>get_current_datetime</code> method.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#more-testing","title":"More Testing","text":"<p>Let's experiment with different ways of requesting the current time. Try requesting for day, time, date, day of the month, time of year, etc. Notice how the LLM can handle all these different results, with only one method.</p> <pre><code>pipeline.run(\"What's the date?\")\nOutput: Today's date is December 2, 2023.\n\npipeline.run(\"What day of the week is it?\")\nOutput: Today is Saturday.\n\npipeline.run(\"What's the time in New Zealand?\")\nOutput: The current time in New Zealand is 07:58 on December 2, 2023.\n\npipeline.run(\"What's the time if Yoda said it?\")\nvThe current time in Yoda's speech would be, \"58 past 7 it is.\"\n\npipeline.run(\"What's the current time as Beaker from the Muppets?\")\nOutput: As Beaker from the Muppets, the current time would be expressed as, \"Meep meep, meep meep meep!\"\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#parameters","title":"Parameters","text":"<p>Sometimes you want an activity to take a specific parameter. In the case of the <code>DateTime</code> Tool, the <code>get_relative_datetime</code> needs to take a parameter to understand what the day should be relative to.</p> <p>Let's try it out. Run the app with a promopt of \"how far away April 3rd is from today?\". Notice a few actions are happening now - the first is <code>get_current_datetime</code> to find out what \"today\" is, then the second is <code>get_relative_datetime</code> where it passes an input.</p> <pre><code>Action: {\"name\": \"DateTime\", \"path\": \"get_current_datetime\", \"input\": {}}\n\nAction: {\"name\": \"DateTime\", \"path\": \"get_relative_datetime\", \"input\": {\"values\": {\"relative_date_string\": \"April 3, 2024\"}}}\n</code></pre> <p>Before we dive into the parameters, there are two things worth pointing out:</p> <ol> <li>We didn't specify the number of steps it should take to get to the answer. We just asked one somewhat ambiguous question and the LLM figured out that it would take two tasks - getting the current date and then getting the relative date.</li> <li>We also didn't specify the <code>relative_date_string</code> key/value pair. We didn't need to. The LLM saw what key/value pairs the <code>get_relative_datetime</code> method required, and figured out how to pass them. </li> </ol> <p>This is why working with Griptape Tools starts to get exciting - once you define the parameters, the LLM can figure out the right way to pass the data.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#schema","title":"Schema","text":"<p>Schemas are how we define what parameters are going to be passed to the method. They are like a checklist for data. They're a set of rules that describe what kind of data you expect, and how it should be structured.</p> <p>For example, if you are creating a schema for a person you might say:</p> <ul> <li>There must be a name, and it should be text.</li> <li>There must be an age, and it should be a number.</li> <li>There might be an email address. If there is, it should be in the format of an email address. If not, well that's just okay with us.</li> </ul> <p>Then the method can use the schema as a checklist to make sure everything matches. If age is written as text instead of a number (for example), you know there's a mistake.</p> <p>You can learn more about Python schemas in the schema documentation.</p> <p>For Griptape Tool Activities, schemas are defined as part of the <code>config</code> dictionary using the <code>Schema</code> class.</p> <p>Let's look at the schema for <code>get_relative_datetime</code>:</p> <pre><code>config={\n\"description\": \"Can be used to return a relative date and time.\",\n\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English. For example, \"now EST\", \"20 minutes ago\", '\n'\"in 2 days\", \"3 months, 1 week and 1 day ago\", or \"yesterday at 2pm\"',\n): str\n}\n),\n}\n</code></pre> <p>Right now the Schema has one parameter it's looking for: <code>relative_date_string</code>. The <code>description</code> tells us what kind of data it should be. It says:</p> <pre><code>Relative date in English. For example or example, \"now EST\", \n\"20 minutes ago\", \"in 2 days\", \"3 months, 1 week and 1 day ago\", \nor \"yesterday at 2 pm\"\n</code></pre> <p>Finally, the <code>: str</code> part means the information should be provided as a string, which basically is just a line of text. This could also be <code>: int</code>, <code>: dict</code>, <code>: list</code>, etc depending on your needs.</p>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#optional-parameters","title":"Optional Parameters","text":"<p>It's possible to also provide optional parameters with Schemas. For example, if we were making our own version of DateTime we could include something like:</p> <pre><code>\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English.',\n): str,\nOptional(\"timezone\"): str  # This is an optional parameter\n}\n),\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#code-review","title":"Code Review","text":"<p>Throughout this section, we've explored quite a bit about Griptape Tools. We learned how to import and use them, how they're structured, and what <code>methods</code> and <code>activities</code> are. You understand <code>schemas</code> and how they allow you to pass parameters to various <code>methods</code>.</p> <p>Before continuing, let's look at <code>test_tool.py</code> in its current state where you can send a prompt to the Pipeline and ask important questions, like how much time you have before my birthday (April 3rd).</p> test_tool.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask, ToolkitTask\nfrom griptape.tools import DateTime\nload_dotenv()\n# Create the pipeline\npipeline = Pipeline()\n# Create task\ntask = ToolkitTask(\"{{ args[0] }}\", tools=[DateTime(off_prompt=False)], id=\"Task\")\n# Add task to the pipeline\npipeline.add_task(task)\n# Run the pipeline\npipeline.run(\"How much time is there before April 3?\")\n</code></pre>"},{"location":"courses/create-image-pipeline/05_understanding_tools/#next-steps","title":"Next Steps","text":"<p>You have access to DateTime (not quite as cool as SpaceTime, but still..). In the next section, you will build your first Griptape Tool.</p>"},{"location":"courses/create-image-pipeline/06_first_tool/","title":"Your First Tool","text":""},{"location":"courses/create-image-pipeline/06_first_tool/#overview","title":"Overview","text":"<p>We'll use a Griptape Tool Template that's available on GitHub to create our first Tool, and then modify it slightly to demonstrate multiple activities.</p>"},{"location":"courses/create-image-pipeline/06_first_tool/#getting-the-template","title":"Getting the template","text":"<p>The Tool template provided creates a <code>reverse_string</code> Tool. It will take any text and reverse it. It's a nice simple example of how to use a Tool with your LLM.</p> <p>The template contains examples of how to use the Tool, testing, and more. The idea is that you can take this template and publish your own Tool on GitHub to share with the world. </p> <p>For the purposes of this course, we'll keep things simple and just focus on the Tool itself, using the code to create our own as part of our current project.</p> <ol> <li>Navigate to the Gritptape tool-template repository on GitHub.</li> <li>Find the Code button and click on it.</li> <li> <p>Choose Download zip to download a zip file of the project.</p> <p>Info</p> <p>If you have a GitHub account and have experience with GitHub repos, you are more than welcome to choose Use this template and work the way you are comfortable. </p> </li> <li> <p>Extract the contents of the .zip file by double-clicking on it.</p> <p></p> <p>The reverse_string_tool folder is the one we are interested in, it contains the required files for the Tool. You can read more about them in the Griptape Custom Tool documentation.</p> </li> <li> <p>Copy the reverse_string_tool folder into the folder where your <code>app.py</code> and <code>test_tool.py</code> files sit. </p> <p>Tip</p> <p>You can just drag the folder from your Finder or Windows Explorer and drop it directly into Visual Studio Code to copy it.</p> <p>You should now see the folder in Visual Studio Code next to <code>app.py</code>, <code>test_tool.py</code>, and <code>.env</code>.</p> </li> </ol>"},{"location":"courses/create-image-pipeline/06_first_tool/#use-reverse-string","title":"Use Reverse String","text":"<p>Here's the code for the Reverse String Tool (as of December 2023). I've highlighted some important lines from the code.</p> <pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema({Literal(\"input\", description=\"The string to be reversed\"): str}),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\nreturn TextArtifact(input_value[::-1])\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre> <p>The highlighted lines illustrate that the Tool (Class) is called <code>ReverseString</code>. It has one module, <code>reverse_string</code>. It has an <code>activity</code> that says it \"Can be used to reverse a string\", and it appears to take one parameter named <code>input</code> which is described as \"The string to be reversed\".</p>"},{"location":"courses/create-image-pipeline/06_first_tool/#add-it-to-test_toolpy","title":"Add it to test_tool.py","text":"<p>Just like any other Griptape Tool, you need to <code>import</code> it. However, because this Tool isn't part of the default Griptape repository, the import line will look slightly different. Add the following line to <code>test_tool.py</code>:</p> <pre><code># ...\nfrom reverse_string_tool import ReverseStringTool\n# ...\n</code></pre> <p>Tip</p> <p>How do you know to choose <code>reverse_string_tool</code> and <code>ReverseStringTool</code> in the <code>import</code> statement?</p> <p>The <code>__init__.py</code> file is a hint. You can think of that file as a sort of index or table of contents for the items in the folder. Its presence tells Python that the directory is a special kind of directory - a package from which you can import <code>modules</code>.</p> <p>Because I saw that <code>__init__.py</code> file, I knew I could import modules from that folder. </p>"},{"location":"courses/create-image-pipeline/06_first_tool/#give-it-to-the-task","title":"Give it to the task","text":"<p>Remember, the <code>ToolkitTask</code> takes a list of Tools. We can add this Tool to the task by simply adding it to the list.</p> <p>Find the line where you create the task and add the <code>ReverseStringTool</code>:</p> <pre><code># ...\n# Create task\ntask = ToolkitTask(\n\"{{ args[0] }}\",\ntools=[DateTime(off_prompt=False), ReverseStringTool(off_prompt=False)],\nid=\"Task\",\n)\n# ...\n</code></pre> <p>Notice the task now has access to two Tools, <code>DateTime</code> and <code>ReverseStringTool</code>. </p>"},{"location":"courses/create-image-pipeline/06_first_tool/#test-it-out","title":"Test it out","text":"<p>Now test the Tool by running modifying the prompt to say something in reverse.</p> <pre><code>pipeline.run(\"Can you say this line in reverse: 'I'm a lumberjack and I'm okay'\")\n</code></pre> <pre><code>[12/18/23 05:43:55] INFO    ToolkitTask Task\n                            Input: Can you say this line in reverse: 'I'm a lumberjack and I'm okay'\n[12/18/23 05:43:59] INFO    Subtask 09bbf86167214c0f994bbbba94445e0c\n                            Thought: I need to use the ReverseStringTool action to reverse the given string.\n\n                            Action:\n                            {\n                                \"name\":\"ReverseStringTool\",\n                                \"path\":\"reverse_string\",\n                                \"input\": {\n                                    \"values\": {\n                                        \"input\": \"I'm a lumberjack and I'm okay\"\n                                    }\n                                }\n                             }\n                    INFO    Subtask 09bbf86167214c0f994bbbba94445e0c\n                            Response: yako m'I dna kcajrebmul a m'I\n[12/18/23 05:44:01] INFO    ToolkitTask Task\n                            Output: The reversed string is 'yako m'I dna kcajrebmul a m'I'.   \n</code></pre> <p>As you can see in the highlighted section above, the <code>Subtask</code> shows that the ToolkitTask has decided to use the ReverseStringTool action.</p>"},{"location":"courses/create-image-pipeline/06_first_tool/#combine-requests","title":"Combine requests","text":"<p>You can absolutely use multiple Tools at the same time. Try a few examples where you might use both the <code>DateTime</code> Tool and the <code>ReverseStringTool</code>.</p> <pre><code>pipeline.run(\"Can you reverse the month?\")\nOutput: The reversed month is \"rebmeceD\".\n\npipeline.run(\"Tell me how many days there are until December 25th, and then reverse the entire response\")\nOutput: The reversed response is \"syad 32 era ereht\".\n</code></pre>"},{"location":"courses/create-image-pipeline/06_first_tool/#adding-a-method","title":"Adding a method","text":"<p>Let's add another method to the <code>ReverseStringTool</code>. This will take a sentence and reverse the words instead of the letters.</p> <p>It will:</p> <ul> <li>Split the sentence into words</li> <li>Reverse the list of words</li> <li>Join the reverse words back into a sentence</li> </ul>"},{"location":"courses/create-image-pipeline/06_first_tool/#open-toolpy","title":"Open tool.py","text":"<ol> <li>In Visual Studio Code, open the <code>reverse_string_tool</code> folder and select <code>tool.py</code>.</li> </ol>"},{"location":"courses/create-image-pipeline/06_first_tool/#add-reverse_sentence","title":"Add <code>reverse_sentence</code>","text":"<ol> <li> <p>Duplicate the code from the first <code>@activity</code> line through the end of the <code>def reverse_string</code> method.</p> </li> <li> <p>Rename the second method to <code>reverse_sentence</code>.</p> </li> <li> <p>Change the description of the second activity to <code>Can be used to reverse a sentence</code> and the schema description to <code>The sentence to be reversed</code>.</p> </li> </ol> <p>Here's the resulting code, with much of it commented out for brevity. I've highlighted the specific sections where we replaced <code>string</code> with <code>sentence</code>. This new method won't reverse sentences yet, we will add that later.</p> <pre><code># ...\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema({Literal(\"input\", description=\"The string to be reversed\"): str}),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a sentence\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The sentence to be reversed\"): str}),\n}\n)\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/06_first_tool/#update-the-logic","title":"Update the logic","text":"<p>Within the <code>reverse_sentence</code> method, find the section of code after <code>try:</code> and before the <code>except</code>, and replace it with the following code:</p> <pre><code># ...\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\n# Splitting the sentence into words\nwords = input_value.split()\n# Reversing the list of words\nreversed_words = words[::-1]\n# Joining the reversed words back into a sentence\nreversed_sentence = \" \".join(reversed_words)\nreturn TextArtifact(reversed_sentence)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/create-image-pipeline/06_first_tool/#try-it-out","title":"Try it out","text":"<p>Now that you've added this new method, let's give it a try!</p> <pre><code>pipeline.run(\"Can you reverse the words in this sentence? \\\"I must eat, therefore, I am hungry\\\".\")\nOutput: The reversed sentence is \"hungry am I therefore, eat, must I\".\n</code></pre> <p>Well done! Now go grab a snack and we'll continue.</p>"},{"location":"courses/create-image-pipeline/06_first_tool/#code-review","title":"Code Review","text":"<p>You have added a Griptape Tool and modified it to add a new activity! Well done! Let's take a look at all the code to review it before moving on.</p>"},{"location":"courses/create-image-pipeline/06_first_tool/#test_toolpy","title":"<code>test_tool.py</code>","text":"test_tool.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask, ToolkitTask\nfrom griptape.tools import DateTime\nfrom reverse_string_tool import ReverseStringTool\nload_dotenv()\n# Create the pipeline\npipeline = Pipeline()\n# Create task\ntask = ToolkitTask(\n\"{{ args[0] }}\",\ntools=[DateTime(off_prompt=False), ReverseStringTool(off_prompt=False)],\nid=\"Task\",\n)\n# Add task to the pipeline\npipeline.add_task(task)\n# Run the pipeline\npipeline.run(\n'Can you reverse the words in this sentence? \"I must eat, therefore, I am hungry\".'\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/06_first_tool/#reverse_string_tooltoolpy","title":"<code>reverse_string_tool/tool.py</code>","text":"reverse_string_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The string to be reversed\"): str}\n),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\nreturn TextArtifact(input_value[::-1])\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a sentence\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The sentence to be reversed\"): str}\n),\n}\n)\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\n# Splitting the sentence into words\nwords = input_value.split()\n# Reversing the list of words\nreversed_words = words[::-1]\n# Joining the reversed words back into a sentence\nreversed_sentence = \" \".join(reversed_words)\nreturn TextArtifact(reversed_sentence)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/create-image-pipeline/06_first_tool/#next-steps","title":"Next Steps","text":"<p>In the next section, we'll take what we learned from these exercises, and create a tool that will display an image when passed the file path.</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/","title":"Display Image Tool","text":""},{"location":"courses/create-image-pipeline/07_display_image_tool/#overview","title":"Overview","text":"<p>In this section, we'll create the Display Image Tool. It will take the file path for the image generated, and use whatever the default image viewer is for the operating system to display it.</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#copy-reverse_string_tool","title":"Copy <code>reverse_string_tool</code>","text":"<ol> <li> <p>In Visual Studio Code, select the folder <code>reverse_string_tool</code> and choose Cmd+C, Cmd+V on Mac, or Ctrl+C, Ctrl+V on Windows.</p> </li> <li> <p>Rename the new folder as <code>display_image_tool</code> by selecting it and choosing Right Mouse Button -&gt; Rename... (or just select it and hit the Enter key)</p> </li> </ol>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#delete-__pycache__","title":"Delete <code>__pycache__</code>","text":"<p>The <code>__pycache__</code> folder is a directory used by Python to store compiled compiled files. When you run a Python program it saves a 'shortcut' version of the program in this folder. The next time you run the same program, Python uses these shortcuts to start the program more quickly.</p> <p>In this case, you don't want it because it holds the compiled code for the <code>reverse_string_tool</code>.</p> <ol> <li>Delete the <code>__pycache__</code> folder that is inside <code>display_image_tool</code> by choosing Right Mouse Button -&gt; Delete (or select it and hit Cmd+Del on Mac, Ctrl+Del on Windows.)</li> </ol>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#modify-__init__py","title":"Modify <code>__init__.py</code>","text":"<p>Remember from earlier, that the <code>__init__.py</code> file in Python is used to mark a directory as a Python package. In our current <code>__init__.py</code> file, it's being used to import the <code>ReverseStringTool</code> class. We're going to be replacing that class with our own: <code>DisplayImageTool</code>. So we'll need to update this file.</p> <p>Replace all instances of <code>ReverseStringTool</code> with <code>DisplayImageTool</code> in the file. Note: we haven't created that class yet, we'll do that in a couple of steps.</p> display_image_tool/__init__.py<pre><code>from .tool import DisplayImageTool\n__all__ = [\"DisplayImageTool\"]\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#modify-manifestyml","title":"Modify <code>manifest.yml</code>","text":"<p>The <code>manifest.yml</code> file provides information for people and other downstream systems to understand what this Tool is about. At the moment it contains information about the <code>Reverse String Tool</code>. Modify it to look like the following (don't forget to include your own contact email and legal details).</p> display_image_tool/manifest.yaml<pre><code>version: \"v1\"\nname: Display Image Tool\ndescription: Tool for displaying an image\ncontact_email: contact@example.com\nlegal_info_url: https://www.example.com/legal\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#create-requirementstxt","title":"Create <code>requirements.txt</code>","text":"<p>Some Tools you create for Griptape will require various Python dependencies - other libraries that they need to operate correctly.  Griptape allows you to easily include these requirements by adding them to a <code>requirements.txt</code> file, located inside your tool folder. You will then import the required dependency inside the method where it's used. </p> <p>This particular tool doesn't need any external libraries to be imported, so we can just leave the <code>requirements.txt</code> file blank. You could simply ignore it and not create the file, but if you decide to change this later and use a library within your code it's good to know how to use this.</p> <ol> <li>Select the <code>display_image_tool</code> folder and choose Right Mouse Button -&gt; New File..</li> <li>Name the new file <code>requirements.txt</code></li> </ol>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#update-toolpy","title":"Update <code>tool.py</code>","text":""},{"location":"courses/create-image-pipeline/07_display_image_tool/#description","title":"Description","text":"<p>Now we're at the part where we update the Display Image Tool itself. We'll be modifying <code>tool.py</code> with the following steps:</p> <ul> <li>Rename the class</li> <li>Define parameters</li> <li>Update the activity</li> <li>Update the method</li> <li>Import requirements</li> <li>Create a function to display the image</li> <li>Use it</li> </ul>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#rename-the-class","title":"Rename the Class","text":"<p>Rename the class definition from <code>ReverseStringTool</code> to <code>DisplayImageTool</code>.</p> display_image_tool/tool.py<pre><code># ...\n@define\nclass DisplayImageTool(BaseTool):\n@activity(\n# ...\n)\n#...\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#update-the-activity","title":"Update the Activity","text":"<p>The method we're going to create will allow us to display an image. We need to describe that method in the <code>@activity</code> section. The description itself should be pretty straightforward.. something like \"Can be used to display an image\". We will require the path of the image to be sent, and we'll use the <code>schema</code> for that.</p> <ul> <li>Change the <code>description</code></li> <li>Update the <code>schema</code> section of the activity. </li> </ul> display_image_tool/tool.py<pre><code># ...\n@define\nclass DisplayImageTool(BaseTool):\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to display an image\",\n\"schema\": Schema(\n{\nLiteral(\n\"filename\", description=\"The filename of the image to view.\"\n): str,\n}\n),\n}\n)\n# ...\n#...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#rename-the-method","title":"Rename the method","text":"<p>The method is still named <code>reverse_string</code>. Let's rename it to what we're actually doing - displaying the image.</p> display_image_tool/tool.py<pre><code># ...\n@define\nclass DisplayImageTool(BaseTool):\n@activity(\n#..\n)\ndef display_image(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\n# ...\n#...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#get-the-parameter","title":"Get the Parameter","text":"<p>We're passing the <code>filename</code> as a parameter, so let's make sure we grab that value right away. Update <code>input_value = params[\"values\"].get(\"input\")</code> so we're getting the filename, and for now just return the <code>filename</code> from the method. Here's what the whole method should look like:</p> <pre><code># ...\nclass DisplayImageTool(BaseTool):\n# ...\ndef display_image(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nfilename = params[\"values\"].get(\"filename\")\ntry:\nreturn TextArtifact(filename)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#import-libraries","title":"Import Libraries","text":"<p>In order to display the image, we need a bit of code that will work on Mac, Windows, and Linux. Our goal is to simply open the image in whatever image viewer the user likes to use.</p> <p>The <code>sys</code> module has a variable called <code>platform</code> that can get the operating system. Then, depending on the operating system we'll need one of two different methods to call. Windows uses <code>os.startfile</code>, and both Mac and Linux use the <code>subprocess</code> library.</p> <p>Let's start by importing the three libraries required, then we'll create the function.</p> <p>In the <code>imports</code> section of <code>tool.py</code>, add the following:</p> <pre><code># ...\nimport os, subprocess, sys\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#create-open_image","title":"Create open_image","text":"<p>Now we can create the function to open the image. It will take a filepath, and then depending on the operating system use the correct command to open the image.</p> <p>Add the following function after you import the libraries, but before <code>@define</code>.</p> display_image_tool/tool.py<pre><code># ...\n# Open an image\ndef open_image(filename):\nif sys.platform == \"win32\":\nos.startfile(filename)\nelif sys.platform == \"darwin\":  # macOS\nsubprocess.run([\"open\", filename])\nelse:  # linux variants\nsubprocess.run([\"xdg-open\", filename])\n@define\nclass DisplayImageTool(BaseTool):\n# ...\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#open-image","title":"Open Image","text":"<p>Now we can use the function to attempt to open an image.</p> <p>Inside the <code>try:</code> statement for the <code>display_image</code> method, use the <code>open_image</code> function and pass it <code>filename</code>.</p> display_image_tool/tool.py<pre><code># ...\nclass DisplayImageTool(BaseTool):\n@activity(\n# ...    \n)\ndef display_image(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nfilename = params[\"values\"].get(\"filename\")\ntry:\nopen_image(filename)\nreturn TextArtifact(filename)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#final-toolpy","title":"Final <code>tool.py</code>","text":"<p>Let's look at the resulting <code>tool.py</code> and make sure all the changes are present.</p> display_image_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\nimport os, subprocess, sys\n# Open an image\ndef open_image(filename):\nif sys.platform == \"win32\":\nos.startfile(filename)\nelif sys.platform == \"darwin\":  # macOS\nsubprocess.run([\"open\", filename])\nelse:  # linux variants\nsubprocess.run([\"xdg-open\", filename])\n@define\nclass DisplayImageTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to display an image\",\n\"schema\": Schema(\n{\nLiteral(\n\"filename\", description=\"The filename of the image to view.\"\n): str,\n}\n),\n}\n)\ndef display_image(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nfilename = params[\"values\"].get(\"filename\")\ntry:\nopen_image(filename)\nreturn TextArtifact(filename)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#update-apppy","title":"Update app.py","text":"<p>Now that we have the tool, let's update our application to use it.</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#import-displayimagetool","title":"Import DisplayImageTool","text":"<p>Just like we imported the <code>ReverseStringTool</code> in the previous lesson, we need to import the <code>DisplayImageTool</code> into our application in order to use it.</p> <p>Add the following import statement in the imports section of your <code>app.py</code> (note: we're back working on <code>app.py</code>, not <code>test_tool.py</code>):</p> app.py<pre><code># ...\nfrom display_image_tool import DisplayImageTool\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#update-display_image_task","title":"Update display_image_task","text":"<p>Change the <code>display_image_task</code> from a <code>PromptTask</code> to a <code>ToolkitTask</code>. Then we can pass it the <code>DisplayImageTool</code>, and modify the prompt to not say \"Pretend\" to display an image, but just go ahead and display it.</p> app.py<pre><code># ...\ndisplay_image_task = ToolkitTask(\n\"\"\"\n    Display the image to the user.\n    {{output_dir}}/{{ parent.output.name }}\n    \"\"\",\ncontext={\"output_dir\": output_dir},\ntools=[DisplayImageTool(off_prompt=False)],\nid=\"Display Image Task\",\n)\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#test-it-out","title":"Test it out","text":"<p>Go ahead and run the code. If everything works as expected, after the Pipeline finishes you an image viewer will open up with a beautiful image!</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#_1","title":"Displaying Images","text":""},{"location":"courses/create-image-pipeline/07_display_image_tool/#code-review","title":"Code Review","text":"<p>You can now generate an image and display it using a Pipeline. Excellent work! Let's review the current state of our application and tools:</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#apppy","title":"app.py","text":"app.py<pre><code>from dotenv import load_dotenv\n# Griptape\nfrom griptape.structures import Pipeline\nfrom griptape.tasks import PromptTask, ImageGenerationTask, ToolkitTask\nfrom griptape.drivers import OpenAiDalleImageGenerationDriver\nfrom griptape.engines import ImageGenerationEngine\nfrom display_image_tool import DisplayImageTool\nload_dotenv()  # Load your environment\n# Variables\noutput_dir = \"./images\"\n# Create the driver\nimage_driver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", api_type=\"open_ai\", image_size=\"1024x1024\"\n)\n# Create the engine\nimage_engine = ImageGenerationEngine(image_generation_driver=image_driver)\n# Create the pipeline object\npipeline = Pipeline()\n# Create tasks\ncreate_prompt_task = PromptTask(\n\"\"\"\n    Create a prompt for an Image Generation pipeline for the following topic: \n    {{ args[0] }}\n    in the style of {{ style }}.\n    \"\"\",\ncontext={\"style\": \"a 1970s polaroid\"},\nid=\"Create Prompt Task\",\n)\ngenerate_image_task = ImageGenerationTask(\n\"{{ parent_output }}\",\nimage_generation_engine=image_engine,\noutput_dir=output_dir,\nid=\"Generate Image Task\",\n)\ndisplay_image_task = ToolkitTask(\n\"\"\"\n    Display the image to the user.\n    {{output_dir}}/{{ parent.output.name }}\n    \"\"\",\ncontext={\"output_dir\": output_dir},\ntools=[DisplayImageTool(off_prompt=False)],\nid=\"Display Image Task\",\n)\n# Add tasks to pipeline\npipeline.add_tasks(create_prompt_task, generate_image_task, display_image_task)\n# Run the pipeline\npipeline.run(\"a cow\")\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#display_image_tooltoolpy","title":"display_image_tool/tool.py","text":"display_image_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\nimport os, subprocess, sys\n# Open an image\ndef open_image(filename):\nif sys.platform == \"win32\":\nos.startfile(filename)\nelif sys.platform == \"darwin\":  # macOS\nsubprocess.run([\"open\", filename])\nelse:  # linux variants\nsubprocess.run([\"xdg-open\", filename])\n@define\nclass DisplayImageTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to display an image\",\n\"schema\": Schema(\n{\nLiteral(\n\"filename\", description=\"The filename of the image to view.\"\n): str,\n}\n),\n}\n)\ndef display_image(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nfilename = params[\"values\"].get(\"filename\")\ntry:\nopen_image(filename)\nreturn TextArtifact(filename)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#display_image_toolinitpy","title":"display_image_tool/init.py","text":"display_image_tool/__init__.py<pre><code>from .tool import DisplayImageTool\n__all__ = [\"DisplayImageTool\"]\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#display_image_toolmanifestyml","title":"display_image_tool/manifest.yml","text":"display_image_tool/manifest.yml<pre><code>version: \"v1\"\nname: Display Image Tool\ndescription: Tool for displaying an image\ncontact_email: contact@example.com\nlegal_info_url: https://www.example.com/legal\n</code></pre>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#are-we-there-yet","title":"Are we there yet?","text":"<p>Congratulations! At this point, you have completed the main requirements for this course! You've built a pipeline that can execute multiple tasks to generate and display an image! You could high-five yourself, call your friends and brag about your accomplishments, and go eat a nice pizza to celebrate.</p> <p></p> <p>Or... continue with the next steps and learn more about various parameters for DALL\u00b7E 3, Leonardo.Ai, and Amazon Bedrock image generation.</p>"},{"location":"courses/create-image-pipeline/07_display_image_tool/#next-step","title":"Next Step","text":"<p>Let's take a look at some of the attributes available to us with each of the Image Generation Drivers available in Griptape. Let's start with OpenAI DALL\u00b7E 3.</p>"},{"location":"courses/create-image-pipeline/08_dalle-3/","title":"DALL\u00b7E 3","text":""},{"location":"courses/create-image-pipeline/08_dalle-3/#overview","title":"Overview","text":"<p>You've been creating images using DALL\u00b7E 3 in this course so far, but you've been using some basic attributes with the <code>OpenAiDalleImageGenerationDriver</code>. Let's take a look at some of the other attributes available in Griptape.</p> <p>Here's an example of calling driver with various attributes set:</p> <pre><code>image_driver = OpenAiDalleImageGenerationDriver(\nmodel=\"dall-e-3\", \napi_type=\"open_ai\", \nimage_size=\"1024x1024\", \nstyle=\"natural\", \nquality=\"hd\"\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/08_dalle-3/#finding-the-attributes","title":"Finding the attributes","text":"<p>Drivers may change over time. At the time of this writing, certain attributes are available - but this is guaranteed to evolve. To stay up to date, it's recommended to review the Driver Classes periodically to see what the attributes are.</p> <p>To see them, simply hover over the <code>OpenAiDalleImageGenerationDriver</code> in Visual Studio Code and Ctrl click, Cmd click, or choose <code>Right Mouse Button --&gt; Go to Definition..</code>. This will open the class in a new tab.</p> <p>As of December 19, 2023 the attributes availaboe for the <code>OpenAiDalleeImageGenerationDriver</code> are:</p> <pre><code>model: OpenAI DALLE model, for example 'dall-e-2' or 'dall-e-3'.\napi_type: OpenAI API type, for example 'open_ai' or 'azure'.\napi_version: API version.\nbase_url: API URL.\napi_key: OpenAI API key.\norganization: OpenAI organization ID.\nstyle: Optional and only supported for dall-e-3, can be either 'vivid' or 'natural'.\nquality: Optional and only supported for dall-e-3. Accepts 'standard', 'hd'.\nimage_size: Size of the generated image. Must be one of the following, depending on the requested model:\ndall-e-2: [256x256, 512x512, 1024x1024]\ndall-e-3: [1024x1024, 1024x1792, 1792x1024]\nresponse_format: The response format. Currently only supports 'b64_json' which will return\na base64 encoded image in a JSON object.\n</code></pre> <p>We will cover the most commonly edited attributes.</p>"},{"location":"courses/create-image-pipeline/08_dalle-3/#model-selection","title":"Model Selection","text":"<p>Griptape provides access to two different OpenAI DALL\u00b7E models, DALL\u00b7E 2 and DALL\u00b7E 3. To choose them, you'll set <code>model</code> to either <code>dall-e-2</code> or <code>dall-e-3</code>.</p> <p>There are different attributes available, depending on the model.</p> <p><pre><code>OpenAiDalleImageGenerationDriver( model=\"dall-e-3\" ) # DALL\u00b7E 3\n</code></pre> <pre><code>OpenAiDalleImageGenerationDriver( model=\"dall-e-2\" ) # DALL\u00b7E 2\n</code></pre></p>"},{"location":"courses/create-image-pipeline/08_dalle-3/#size","title":"Size","text":"<p>It's possible to specify the size of the resulting images. Depending on which model you choose, you have a different series of sizes.</p> <p>When using DALL\u00b7E 3, you have access to 3 sizes: <code>1024x1024</code>, <code>1024x1792</code>, and <code>1792x1024</code>. DALL\u00b7E 2 allows for <code>256x256</code>, <code>512x512</code>, <code>1024x1024</code>.</p> <p>Set the size using the <code>image_size</code> attribute:</p> <pre><code>OpenAiDalleImageGenerationDriver( \nmodel=\"dall-e-3\",\nimage_size: \"1024x1024\" \n) \n</code></pre>"},{"location":"courses/create-image-pipeline/08_dalle-3/#style","title":"Style","text":"<p>This attribute is only supported for DALL\u00b7E 3. It can be either 'vivid' or 'natural'. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. Defaults to \u2018vivid\u2019. </p> <p>Here are two examples of pineapples created with the same prompt we've been using - a 1970s polaroid. The image on the left is the \"natural\" image, and the one on the right is \"vivid\".</p> <pre><code>OpenAiDalleImageGenerationDriver( \nmodel=\"dall-e-3\",\nstyle=\"vivid\"\n) \n</code></pre>"},{"location":"courses/create-image-pipeline/08_dalle-3/#quality","title":"Quality","text":"<p>Also only for DALL\u00b7E 3, you can specify the <code>quality</code> of the resulting image. \u2018hd\u2019 creates images with finer details and greater consistency across the image. Defaults to \u2018standard\u2019.</p> <p>With the images below, the left is <code>standard</code>, right is <code>hd</code>.</p> <pre><code>OpenAiDalleImageGenerationDriver( \nmodel=\"dall-e-3\",\nquality=\"hd\"\n) \n</code></pre>"},{"location":"courses/create-image-pipeline/08_dalle-3/#api-type","title":"API Type","text":"<p>You can choose which API you'd like to use. Griptape allows either <code>open_ai</code> or <code>azure</code> if you're using DALL\u00b7E on Microsoft Azure.</p>"},{"location":"courses/create-image-pipeline/08_dalle-3/#next-step","title":"Next Step","text":"<p>Learn more about using Leonardo.ai in the next section.</p>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/","title":"Leonardo.AI","text":""},{"location":"courses/create-image-pipeline/09_leonardo-ai/#overview","title":"Overview","text":"<p>Leonardo.Ai is a powerful image generation model that offers some fantastic options. Two notable ones are the ability to train and utilize a model to achieve a specific graphic style. Another is the ability to set a <code>seed</code> value - providing more consistent output.</p> <p>The following two images are from the same prompt, but using different models.</p>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#getting-a-key","title":"Getting a Key","text":"<p>To use Leonardo.Ai you will need an API key.</p> <ul> <li>Sign up for a Leonardo.Ai account</li> <li>Save your <code>LEONARDO_API_KEY</code> in your <code>.env</code> file.</li> </ul>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#importing","title":"Importing","text":"<p>Update your <code>imports</code> section to import the <code>LeonardoImageGenerationDriver</code> and <code>os</code> so you can get the API Key environment variable.</p> <pre><code># ...\nfrom griptape.drivers import LeonardoImageGenerationDriver\n# ...\nimport os\n</code></pre>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#create-the-driver","title":"Create the Driver","text":"<p>When creating the driver, you can specify the <code>LeonardoImageGenerationDriver</code> instead of <code>OpenAiDalleImageGenerationDriver</code>. It has some similar attributes to the OpenAi driver, but there are a few notable differences.</p> <p>At a minimum, you must specify the <code>model</code> and the <code>api_key</code>. This example uses the Leonardo Vision XL model - a versatile model that excels at realism and photography.</p> <pre><code># Create the driver\nimage_driver = LeonardoImageGenerationDriver(\napi_key=os.getenv(\"LEONARDO_API_KEY\"),\nmodel=\"5c232a9e-9061-4777-980a-ddc8e65647c6\", \n)\n</code></pre> <p>Below is the full list of attributes that are available.</p> <pre><code>model: The ID of the model to use when generating images.\napi_key: The API key to use when making requests to the Leonardo API.\nrequests_session: The requests session to use when making requests to the Leonardo API.\napi_base: The base URL of the Leonardo API.\nmax_attempts: The maximum number of times to poll the Leonardo API for a completed image.\nimage_width: The width of the generated image in the range [32, 1024] and divisible by 8.\nimage_height: The height of the generated image in the range [32, 1024] and divisible by 8.\nsteps: Optionally specify the number of inference steps to run for each image generation request, [30, 60].\nseed: Optionally provide a consistent seed to generation requests, increasing consistency in output.\n</code></pre>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#api-key","title":"API Key","text":"<p>If you have set the <code>LEONARDO_API_KEY</code> in your <code>.env</code> file, and imported the <code>os</code> library, you can specify it when you load the driver:</p> <pre><code># Create the driver\nimage_driver = LeonardoImageGenerationDriver(\napi_key=os.getenv(\"LEONARDO_API_KEY\"),\n# ...\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#model-selection","title":"Model Selection","text":"<p>Leonardo.Ai's model selection is vast. To find a particular model, I highly recommend viewing their Platform Model Library. </p> <p></p> <p>To choose a particular model, you'll need to find the model ID. To find the ID:</p> <ol> <li>Click on the image of the model you're interested in.</li> <li> <p>A modal will appear with more information about the model. You'll see the Name, the Description, and more.</p> <p></p> </li> <li> <p>Click View More --&gt; to open a more detailed page about this model.</p> <p></p> </li> <li> <p>Select the model ID and copy it. It's the long string of random characters located under the name of the model. It should look something like: <code>5c232a9e-9061-4777-980a-ddc8e65647c6</code>.</p> </li> <li> <p>Use that string in your code:</p> <pre><code># Create the driver\nimage_driver = LeonardoImageGenerationDriver(\n# ...\nmodel=\"5c232a9e-9061-4777-980a-ddc8e65647c6\", \n)\n</code></pre> </li> </ol>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#size","title":"Size","text":"<p>It's possible to specify the size of the resulting images. Leonardo.Ai allows you to specify width and height directly using <code>image_width</code> and <code>image_height</code>. Important - values must be between <code>32</code> and <code>1024</code>, and be a multiple of <code>8</code>.</p> <p>Examples: <code>32</code>, <code>64</code>, <code>128</code>, <code>512</code>, <code>1024</code></p> <pre><code>LeonardoImageGenerationDriver( \nmodel=\"5c232a9e-9061-4777-980a-ddc8e65647c6\",\nimage_height: 1024,\nimage_width: 512,\n) \n</code></pre> <p></p>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#seed","title":"Seed","text":"<p>The seed attribute is great for ensuring consistent results. For example, here are 3 images created with the same seed. Note the consistent quality:</p> <p> </p> <pre><code>image_driver = LeonardoImageGenerationDriver(\nseed=\"42\",\n# ...\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#steps","title":"Steps","text":"<p>The steps allow you to identify the number of inference steps (iterations) to run for each image generation request. The number of steps often correlates with the quality and coherence of the final image.</p> <p>Here are three images of a frog on a skateboard, with inference steps set to <code>10</code>, <code>30</code>, and <code>60</code></p> <pre><code>image_driver = LeonardoImageGenerationDriver(\nsteps=60,\n# ...\n)\n</code></pre> <p>```</p>"},{"location":"courses/create-image-pipeline/09_leonardo-ai/#next-step","title":"Next Step","text":"<p>Another option is to use Amazon Bedrock and their image models. Check out the next section for details.</p>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/","title":"Amazon Bedrock","text":""},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#overview","title":"Overview","text":"<p>Amazon Bedrock offers a couple of different image generation models, and thus the method of using them is slightly different than DALL\u00b7E 3 and Leonardo.Ai.</p> <p>Instead of just importing one driver, you import <code>AmazonBedrockImageGenerationDriver</code> and then the model driver: <code>AmazonBedrockStableDiffusionImageGenerationModelDriver</code> or <code>AmazonBedrockTitanImageGenerationModelDriver</code>.</p> <p>When specifying which model driver, you also will need to specify the <code>model</code> in the <code>AmazonBedrockImageGenerationDriver</code>.</p> <p>It looks something like:</p> <pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nmodel=\"stability.stable-diffusion-xl-v0\", # Model Definition\nimage_generation_model_driver=AmazonBedrockStableDiffusionImageGenerationModelDriver(), # Driver\n# ...\n)\n</code></pre> <p>We'll get into the specifics, but first it's important to ensure you have access to Amazon Bedrock, as it's a requirement to use either of these two models.</p>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#aws-access","title":"AWS Access","text":"<ul> <li>Ensure you have an AWS account</li> <li>Ensure you have access to the appropriate model by following the Amazon Documentation</li> <li>Add the following environment variables to your <code>.env</code> file:<ul> <li><code>AWS_REGION_NAME</code></li> <li><code>AWS_ACCESS_KEY_ID</code></li> <li><code>AWS_SECRET_ACCESS_KEY</code></li> </ul> </li> </ul>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#boto3","title":"boto3","text":"<p>You'll need to use <code>boto3</code> to access Amazon Bedrock. </p> <p>To install <code>boto3</code> by going to your terminal inside Visual Studio Code and:</p> <ul> <li>If using <code>pip</code>, type:     <pre><code>pip install boto3\n</code></pre></li> <li>If using <code>poetry</code> type:     <pre><code>poetry add boto3\n</code></pre></li> </ul>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#import","title":"Import","text":"<p>Let's import boto3, os, and all three drivers, and then we'll discuss their differences.</p> <p>In your <code>app.py</code> imports section, add the three drivers:</p> <pre><code># ...\nimport boto3\nimport os\n# ...\nfrom griptape.drivers import (\nAmazonBedrockImageGenerationDriver,\nAmazonBedrockStableDiffusionImageGenerationModelDriver,\nAmazonBedrockTitanImageGenerationModelDriver\n)\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#create-a-session","title":"Create a session","text":"<p>You will need a <code>boto3</code> session to pass to <code>AmazonBedrockImageGenerationDriver</code>. I recommend you create this after the <code># Variables</code> section of your code:</p> <pre><code># ...\n# Boto3\nsession = boto3.Session(\nregion_name=os.getenv(\"AWS_REGION_NAME\"),\naws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\naws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n)\n# ...\n</code></pre>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#image-driver","title":"Image Driver","text":"<p>To create the Image Driver, you're going to specify three attributes:</p> <ul> <li><code>session</code> : This is the boto3 session you created earlier.</li> <li> <p><code>model</code> : This is the particular model you will be using. The list of models you have available to your account is in the AWS Console here. Here are some examples you may have access to:</p> <ul> <li><code>amazon.titan-image-generator-v1</code></li> <li><code>stability.stable-diffusion-xl-v0</code></li> </ul> <p>Tip</p> <p>To get a list of all the models you have access to, you can add the following code after you defined <code>session</code>: <pre><code>bedrock = session.client(\"bedrock\")\nmodels = bedrock.list_foundation_models()\nfor model in models[\"modelSummaries\"]:\nif model[\"outputModalities\"] == [\"IMAGE\"]:\nprint(model[\"modelId\"])    \n</code></pre></p> <p>This will print a list of all models you should be able to use. </p> <ul> <li><code>image_generation_model_driver</code> : This is the specific Model Driver Class you imported above.</li> </ul> <p>Important</p> <p>You must specify the correct <code>model</code> for the <code>image_generation_model_driver</code> you're using. Specifying a <code>titan</code> model with <code>StableDiffusion</code> won't work.</p> </li> </ul>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#attributes","title":"Attributes","text":"<p>Below is the full list of attributes available.</p> <pre><code>model: Bedrock model ID.\nsession: boto3 session.\nbedrock_client: Bedrock runtime client.\nimage_width: Width of output images. Defaults to 512 and must be a multiple of 64.\nimage_height: Height of output images. Defaults to 512 and must be a multiple of 64.\nseed: Optionally provide a consistent seed to generation requests, increasing consistency in output.\nimage_generation_model_driver: Image Generation Model Driver to use.\n</code></pre>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#stable-diffusion","title":"Stable Diffusion","text":"<p>Here's an example of a simple driver using Stable Diffusion. Notice the <code>model</code> and the <code>image_generation_model_driver</code> are both set.</p> <pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nsession=session,\nmodel=\"stability.stable-diffusion-xl-v0\",\nimage_generation_model_driver=AmazonBedrockStableDiffusionImageGenerationModelDriver(),\n)\n</code></pre> <p>There are a number of attributes available for Stable Diffusion. We'll cover details of a few key ones.</p> <pre><code>cfg_scale: How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt). The default is 7. style_preset: Pass in a style preset to guide the image model towards a particular style. clip_guidance_preset: CLIP Guidance is a technique that uses the CLIP neural network to guide the generation of images to be more in-line with your included prompt, which often results in improved coherency.\nsampler: Which sampler to use for the diffusion process. If this value is omitted it automatically selects an appropriate sampler.\nsteps: The number of diffusion steps to run. The default is 30.\n</code></pre>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#style_preset","title":"style_preset","text":"<p>The <code>style_preset</code> is a fun one to work with. Instead of modifying the prompt, you can try various styles. Here are some variations of <code>bear on a skateboard</code> - still with the 1970s polaroid theme, but passing different <code>style presets</code>. </p> <p>In order they're: <code>line-art</code>, <code>neon-punk</code>, <code>photographic</code>.</p> <pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nsession=session,\nmodel=\"stability.stable-diffusion-xl-v0\",\nimage_generation_model_driver=AmazonBedrockStableDiffusionImageGenerationModelDriver(\nstyle_preset=\"neon-punk\",\n),\n)\n</code></pre> <p>The full options available are: <code>3d-model</code> <code>analog-film</code> <code>anime</code> <code>cinematic</code> <code>comic-book</code> <code>digital-art</code> <code>enhance</code> <code>fantasy-art</code> <code>isometric</code> <code>line-art</code> <code>low-poly</code> <code>modeling-compound</code> <code>neon-punk</code> <code>origami</code> <code>photographic</code> <code>pixel-art</code> <code>tile-texture</code></p>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#sampler","title":"Sampler","text":"<p>Which sampler to use for the diffusion process. The default is <code>K_DPMPP_2M</code>. This can be quite confusing, so there's a helpful guide here about which samplers to use: https://stable-diffusion-art.com/samplers/.</p> <pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nsession=session,\nmodel=\"stability.stable-diffusion-xl-v0\",\nimage_generation_model_driver=AmazonBedrockStableDiffusionImageGenerationModelDriver(\nsampler=\"K_DPM_2\",\n),\n)\n</code></pre> <p>The options available are: <code>DDIM</code> <code>DDPM</code> <code>K_DPMPP_2M</code> <code>K_DPMPP_2S_ANCESTRAL</code> <code>K_DPM_2</code> <code>K_DPM_2_ANCESTRAL</code> <code>K_EULER</code> <code>K_EULER_ANCESTRAL</code> <code>K_HEUN</code> <code>K_LMS</code></p>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#clip-guidance","title":"CLIP guidance","text":"<p>The <code>clip_guidance_preset</code> uses a neural network to guide the generation of images. You can see more information about it in the Stable Diffusion documentation.</p> <p>CLIP guidance only works when using an ANCESTRAL sampler.</p> <p><pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nsession=session,\nmodel=\"stability.stable-diffusion-xl-v0\",\nimage_generation_model_driver=AmazonBedrockStableDiffusionImageGenerationModelDriver(\nclip_guidance_preset=\"SLOWEST\",\n),\n)\n</code></pre> The full options available are: <code>FAST_BLUE</code> <code>FAST_GREEN</code> <code>NONE</code> <code>SIMPLE</code> <code>SLOW</code> <code>SLOWER</code> <code>SLOWEST</code>.</p> <p>Try out different options to see what works best for your use case. Here are three examples using <code>NONE</code>, <code>FAST_BLUE</code>, and <code>SLOWEST</code>.</p>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#bedrock-titan","title":"Bedrock Titan","text":"<p>The <code>AmazonBedrockTitanImageGenerationModelDriver</code> utilizes Amazon Titan for image generation. </p> <p>It currently has a few options, with more being added soon. The current list is:</p> <pre><code>task_type: The default is TEXT_IMAGE. quality: 'standard' or 'premium'.\ncfg_scale: How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt). The default is 7.\n</code></pre> <p>Here's an example, of using it while setting <code>quality</code> and image height/width.</p> <pre><code>image_driver = AmazonBedrockImageGenerationDriver(\nsession=session,\nmodel=\"amazon.titan-image-generator-v1\",\nimage_generation_model_driver=AmazonBedrockTitanImageGenerationModelDriver(\nquality='premium'\n),\nimage_height=1024,\nimage_width=1024,\n)\n</code></pre>"},{"location":"courses/create-image-pipeline/10_amazon-bedrock/#finished","title":"Finished","text":"<p>Success</p> <p>Congratulations! You have created a successful Griptape Image Generation Pipeline!</p> <p>Fantastic work, you've successfully created a Griptape Pipeline that allows you to consistently execute a series of steps to generate an image.</p> <p>You have learned how to:</p> <ul> <li>Create tasks that can handle prompts and tools.</li> <li>Learned a bit about Jinja2 templates.</li> <li>Create parent/child relationships.</li> <li>Use Image Generation Tasks.</li> <li>Create your own Custom Tools.</li> </ul> <p>We hope you enjoyed this course, and look forward to seeing what you're able to create with these new skills. If you'd like to take things further, try and see how you can implement pipelines into your existing workflows! Share your results in our Discord!</p>"},{"location":"courses/shotgrid-client/","title":"Griptape and ShotGrid: A Practical Approach to Tool Integration","text":""},{"location":"courses/shotgrid-client/#course-description","title":"Course Description","text":"<p>This course offers a friendly and accessible path to understand how Griptape Tools, functioning as specialized Python classes, enable Language Learning Models (LLMs) to interface with external APIs and datasets, thus broadening their operational scope.</p> <p>At the end of this course, you will have working Python code for a Griptape Tool that enables a Griptape Agent to invoke capabilities from Autodesk ShotGrid. Imagine commanding the chatbot to \"Create 20 assets for a 1950's kitchen counter, give them relevant descriptions, and set up initial task dependencies.\" This scenario encapsulates the kind of interactive and practical tasks you will be able to accomplish. </p>"},{"location":"courses/shotgrid-client/#what-is-shotgrid","title":"What is ShotGrid?","text":"<p>ShotGrid is Autodesk's production management software. It is used mainly to manage Media and Entertainment (Games, Film, Commercials, etc) productions. You can track deadlines, manage budgets, create and manage asset development, collaborate with others, and more. </p> <p>It's got a rich Python API, which many studios have used to integrate with various software tools like Autodesk Maya, SideFX Houdini, Foundry Nuke, and many others.</p>"},{"location":"courses/shotgrid-client/#who-is-this-course-for","title":"Who is this course for","text":"<p>This course is specifically designed for a diverse group of learners.</p> <ul> <li> <p>Intermediate-Level Python Developers: If you have a solid grounding in Python and are looking to broaden your skill set, this course will introduce you to the exciting world of Griptape Tools. It's perfect for those who want to learn how to develop and implement these tools in various contexts, adding a valuable dimension to their programming expertise.</p> </li> <li> <p>Pipeline Technical Directors in the Entertainment Industry: For professionals involved in managing and optimizing content creation pipelines, this course offers insights into integrating LLMs into existing workflows. Whether you're working in film, animation, or gaming, the skills learned here will empower you to leverage LLMs for enhanced efficiency and innovation in your projects.</p> </li> <li> <p>Tool Makers and Developers: If you're in the business of creating tools and applications, this course will show you how to integrate LLMs using Griptape. It's an opportunity to see how LLMs can add advanced capabilities to your products, making them more dynamic and intelligent.</p> </li> </ul>"},{"location":"courses/shotgrid-client/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this course, you will need:</p> <ul> <li>An OpenAI API Key (available here: https://beta.openai.com/account/api-keys){target=\"_blank\"}</li> <li>Python3.9+ installed on your machine</li> <li>An IDE (such as Visual Studio Code or PyCharm) to write and manage your code</li> </ul> <p>If you don't have those items available, it's highly recommended you go through the Griptape Setup - Visual Studio Code course to set up your environment.</p> <p>Note</p> <p>If you don't currently have an Autodesk ShotGrid subscription, that's okay. We'll take you through the process of signing up for a free trial in the second module.</p>"},{"location":"courses/shotgrid-client/#course-outline","title":"Course Outline","text":"<p>The course will cover:</p> <ul> <li>Signing up for Autodesk ShotGrid</li> <li>Using Griptape Tools</li> <li>Creating your first tool</li> <li>Extending your tool with different activities</li> <li>Creating your first ShotGrid client tool</li> <li>Using the tool with an Agent</li> <li>Directing the interaction with Rules and Rulesets</li> <li>Giving the Agent access to ShotGrid API docs for improved results</li> </ul>"},{"location":"courses/shotgrid-client/#useful-resources-and-links","title":"Useful Resources and Links","text":"<ul> <li>Griptape Documentation</li> <li>Visual Studio Code</li> <li>Jinja2 Documentation</li> <li>Autodesk ShotGrid</li> <li>Autodesk Shotgrid Python API</li> </ul>"},{"location":"courses/shotgrid-client/#next-steps","title":"Next Steps","text":"<p>Get yourself all set up and ready by moving on to Setup.</p>"},{"location":"courses/shotgrid-client/01_setup/","title":"Setup","text":"<p>As with any project, the first step is setting up your environment. Let's get started by ensuring you have a project structure ready to work with.</p> <p>Important</p> <p>Since this is an intermediate-level course, please ensure you've gone through the Griptape Setup - Visual Studio Code course to set up your environment. We will be starting from the code at that point.</p>"},{"location":"courses/shotgrid-client/01_setup/#create-a-project","title":"Create a Project","text":"<p>Following the instructions in Griptape Setup - Visual Studio Code  please:</p> <ol> <li>Create your project folder. Example: <code>griptape-shotgrid-tool</code></li> <li>Set up your virtual environment</li> <li>Ensure you <code>pip install griptape python-dotenv</code></li> <li>Create a <code>.env</code> file with your <code>OPENAI_API_KEY</code></li> <li>Create your <code>app.py</code> file with the following code:</li> </ol> app.py<pre><code>from dotenv import load_dotenv\nload_dotenv() # Load your environment\n</code></pre>"},{"location":"courses/shotgrid-client/01_setup/#next-steps","title":"Next Steps","text":"<p>And there we have it, your environment is all set up! In the next section,  we'll get started by using one of Griptape's built-in Tools (DateTime) and understand how it works.</p>"},{"location":"courses/shotgrid-client/02_shotgrid/","title":"Autodesk ShotGrid - Signup","text":"<p>Before we get started with the rest of the course, let's make sure you have access to Autodesk ShotGrid.</p> <p>If you don't already have an account, Autodesk does provide access to a 30-day free trial of ShotGrid, and you can even sign up without a credit card.</p> <p>Nice!</p> <p>Info</p> <p>This documentation will take you through the ShotGrid signup process as of December 2023. By the time you read this tutorial these steps may have changed, but hopefully, the concepts are still the same. </p>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>Follow these steps to sign up for the ShotGrid free trial:</p>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-1-visit-the-shotgrid-free-trial-signup-site","title":"Step 1: Visit the ShotGrid Free Trial Signup Site","text":"<ul> <li>Navigate to ShotGrid Free Trial Signup Site.</li> <li>Enter your email address in the provided field.</li> <li>Click on <code>GET STARTED</code>.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-2-create-an-account","title":"Step 2: Create an Account","text":"<ul> <li>Fill in your first name, last name, and email, and create a password.</li> <li>Agree to Autodesk's terms of use and privacy statement.</li> <li>Click on the confirmation button to proceed.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-3-verify-your-new-account","title":"Step 3: Verify Your New Account","text":"<ul> <li>Check your email for a verification link from ShotGrid.</li> <li>Click the link to verify your email address.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-4-complete-additional-information","title":"Step 4: Complete Additional Information","text":"<p>Once your email is verified, you will be redirected to a page where you need to enter more information:</p> <ul> <li>Enter your phone number.</li> <li>Select your country from the dropdown menu.</li> <li>Provide the name of your company.</li> <li>Create a name for your ShotGrid site (e.g., <code>griptape.shotgrid.autodesk.com</code>).</li> <li>... there are a few more questions, just go through them until ShotGrid says it's setting up your site.</li> </ul> <p>Wait for ShotGrid to create your site. This process may take a few minutes.</p>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-5-log-into-your-shotgrid-site","title":"Step 5: Log into Your ShotGrid Site","text":"<ul> <li>Once your site is ready, ShotGrid will send you an email notification.</li> <li>Click on the <code>Log into your site</code> button in the email.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-6-first-time-login-and-role-selection","title":"Step 6: First-Time Login and Role Selection","text":"<ul> <li>Upon first login, ShotGrid will inquire about your role (e.g., Technical Director / Pipeline Engineer). This isn't required, but select the role that best describes your position if you desire.</li> <li>Click <code>Submit</code> or <code>Skip</code>.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#step-7-take-a-tour-of-shotgrid-optional","title":"Step 7: Take a Tour of ShotGrid (Optional)","text":"<ul> <li>Autodesk offers a tour of ShotGrid for new users. You can choose <code>Next</code> to take the tour or <code>Skip Tour</code> to proceed directly to your dashboard.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#additional-resource","title":"Additional Resource","text":"<ul> <li>For those new to ShotGrid, it is recommended to watch this five-minute overview of ShotGrid.</li> </ul>"},{"location":"courses/shotgrid-client/02_shotgrid/#conclusion","title":"Conclusion","text":"<p>Congratulations! You should now see your ShotGrid desktop and are all set to start your 30-day trial! </p> <p></p>"},{"location":"courses/shotgrid-client/02_shotgrid/#next-steps","title":"Next Steps","text":"<p>Now that you have your environment set up and access to ShotGrid, you're ready to build your ShotGrid Tool that will allow an agent to connect and authenticate with it. </p>"},{"location":"courses/shotgrid-client/03_understanding_tools/","title":"Understanding Tools - DateTime","text":""},{"location":"courses/shotgrid-client/03_understanding_tools/#overview","title":"Overview","text":"<p>In this module, we will explore the DateTime Tool within Griptape, demonstrating its integration into an <code>Agent</code> and breaking down how activities function. We'll then show how you can use the tool in a <code>Pipeline</code> by employing <code>ToolTask</code> and <code>ToolkitTask</code>. </p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#what-is-a-griptape-tool","title":"What is a Griptape Tool?","text":"<p>Griptape Tools are like additional helpers when dealing with tasks that a Large Language Model (LLM) can't handle by itself. They expand the capabilities of a system, allowing it to connect with external applications and use specific Python functionalities that aren't part of the LLM's standard toolkit. Whether it's for an automated workflow, a data processing pipeline, or an interactive agent, Griptape Tools provides the extra abilities needed to tackle a wider range of problems and tasks, enhancing the overall functionality and efficiency of the system.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#setting-up-the-agent","title":"Setting up the Agent","text":"<p>Let's update our current app to give it access to an Agent so we can interact with the LLM.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#updating-the-app","title":"Updating the app","text":"<p>First, let's set up a basic Agent in our application. If you've taken the other courses, this should feel very familiar. Your current <code>app.py</code> file looks something like this:</p> app.py<pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre> <p>Let's add the lines to import the Agent and the Chat utility.</p> <pre><code># ... shortened for brevity\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\n# ...\n</code></pre> <p>Then we'll instantiate the Agent, and call it with the chat utility. Add the following lines at the end of the code.</p> <pre><code># ...\n# Instantiate the agent\nagent = Agent(stream=True)\n# Start chatting\nChat(agent).start()\n</code></pre> <p>Here's the code in its entirety:</p> app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nload_dotenv()\n# Instantiate the agent\nagent = Agent(stream=True)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#test-it-out","title":"Test it out","text":"<p>Now that you have an agent, let's give it a try by running the application. Remember, you can execute the app by using the <code>Run Python</code> button in the top right of your Visual Studio Code editor.</p> <p>When the application launches, you should see a prompt that looks like the following:</p> <pre><code>Q:\n</code></pre> <p>This is the prompt for the Chat, indicating you can now chat with the agent.</p> <p>Tip</p> <p>You may see a different prompt than <code>Q:</code>. We are currently experimenting with different prompt suggestions to find something more intuitive. If you want to specify the prompt explicitly, you can pass the <code>prompt_prefix</code> parameter to the <code>Chat</code> utility.</p> <pre><code>Chat(agent, prompt_prefix=\"Q: \").start()\n</code></pre> <p>Ask the agent: <code>\"What day is it?\"</code></p> <p>You will receive a response similar to this:</p> <pre><code>Q: What day is it?\nprocessing...\n[12/02/23 05:23:35] INFO     PromptTask 8774d4cf5d2e4630bce4937864a6dd81                                      \n                             Input: What day is it?                                                           \n[12/02/23 05:23:39] INFO     PromptTask 8774d4cf5d2e4630bce4937864a6dd81                                      \n                             Output: As an AI, I don't have real-time capabilities to provide the current     \n                             date. Please check your device for the current date.                             \nA: As an AI, I don't have real-time capabilities to provide the current date. Please check your device for the current date.\n</code></pre> <p>As you can see, the LLM does not have access to any tools that tell it what day it is. Luckily - Griptape provides one that does! The DateTime Tool!</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#adding-tools","title":"Adding Tools","text":"<p>Griptape Tools allow you to add functionality that Griptape Structures (Agents, Pipelines, Workflows) can use. We'll use the DateTime Tool to give the agent the ability to figure out the current time. </p> <p>Adding a Tool is a straightforward process. You <code>import</code> it, configure it if necessary, and then give it to the Agent (or task). Some Tools are more complicated than others, which is why we're getting started with a nice simple one.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#include-datetime","title":"Include DateTime","text":"<ul> <li> <p>Modify the import statements to include the DateTime Tool:</p> <pre><code># ...\nfrom griptape.tools import DateTime\n# ...\n</code></pre> </li> <li> <p>Next, provide the Tool to the agent. Agents can work with multiple Tools, so you will be adding it as a list. Modify the code where we instantiate the agent so it looks like:</p> <pre><code># ...\n# Instantiate the agent\nagent = Agent(tools=[DateTime(off_prompt=False)], stream=True)\n# ...\n</code></pre> <p>What is \"off_prompt\"?</p> <p>Important Note: Griptape directs outputs from Tool activities into short-term TaskMemory, keeping them 'off_prompt' and separate from the LLM. This makes it easy to work with big data securely and with low latency. To change this default for more direct interaction with the LLM, set the <code>off_prompt</code> parameter to <code>False</code>. This allows the LLM to access and respond to Tool outputs directly.</p> <p>DateTime</p> <p>For more information on the DateTime Tool, you can visit the DateTime Tool Documentation. </p> </li> </ul>"},{"location":"courses/shotgrid-client/03_understanding_tools/#try-it-again","title":"Try it again","text":"<ul> <li> <p>Run the application, and at the <code>Q:</code> prompt again ask what day it is.</p> <p>You'll see a very different response this time, something similar to the following:</p> <pre><code>Q: What day is it?\nprocessing...\n[12/02/23 06:07:08] INFO     ToolkitTask 0024a33acd8946deac94355ca92ccfde                                     \n                            Input: What day is it?                                                           \n[12/02/23 06:07:12] INFO     Subtask c9606eb9fbb243998e821fb0ebeb961a                                         \n                            Thought: To answer this question, I need to get the current date and time. I can \n                            use the \"get_current_datetime\" action for this.                                  \n\n                            Action:                                                                          \n                            {                                                                                \n                            \"name\": \"DateTime\",                                                            \n                            \"path\": \"get_current_datetime\",                                                \n                            \"input\": {}                                                                    \n                            }                                                                                \n                    INFO     Subtask c9606eb9fbb243998e821fb0ebeb961a                                         \n                            Response: 2023-12-02 06:07:12.902983                                             \n[12/02/23 06:07:15] INFO     ToolkitTask 0024a33acd8946deac94355ca92ccfde                                     \n                            Output: Today is December 2, 2023.                                               \nA: Today is December 2, 2023.\n</code></pre> </li> </ul> <p>Notice the highlighted section above. This is the <code>subtask</code>, where the Agent is using Chain-of-Thought to figure out what to do. It recognizes the need to use one of its activities - in this case, <code>get_current_datetime</code> to get the result.</p> <p>Take a look at the <code>Action</code>:</p> <pre><code>Action:\n{           \"name\": \"DateTime\", \"path\": \"get_current_datetime\",\n\"input\": {}   }                   </code></pre> <p>It's using the <code>DateTime</code> tool, with a method <code>get_current_datetime</code>, and no <code>inputs</code> (parameters).</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#tool-classes","title":"Tool Classes","text":""},{"location":"courses/shotgrid-client/03_understanding_tools/#the-datetime-class","title":"The DateTime Class","text":"<p>Let's take a look at the <code>DateTime</code> class itself and see if we can determine what's happening.</p> <ul> <li> <p>Find the line in your code where you <code>import</code> <code>DateTime</code>:</p> <pre><code>from griptape.tools import DateTime\n</code></pre> </li> <li> <p>Hover over <code>DateTime</code> and <code>Ctrl+Click</code> (<code>Cmd+Click</code> on Mac). This will open the DateTime class for Griptape in your editor.</p> <p>Tip</p> <p>In Visual Studio Code, you can navigate to the Definition of a class by using <code>Ctrl+Click</code> (<code>Cmd+Click</code> on Mac). See the documentation to learn more about Visual Studio Code tips for code navigation.</p> <p></p> <p>As you can see in the editor, this is the DateTime class, ready for you to inspect. Jumping around between definitions of classes and functions you use is a very handy way to learn more about how Tools are implemented. 10 stars - would highly recommend.</p> </li> </ul>"},{"location":"courses/shotgrid-client/03_understanding_tools/#tool-structure","title":"Tool Structure","text":"<p>In Griptape, a \"Tool\" is a <code>Class</code>. It is a blueprint that defines the properties and behaviors the Tool will have.</p> <p>Each Tool has <code>activities</code> and <code>methods</code>.</p> <pre><code># Example of a very simple class with an activity and method\nclass SayHello():\n@activity(config={\n\"description\": \"Can be used to say Hello!\"\n}\n)\ndef say_hello():\nreturn TextArtifact(\"Hello!\")\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#methods","title":"Methods","text":"<p>Methods define the actions that the Tool can perform. They are implemented as Python functions in the class. In the case of the <code>DateTime</code> Tool, it has a few methods - <code>get_current_datetime</code> and <code>get_relative_datetime</code>. They define specific actions it can perform.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#activities","title":"Activities","text":"<p>Activities tell the LLM what the action does and when it might want to use it - kind of like attaching a label or instruction. They are implemented as a decorator above the Python method. For example, the <code>@activity</code> decorator in <code>DateTime</code> describes what the <code>get_current_datetime</code> method does (\"Can be used to return current date and time\"), and how it should behave.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#datetime-structure","title":"DateTime Structure","text":"<p>Let's look specifically at the DateTime structure. I'll comment out details so we can keep it simple.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\n# ...\nexcept Exception as e:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English...\n): str\n}\n),\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\ntry:\n# ...\nexcept Exception as e:\n# ...\n</code></pre> <p>Notice there are two <code>methods</code>: <code>get_current_datetime</code> and <code>get_relative_datetime</code>.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n# ...\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\n</code></pre> <p>And each <code>method</code> has its associated <code>activity</code>.</p> <pre><code># ...\nclass DateTime(BaseTool):\n@activity(config={\"description\": \"Can be used to return current date and time.\"})\ndef get_current_datetime(self, _: dict) -&gt; BaseArtifact:\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to return a relative date and time.\",\n# ...\n}\n)\ndef get_relative_datetime(self, params: dict) -&gt; BaseArtifact:\n# ...\n</code></pre> <p>The LLM uses the description of the activities to figure out what it can do, and what the appropriate method is to call.</p> <p>In our earlier example, the Action taken was <code>get_current_datetime</code>:</p> <pre><code>Action:\n{           \"name\": \"DateTime\", \"path\": \"get_current_datetime\",\n\"input\": {}   }\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#methods_1","title":"Methods","text":""},{"location":"courses/shotgrid-client/03_understanding_tools/#basic-structure","title":"Basic Structure","text":"<p>Let's use the <code>get_current_datetime</code> to understand the structure of a method.</p> <pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <ul> <li><code>get_current_datetime</code>: This is the name of the method we are defining. </li> <li> <p><code>(self, _: dict)</code>: These are the parameters the method can take. <code>self</code> refers to the object itself (common in class methods), and <code>_</code> is a placeholder for a parameter that is a dictionary (<code>dict</code>), but this dictionary is not actively used in the method.</p> <p>Tip</p> <p>Neither of these are used in this particular method, but they're there because it's good practice to include them.</p> </li> <li> <p><code>-&gt; BaseArtifact</code>: This indicates that the method will return an object of type <code>BaseArtifact</code>. Griptape provides various artifacts, including Text, List, Blob, etc. You can learn more about them in the documentation. </p> </li> </ul> <p>Since we're not using <code>self</code>, or <code>_</code> in this method, and Python is a dynamically typed language, we don't need to specify what a function will return. We could probably write this method as:</p> <pre><code>def get_current_datetime():\n</code></pre> <p>However, including type hints in method definitions is good practice as it enhances the overall quality and maintainability of our code.</p> <p>In summary, he's a great way to understand the <code>def</code> line:</p> Item What it's used for <code>def</code> Let's define a method! <code>get_current_datetime</code> That's the name of my method! <code>(self, _: dict)</code> Some stuff we're passing to the method! <code>--&gt; BaseArtifact:</code> The stuff I want to get back from the method!"},{"location":"courses/shotgrid-client/03_understanding_tools/#try-except","title":"Try / Except","text":"<p>Moving further into the method, you'll see the <code>try</code> and <code>except</code> block. </p> <pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <ul> <li><code>try</code> Block:<ul> <li>The <code>try</code> keyword starts a block of code Python will attempt to execute. In this case, it's trying to get the current date and return it as a <code>TextArtifact</code> (more on text artifacts in the documentation). </li> <li>Think of it as saying \"Hey - give this a shot and see if it works?\"</li> </ul> </li> <li><code>except</code> Block:<ul> <li>Code doesn't always work as expected, and the <code>except</code> block is what happens if <code>try</code> encounters an error.</li> <li><code>Exception as e</code> part catches any error and stores it in a variable <code>e</code>.</li> <li>Simply put, the <code>except</code> block says \"If there was a problem in <code>try</code>, let's do this instead.</li> </ul> </li> </ul> <p>Using <code>try/except</code> is always a good practice, especially with Tools in Griptape. One of the benefits of using this is that <code>ErrorArtifacts</code> get passed back to Griptape. This means Griptape can evaluate the error, and try again - often fixing mistakes the LLM made in its query!</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#return","title":"Return","text":"<pre><code>def get_current_datetime(self, _: dict) -&gt; BaseArtifact:\ntry:\ncurrent_datetime = datetime.now()\nreturn TextArtifact(str(current_datetime))\nexcept Exception as e:\nreturn ErrorArtifact(f\"error getting current datetime: {e}\")\n</code></pre> <p>Finally, the <code>return</code> statements. Whatever is in these will be returned to the subtask in order to continue. As mentioned in the <code>try/except</code> section above, <code>ErrorArtifacts</code> are important to return because they will allow Griptape to try again.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#activities_1","title":"Activities","text":"<p>As mentioned previously, <code>activities</code> add information and certain features to methods. With Griptape Tools, they can provide simple information (like a description), or even schemas defining what kind of parameters should be passed.</p> <p>For the <code>get_current_datetime</code> method, there are no parameters, so the activity itself is quite simple - it's just a description that tells the LLM when to use it.</p> <pre><code>@activity(config={\"description\": \"Can be used to return current date and time.\"})\n</code></pre> <p>As you can see, any time the LLM determines the task is to return the current date and/or time, it will use this method.</p> <p>Notice with the <code>get_relative_datetime</code> method (the other method in the DateTime class) the activity is different - it says to return a relative date and time and also has a <code>schema</code> involved. We'll dive into this detail shortly - for now, let's just understand that any time the LLM thinks that its task is to return something about the current date and time, it will use the <code>get_current_datetime</code> method.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#more-testing","title":"More Testing","text":"<p>Let's experiment with different ways of requesting the current time. Try requesting for day, time, date, day of the month, time of year, etc. Notice how the LLM can handle all these different results, with only one method.</p> <pre><code>Q: What's the date?\nA: Today's date is December 2, 2023.\n\nQ: What day of the week is it?\nA: Today is Saturday.\n\nQ: What's the time in New Zealand?\nA: The current time in New Zealand is 07:58 on December 2, 2023.\n\nQ: What's the time if Yoda said it?\nA: The current time in Yoda's speech would be, \"58 past 7 it is.\"\n\nQ: What's the current time as Beaker from the Muppets?\nA: As Beaker from the Muppets, the current time would be expressed as, \"Meep meep, meep meep meep!\"\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#parameters","title":"Parameters","text":"<p>Sometimes you want an activity to take a specific parameter. In the case of the <code>DateTime</code> Tool, the <code>get_relative_datetime</code> needs to take a parameter to understand what the day should be relative to.</p> <p>Let's try it out. Run the app and ask how far away April 3rd is from today. Notice a few actions are happening now - the first is <code>get_current_datetime</code> to find out what \"today\" is, then the second is <code>get_relative_datetime</code> where it passes an input.</p> <pre><code>Action: {\"name\": \"DateTime\", \"path\": \"get_current_datetime\", \"input\": {}}\n\nAction: {\"name\": \"DateTime\", \"path\": \"get_relative_datetime\", \"input\": {\"values\": {\"relative_date_string\": \"April 3, 2024\"}}}\n</code></pre> <p>Before we dive into the parameters, there are two things worth pointing out:</p> <ol> <li>We didn't specify the number of steps it should take to get to the answer. We just asked one somewhat ambiguous question and the LLM figured out that it would take two tasks - getting the current date and then getting the relative date.</li> <li>We also didn't specify the <code>relative_date_string</code> key/value pair. We didn't need to. The LLM saw what key/value pairs the <code>get_relative_datetime</code> method required, and figured out how to pass them. </li> </ol> <p>This is why working with Griptape Tools starts to get exciting - once you define the parameters, the LLM can figure out the right way to pass the data.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#schema","title":"Schema","text":"<p>Schemas are how we define what parameters are going to be passed to the method. They are like a checklist for data. They're a set of rules that describe what kind of data you expect, and how it should be structured.</p> <p>For example, if you are creating a schema for a person you might say:</p> <ul> <li>There must be a name, and it should be text.</li> <li>There must be an age, and it should be a number.</li> <li>There might be an email address. If there is, it should be in the format of an email address. If not, well that's just okay with us.</li> </ul> <p>Then the method can use the schema as a checklist to make sure everything matches. If age is written as text instead of a number (for example), you know there's a mistake.</p> <p>You can learn more about Python schemas in the schema documentation.</p> <p>For Griptape Tool Activities, schemas are defined as part of the <code>config</code> dictionary using the <code>Schema</code> class.</p> <p>Let's look at the schema for <code>get_relative_datetime</code>:</p> <pre><code>config={\n\"description\": \"Can be used to return a relative date and time.\",\n\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English. For example, \"now EST\", \"20 minutes ago\", '\n'\"in 2 days\", \"3 months, 1 week and 1 day ago\", or \"yesterday at 2pm\"',\n): str\n}\n),\n}\n</code></pre> <p>Right now the Schema has one parameter it's looking for: <code>relative_date_string</code>. The <code>description</code> tells us what kind of data it should be. It says:</p> <pre><code>Relative date in English. For example or example, \"now EST\", \n\"20 minutes ago\", \"in 2 days\", \"3 months, 1 week and 1 day ago\", \nor \"yesterday at 2 pm\"\n</code></pre> <p>Finally, the <code>: str</code> part means the information should be provided as a string, which basically is just a line of text. This could also be <code>: int</code>, <code>: dict</code>, <code>: list</code>, etc depending on your needs.</p>"},{"location":"courses/shotgrid-client/03_understanding_tools/#optional-parameters","title":"Optional Parameters","text":"<p>It's possible to also provide optional parameters with Schemas. For example, if we were making our own version of DateTime we could include something like:</p> <pre><code>\"schema\": Schema(\n{\nLiteral(\n\"relative_date_string\",\ndescription='Relative date in English.',\n): str,\nOptional(\"timezone\"): str  # This is an optional parameter\n}\n),\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#code-review","title":"Code Review","text":"<p>Throughout this section, we've explored quite a bit about Griptape Tools. We learned how to import and use them, how they're structured, and what <code>methods</code> and <code>activities</code> are. You understand <code>schemas</code> and how they allow you to pass parameters to various <code>methods</code>.</p> <p>Before continuing, let's look at our app in its current state where you can chat with the agent and ask important questions, like how much time you have before my birthday (April 3rd).</p> app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nload_dotenv()\n# Instantiate the agent\nagent = Agent(tools=[DateTime(off_prompt=False)], stream=True)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/03_understanding_tools/#next-steps","title":"Next Steps","text":"<p>You have access to DateTime (not quite as cool as SpaceTime, but still..). In the next section, you will build your first Griptape Tool.</p>"},{"location":"courses/shotgrid-client/04_first_tool/","title":"Your First Tool","text":""},{"location":"courses/shotgrid-client/04_first_tool/#overview","title":"Overview","text":"<p>We'll use a Griptape Tool Template that's available on GitHub to create our first Tool, and then modify it slightly to demonstrate multiple activities.</p>"},{"location":"courses/shotgrid-client/04_first_tool/#getting-the-template","title":"Getting the template","text":"<p>The Tool template provided creates a <code>reverse_string</code> Tool. It will take any text and reverse it. It's a nice simple example of how to use a Tool with your LLM.</p> <p>The template contains examples of how to use the Tool, testing, and more. The idea is that you can take this template and publish your own Tool on GitHub to share with the world. </p> <p>For the purposes of this course, we'll keep things simple and just focus on the Tool itself, using the code to create our own as part of our current project.</p> <ol> <li>Navigate to the Gritptape tool-template repository on GitHub.</li> <li>Find the Code button and click on it.</li> <li> <p>Choose Download zip to download a zip file of the project.</p> <p>Info</p> <p>If you have a GitHub account and have experience with GitHub repos, you are more than welcome to choose Use this template and work the way you are comfortable. </p> </li> <li> <p>Extract the contents of the .zip file by double-clicking on it.</p> <p></p> <p>The reverse_string_tool folder is the one we are interested in, it contains the required files for the Tool. You can read more about them in the Griptape Custom Tool documentation.</p> </li> <li> <p>Copy the reverse_string_tool folder into the folder where your <code>app.py</code> file sits. </p> <p>Tip</p> <p>You can just drag the folder from your Finder or Windows Explorer and drop it directly into Visual Studio Code to copy it.</p> <p>You should now see the folder in Visual Studio Code next to <code>app.py</code> and <code>.env</code>.</p> <p></p> </li> </ol>"},{"location":"courses/shotgrid-client/04_first_tool/#use-reverse-string","title":"Use Reverse String","text":"<p>Here's the code for the Reverse String Tool (as of December 2023). I've highlighted some important lines from the code.</p> <pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema({Literal(\"input\", description=\"The string to be reversed\"): str}),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\nreturn TextArtifact(input_value[::-1])\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre> <p>The highlighted lines illustrate that the Tool (Class) is called <code>ReverseString</code>. It has one module, <code>reverse_string</code>. It has an <code>activity</code> that says it \"Can be used to reverse a string\", and it appears to take one parameter named <code>input</code> which is described as \"The string to be reversed\".</p>"},{"location":"courses/shotgrid-client/04_first_tool/#add-it-to-apppy","title":"Add it to app.py","text":"<p>Just like any other Griptape Tool, you need to <code>import</code> it. However, because this Tool isn't part of the default Griptape repository, the import line will look slightly different. Add the following line to <code>app.py</code>:</p> <pre><code># ...\nfrom reverse_string_tool import ReverseStringTool\n# ...\n</code></pre> <p>Tip</p> <p>How do you know to choose <code>reverse_string_tool</code> and <code>ReverseStringTool</code> in the <code>import</code> statement?</p> <p>The <code>__init__.py</code> file is a hint. You can think of that file as a sort of index or table of contents for the items in the folder. Its presence tells Python that the directory is a special kind of directory - a package from which you can import <code>modules</code>.</p> <p>Because I saw that <code>__init__.py</code> file, I knew I could import modules from that folder. </p>"},{"location":"courses/shotgrid-client/04_first_tool/#give-it-to-the-agent","title":"Give it to the agent","text":"<p>Remember, the agent takes a list of Tools. We can add this Tool to the agent by simply adding it to the list.</p> <p>Find the line where you instantiate the agent and add the <code>ReverseStringTool</code>:</p> <pre><code># ...\n# Instantiate the agent\nagent = Agent(tools=[DateTime(off_prompt=False), ReverseStringTool(off_prompt=False)])\n# ...\n</code></pre> <p>Notice the agent now has access to two Tools, <code>DateTime</code> and <code>ReverseStringTool</code>. </p>"},{"location":"courses/shotgrid-client/04_first_tool/#test-it-out","title":"Test it out","text":"<p>Now test the Tool by running the application and asking it to say something in reverse.</p> <pre><code>Q: can you say this in revese \"I'm a lumberjack and I'm okay\"\nprocessing...\n[12/03/23 05:56:54] INFO     ToolkitTask 656bcf9d58654d53a60ae24a7dad6af2                                                                     \n                             Input: can you say this in revese \"I'm a lumberjack and I'm okay\"                                                \n[12/03/23 05:57:01] INFO     Subtask 6eeda1fd106a480ebaa8fe112fffdfe6                                                                         \n                             Thought: I need to use the ReverseStringTool action to reverse the given string.                                 \n\n                             Action:                                                                                                          \n                             {                                                                                                                \n                               \"name\": \"ReverseStringTool\",                                                                                   \n                               \"path\": \"reverse_string\",                                                                                      \n                               \"input\": {                                                                                                     \n                                 \"values\": {                                                                                                  \n                                   \"input\": \"I'm a lumberjack and I'm okay\"                                                                   \n                                 }                                                                                                            \n                               }                                                                                                              \n                             }                                                                                                                \n                    INFO     Subtask 6eeda1fd106a480ebaa8fe112fffdfe6                                                                         \n                             Response: yako m'I dna kcajrebmul a m'I                                                                          \n[12/03/23 05:57:03] INFO     ToolkitTask 656bcf9d58654d53a60ae24a7dad6af2                                                                     \n                             Output: The reversed string is \"yako m'I dna kcajrebmul a m'I\".                                                  \nA: The reversed string is \"yako m'I dna kcajrebmul a m'I\".\n</code></pre> <p>As you can see in the highlighted section above, the <code>Subtask</code> shows that the agent has decided to use the ReverseStringTool action.</p>"},{"location":"courses/shotgrid-client/04_first_tool/#combine-requests","title":"Combine requests","text":"<p>You can absolutely use multiple Tools at the same time. Try a few examples where you might use both the <code>DateTime</code> Tool and the <code>ReverseStringTool</code>.</p> <pre><code>Q: Can you reverse the month?\nA: The reversed month is \"rebmeceD\".\n\nQ: Tell me how many days there are until December 25th, and then reverse the entire response\nA: The reversed response is \"syad 32 era ereht\".\n</code></pre>"},{"location":"courses/shotgrid-client/04_first_tool/#adding-a-method","title":"Adding a method","text":"<p>Let's add another method to the <code>ReverseStringTool</code>. This will take a sentence and reverse the words instead of the letters.</p> <p>It will:</p> <ul> <li>Split the sentence into words</li> <li>Reverse the list of words</li> <li>Join the reverse words back into a sentence</li> </ul>"},{"location":"courses/shotgrid-client/04_first_tool/#open-toolpy","title":"Open tool.py","text":"<ol> <li>In Visual Studio Code, open the <code>reverse_string_tool</code> folder and select <code>tool.py</code>.</li> </ol>"},{"location":"courses/shotgrid-client/04_first_tool/#add-reverse_sentence","title":"Add <code>reverse_sentence</code>","text":"<ol> <li> <p>Duplicate the code from the first <code>@activity</code> line through the end of the <code>def reverse_string</code> method.</p> </li> <li> <p>Rename the second method to <code>reverse_sentence</code>.</p> </li> <li> <p>Change the description of the second activity to <code>Can be used to reverse a sentence</code> and the schema description to <code>The sentence to be reversed</code>.</p> </li> </ol> <p>Here's the resulting code, with much of it commented out for brevity. I've highlighted the specific sections where we replaced <code>string</code> with <code>sentence</code>. This new method won't reverse sentences yet, we will add that later.</p> <pre><code># ...\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema({Literal(\"input\", description=\"The string to be reversed\"): str}),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a sentence\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The sentence to be reversed\"): str}),\n}\n)\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/04_first_tool/#update-the-logic","title":"Update the logic","text":"<p>Within the <code>reverse_sentence</code> method, find the section of code after <code>try:</code> and before the <code>except</code>, and replace it with the following code:</p> <pre><code># ...\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\n# Splitting the sentence into words\nwords = input_value.split()\n# Reversing the list of words\nreversed_words = words[::-1]\n# Joining the reversed words back into a sentence\nreversed_sentence = \" \".join(reversed_words)\nreturn TextArtifact(reversed_sentence)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/04_first_tool/#try-it-out","title":"Try it out","text":"<p>Now that you've added this new method, let's give it a try!</p> <pre><code>Q: Can you reverse the words in this sentence? \"I must eat, therefore, I am hungry\".\nA: The reversed sentence is \"hungry am I therefore, eat, must I\".\n</code></pre> <p>Well done! Now go grab a snack and we'll continue.</p>"},{"location":"courses/shotgrid-client/04_first_tool/#code-review","title":"Code Review","text":"<p>You have added a Griptape Tool and modified it to add a new activity! Well done! Let's take a look at all the code to review it before moving on.</p>"},{"location":"courses/shotgrid-client/04_first_tool/#apppy","title":"<code>app.py</code>","text":"app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nfrom reverse_string_tool import ReverseStringTool\nload_dotenv()\n# Instantiate the agent\nagent = Agent(tools=[DateTime(off_prompt=False), ReverseStringTool(off_prompt=False)], stream=True)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/04_first_tool/#reverse_string_tooltoolpy","title":"<code>reverse_string_tool/tool.py</code>","text":"reverse_string_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define\n@define\nclass ReverseStringTool(BaseTool):\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a string\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The string to be reversed\"): str}\n),\n}\n)\ndef reverse_string(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\nreturn TextArtifact(input_value[::-1])\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n@activity(\nconfig={\n\"description\": \"Can be used to reverse a sentence\",\n\"schema\": Schema(\n{Literal(\"input\", description=\"The sentence to be reversed\"): str}\n),\n}\n)\ndef reverse_sentence(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\ninput_value = params[\"values\"].get(\"input\")\ntry:\n# Splitting the sentence into words\nwords = input_value.split()\n# Reversing the list of words\nreversed_words = words[::-1]\n# Joining the reversed words back into a sentence\nreversed_sentence = \" \".join(reversed_words)\nreturn TextArtifact(reversed_sentence)\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/04_first_tool/#next-steps","title":"Next Steps","text":"<p>In the next section, we'll begin our work to connect with ShotGrid. First, we'll make sure you're signed up for an account before creating our ShotGrid Tool.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/","title":"Creating the ShotGrid Tool","text":""},{"location":"courses/shotgrid-client/05_shotgrid_tool/#overview","title":"Overview","text":"<p>In this section, we'll create our first ShotGrid Tool. It won't do much yet, just connect to ShotGrid and validate that it's got a valid connection by returning the session token.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#authenticating-with-shotgrid","title":"Authenticating with ShotGrid","text":"<p>There are two ways that ShotGrid allows you to authenticate when working with the API. Through an Application Key, or with User Credentials.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#api-key-authentication","title":"API Key Authentication","text":"<ul> <li>Uses a unique key linked to a 'script' user.</li> <li>Ideal for automated tasks not tied to specific users.</li> <li>Advantages: Secure, controlled, and suitable for general actions.</li> <li>Best for background tasks and general automation.</li> </ul>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#usernamepassword-authentication","title":"Username/Password Authentication","text":"<ul> <li>Utilizes real user credentials.</li> <li>Suitable for actions needing user attribution.</li> <li>Advantages: Tracks user-specific actions, and respects user permissions.</li> <li>Ideal for user-specific tasks and where precise permissions are crucial, triggers WebHooks.</li> </ul>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#how-to-choose","title":"How to choose?","text":"<p>API key authentication is easier to set up, but Username/Password authentication is more powerful. So which should we set up? Considering they both have their uses, we'll do both. First, we'll start with the API key and validate the process works. Then we'll go through the Username/Password method.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#api-key","title":"API Key","text":""},{"location":"courses/shotgrid-client/05_shotgrid_tool/#getting-a-key","title":"Getting a key","text":"<p>Before we create the Tool, we'll need a ShotGrid Application Key. Autodesk handles this by allowing you to create an API script in the ShotGrid UI. It will return an API key for you. You can review the official ShotGrid documentation, but as of December 2023, this is the process:</p> <ol> <li>Open the Admin Menu by clicking on your user in the upper right corner of ShotGrid</li> <li>Choose Scripts.</li> <li>Create a new Script by using the <code>Add Script</code> button.</li> <li>Give the script a Name. Example: <code>Griptape API</code>.</li> <li>Give the script a Description. Example: <code>Interact with ShotGrid via Griptape</code>.</li> <li>Optional - your email.</li> <li> <p>Grab the value from the Application Key. You'll need this to initiate a connection to ShotGrid. I recommend you put it in your <code>.env</code> file as <code>SHOTGRID_API_KEY</code>.</p> <p>Here is an example of what your <code>.env</code> should look like. Note: These are fake API keys - use your real one.</p> .env<pre><code>OPENAI_API_KEY=OP3NAI4PI-K3Y-1234567890ABCDEFG\nSHOTGRID_API_KEY=SGAPI-K3Y-0987654321ZYXWVUTS\n</code></pre> <p>Important</p> <p>You must copy this key and save it before continuing. The API key will only appear this one time.</p> </li> <li> <p>Choose Create Script</p> </li> </ol> <p>ShotGrid will create the script for you. This may take a minute. When finished, you'll be taken to your Scripts page, with the list of API scripts available.</p> <p></p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#add-url-to-env","title":"Add URL to <code>.env</code>","text":"<p>I also highly recommend you add the URL for your ShotGrid site to your <code>.env</code> file. This will make it easy to access from your script.</p> .env<pre><code>OPENAI_API_KEY=OP3NAI4PI-K3Y-1234567890ABCDEFG\nSHOTGRID_API_KEY=SGAPI-K3Y-0987654321ZYXWVUTS\nSHOTGRID_URL=https://your-shotgrid-name.shotgrid.autodesk.com\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#create-shotgrid-tool","title":"Create ShotGrid Tool","text":"<p>Now comes the fun part - the actual ShotGrid tool! We'll copy the Reverse String Tool as a template and modify it to suit our needs.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#copy-reverse_string_tool","title":"Copy <code>reverse_string_tool</code>","text":"<ol> <li> <p>In Visual Studio Code, select the folder <code>reverse_string_tool</code> and choose Cmd+C, Cmd+V on Mac, or Ctrl+C, Ctrl+V on Windows.</p> </li> <li> <p>Rename the new folder as <code>shotgrid_tool</code> by selecting it and choosing Right Mouse Button -&gt; Rename... (or just select it and hit the Enter key)</p> <p></p> </li> </ol>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#delete-__pycache__","title":"Delete <code>__pycache__</code>","text":"<p>The <code>__pycache__</code> folder is a directory used by Python to store compiled compiled files. When you run a Python program it saves a 'shortcut' version of the program in this folder. The next time you run the same program, Python uses these shortcuts to start the program more quickly.</p> <p>In this case, you don't want it because it holds the compiled code for the <code>reverse_string_tool</code>.</p> <ol> <li>Delete the <code>__pycache__</code> folder that is inside <code>shotgrid_tool</code> by choosing Right Mouse Button -&gt; Delete (or select it and hit Cmd+Del on Mac, Ctrl+Del on Windows.)</li> </ol>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#modify-__init__py","title":"Modify <code>__init__.py</code>","text":"<p>Remember from earlier, that the <code>__init__.py</code> file in Python is used to mark a directory as a Python package. In our current <code>__init__.py</code> file, it's being used to import the <code>ReverseStringTool</code> class. We're going to be replacing that class with our own: <code>ShotGridTool</code>. So we'll need to update this file.</p> <p>Replace all instances of <code>ReverseStringTool</code> with <code>ShotGridTool</code> in the file. Note: we haven't created that class yet, we'll do that in a couple of steps.</p> shotgrid_tool/__init__.py<pre><code>from .tool import ShotGridTool\n__all__ = [\"ShotGridTool\"]\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#modify-manifestyml","title":"Modify <code>manifest.yml</code>","text":"<p>The <code>manifest.yml</code> file provides information for people and other downstream systems to understand what this Tool is about. At the moment it contains information about the <code>Reverse String Tool</code>. Modify it to look like the following (don't forget to include your own contact email and legal details).</p> shotgrid_tool/manifest.yaml<pre><code>version: \"v1\"\nname: Autodesk ShotGrid Tool\ndescription: Tool for using the Autodesk ShotGrid API\ncontact_email: contact@example.com\nlegal_info_url: https://www.example.com/legal\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#create-requirementstxt","title":"Create <code>requirements.txt</code>","text":"<p>Some Tools you create for Griptape will require various Python dependencies - other libraries that they need to operate correctly. ShotGrid is one of those Tools - it requires the ShotGrid library, available from GitHub.  </p> <p>Griptape allows you to easily include these requirements by adding them to a <code>requirements.txt</code> file, located inside your tool folder. You will then import the required dependency inside the method where it's used. We'll cover that in more detail later.</p> <ol> <li>Select the <code>shotgrid_tool</code> folder and choose Right Mouse Button -&gt; New File..</li> <li>Name the new file <code>requirements.txt</code></li> <li>Add the ShotGrid GitHub path to <code>requirements.txt</code></li> </ol> shotgrid_tool/requirements.txt<pre><code>git+https://github.com/shotgunsoftware/python-api.git\n</code></pre> <p>What's shotgun?</p> <p>You may notice that the ShotGrid API is called \"shotgunsoftware\". That's because ShotGrid used to be named Shotgun before Autodesk renamed it in 2021. The API is still referenced by its original name in order to reduce breaking changes.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#update-toolpy","title":"Update <code>tool.py</code>","text":""},{"location":"courses/shotgrid-client/05_shotgrid_tool/#description","title":"Description","text":"<p>Now we're at the part where we update the ShotGrid Tool itself. In this first example of the Tool, we're simply going to use the <code>Shotgun.get_session_token()</code> method to verify that we can connect and have a valid session. So we'll be modifying <code>tool.py</code> with the following steps:</p> <ul> <li>Rename the class</li> <li>Define parameters</li> <li>Update the activity</li> <li>Rename the method to <code>get_session_token</code></li> <li>Import ShotGrid</li> <li>Connect to ShotGrid</li> <li>Selet second activity</li> </ul>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#rename-the-class","title":"Rename the Class","text":"<p>Rename the class definition from <code>ReverseStringTool</code> to <code>ShotGridTool</code>.</p> shotgrid_tool/tool.py<pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n@activity(\n# ...\n)\n#...\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#define-parameters","title":"Define parameters","text":"<p>When using the ShotGrid API there are some parameters that are required to authenticate. Reviewing the documentation, we can see that there are at least three parameters we will always require:</p> <ul> <li>base_url - The URL for your ShotGrid site</li> <li>script_name - The name for your script</li> <li>api_key - The script API key, given to you by ShotGrid</li> </ul> <p>We're going to add these to our Class, giving us access to them from the various methods. In addition, we'll take advantage of the <code>attr.field</code> function, which will allow us to define attributes with default values, validators, converters and various other options.</p> <p>First, let's make sure we're importing the <code>field</code> function properly. In <code>shotgrid_tool/tool.py</code> find the line that contains <code>from attr</code> import define<code>, and then modify to add</code>, field` at the end.</p> shotgrid_tool/tool.py<pre><code># ...\nfrom schema import Schema, Literal\nfrom attr import define, field\n# ...\n</code></pre> <p>Then, add the definitions in the top section of the Class:</p> shotgun_tool/tool.py<pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your ShotGrid site\n        script_name: The name for your script\n        api_key: The script API key, given to you by ShotGrid\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\n@activity(\n# ...\n)\n#...\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#update-the-activity","title":"Update the Activity","text":"<p>The method we're going to create will allow us to connect to the ShotGrid API. We need to describe that method in the <code>@activity</code> section. The description itself should be pretty straightforward.. something like \"Can be used to get the session token from ShotGrid\". We won't need any parameters for this activity, as the URL, script_name, and api_keys will come from the class itself. </p> <ul> <li>Change the <code>description</code></li> <li>Remove the <code>schema</code> section of the activity. </li> </ul> shotgrid_tool/tool.py<pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n# ...\n@activity(\nconfig={\n\"description\": \"Can be used to get the active session token from ShotGrid\",\n}\n)\n# ...\n#...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#rename-the-method","title":"Rename the method","text":"<p>The method is still named <code>reverse_string</code>. Let's rename it to what we're actually doing - getting the session token from the API. We won't need any parameters, so we can just replace the params section with <code>_:dict</code> as we saw in the <code>DateTime</code> get_current_datetime method.</p> shotgrid_tool/tool.py<pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n@activity(\n#..\n)\ndef get_session_token(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\n# ...\n#...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#import-shotgrid","title":"Import ShotGrid","text":"<p>To use the ShotGrid API, we'll need to import the library. This is the library we added in <code>requirements.txt</code>. The unique spin on this is that instead of importing it at the beginning of our file, we'll import it inside the method. This will tell Griptape to install the requirement automatically.</p> <p>Add the following <code>import</code> after the definition of the method:</p> shotgrid_tool/tool.py<pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n@activity(\n#..\n)\ndef get_session_token(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\n# ...\n#...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#connect-to-shotgrid","title":"Connect to ShotGrid","text":"<p>Now we can use the ShotGrid API to attempt to get a session key. This is where we get to use the official <code>get_session_token</code> method from the API and the base_url, script_name, and api_keys.</p> <p>Inside the <code>try:</code> statement for the <code>get_session_token</code> method, create an instance of <code>Shotgun</code> class, and then return the result of the <code>get_session_token</code> method. Don't forget to include the <code>base_url</code>, <code>script_name</code>, and <code>api_key</code> we defined at the beginning of the Class. We will access them using the <code>self</code> parameter. Delete the second activity and method</p> <p>Lastly, we'll remove the second activity and method, as those are from our original version of the Tool. Delete the method <code>reverse_sentence</code> and the activity associated with it.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#final-toolpy","title":"Final <code>tool.py</code>","text":"<p>Let's look at the resulting <code>tool.py</code> and make sure all the changes are present.</p> shotgrid_tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define, field\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your your ShotGrid site\n        script_name: The name for your script\n        api_key: The script API key, given to you by ShotGrid\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\n@activity(\nconfig={\n\"description\": \"Can be used to get the active session token from ShotGrid\",\n}\n)\ndef get_session_token(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\ntry:\nsg = shotgun_api3.Shotgun(\nself.base_url,  # ShotGrid url\nscript_name=self.script_name,  # Name of the ShotGrid script\napi_key=self.api_key,  # ShotGrid API key\n)\nreturn TextArtifact(sg.connect()) # Return the results of the connection\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#add-shotgridtool-to-apppy","title":"Add ShotGridTool to <code>app.py</code>","text":"<p>We are almost at the point where we can give the Agent access to the ShotGridTool. In the next steps we will:</p> <ul> <li>Import the <code>ShotGridTool</code></li> <li>Get the url, api_key, and script_name</li> <li>Instantiate the Tool</li> <li>Give it to our Agent</li> </ul>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#import-shotgridtool","title":"Import ShotGridTool","text":"<p>Just like we've imported the <code>ReverseStringTool</code>, we will do the same with the <code>ShotGridTool</code>.</p> <p>Add the following line to your <code>app.py</code> in the <code>imports</code> section:</p> app.py<pre><code># ...\nfrom reverse_string_tool import ReverseStringTool\nfrom shotgrid_tool import ShotGridTool\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#import-os","title":"Import <code>os</code>","text":"<p>We stored the URL and API key in our <code>.env</code> file. To access them, we're going to use the <code>os.getenv</code> function. But to do that, we need the <code>os</code> library.</p> <p>Add <code>import os</code> to the <code>imports</code> section of <code>app.py</code>.</p> app.py<pre><code>from dotenv import load_dotenv\nimport os\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#get-the-parameters","title":"Get the parameters","text":"<p>Now, after we use the function <code>load_dotenv()</code>, we can pull the two parameters from our <code>.env</code> file and also set the script name.</p> app.py<pre><code># ...\nload_dotenv()\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\" # The name of your script when you created your key\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#instantiate-the-tool","title":"Instantiate the Tool","text":"<p>Now we'll instantiate the Tool, passing it the required fields. Add the highlited lines to your <code>app.py</code>, and make sure to include the parameters we specified in the ShotGridTool:</p> app.py<pre><code># ...\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\noff_prompt=False,\n)\n# Instantiate the agent\nagent = Agent(\n# ...\n)\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#give-shotgridtool-to-agent","title":"Give ShotGridTool to Agent","text":"<p>Lastly, let's give the Agent access to the Tool! We no longer need the `ReverseStringTool``, so you can comment that out.</p> app.py<pre><code># ...\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\n# ReverseStringTool(off_prompt=False),\n]\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#final-apppy","title":"Final <code>app.py</code>","text":"<p>Let's take a look at the final <code>app.py</code> now that we've added the ShotGridTool.</p> app.py<pre><code>from dotenv import load_dotenv\nimport os\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nfrom reverse_string_tool import ReverseStringTool\nfrom shotgrid_tool import ShotGridTool\nload_dotenv()\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\noff_prompt=False,\n)\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\n# ReverseStringTool(off_prompt=False),\n],\nstream=True\n)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#try-it-out","title":"Try it out","text":""},{"location":"courses/shotgrid-client/05_shotgrid_tool/#successful-connection","title":"Successful Connection","text":"<p>Now that you've got the ShotGridTool and <code>app.py</code> updated, let's give this a try. Go ahead and run <code>app.py</code>. The first time you run it, it will take a minute to install the Shotgun library, but as soon as it the prompt appears you can ask if you're connected.</p> <pre><code>Q: Am I connected to ShotGrid?\nprocessing...\n[12/05/23 11:20:13] INFO     ToolkitTask 0591d3c40f38422abb1b2abc0a7c2761                                                                                       \n                             Input: Am I connected to ShotGrid?                                                                                                 \n[12/05/23 11:20:16] INFO     Subtask cbf178a93cbe448580e73c94336bfd1a                                                                                           \n                             Thought: To check if the user is connected to ShotGrid, I need to use the ShotGridTool action to get the active session token. If  \n                             the action is successful, it means the user is connected to ShotGrid.                                                              \n\n                             Action:                                                                                                                            \n                             {                                                                                                                                  \n                               \"name\": \"ShotGridTool\",                                                                                                          \n                               \"path\": \"get_session_token\",                                                                                                     \n                               \"input\": {}                                                                                                                      \n                             }                                                                                                                                  \n[12/05/23 11:20:19] INFO     Subtask cbf178a93cbe448580e73c94336bfd1a                                                                                           \n                             Response: a71268be154c2b539d774aa864793882                                                                                         \n[12/05/23 11:20:22] INFO     ToolkitTask 0591d3c40f38422abb1b2abc0a7c2761                                                                                       \n                             Output: Yes, you are connected to ShotGrid.                                                                                        \nA: Yes, you are connected to ShotGrid.\n</code></pre> <p>If you've set up everything correctly, it will return your session ID and state that you're connected!</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#unsuccessful-connection","title":"Unsuccessful Connection","text":"<p>It's good to double-check that things are working correctly by knowingly providing incorrect credentials. Quit your application, and modify the <code>.env</code> file to change the <code>SHOTGRID_API_KEY</code> to something like \"fake_key\".</p> .env<pre><code>SHOTGRID_API_KEY=fake_key\n</code></pre> <p>Run the script again, and check to see if you're connected.</p> <pre><code>Q: Am I connected to ShotGrid?\nprocessing...\n[12/05/23 11:32:10] INFO     ToolkitTask 49b621b92b6c4da98496e90862b4e171                                                                                       \n                             Input: Am I connected to ShotGrid?                                                                                                 \n[12/05/23 11:32:16] INFO     Subtask 7dcaacb0124b4e6a85e143bf42777d36                                                                                           \n                             Thought: To check if the user is connected to ShotGrid, I need to get the active session token from ShotGrid using the ShotGridTool\n                             action.                                                                                                                            \n\n                             Action:                                                                                                                            \n                             {                                                                                                                                  \n                               \"name\": \"ShotGridTool\",                                                                                                          \n                               \"path\": \"get_session_token\",                                                                                                     \n                               \"input\": {}                                                                                                                      \n                             }                                                                                                                                  \n[12/05/23 11:32:19] INFO     Subtask 7dcaacb0124b4e6a85e143bf42777d36                                                                                           \n                             Response: Can't authenticate script 'Griptape API'                                                                                 \n[12/05/23 11:32:21] INFO     ToolkitTask 49b621b92b6c4da98496e90862b4e171                                                                                       \n                             Output: No, you are not currently connected to ShotGrid. The authentication for the script 'Griptape API' failed.                  \nA: No, you are not currently connected to ShotGrid. The authentication for the script 'Griptape API' failed.\n</code></pre> <p>As you can see, the script wasn't able to authenticate and thus tells us the authentication failed. Congrats! Your failure means success!</p> <p>Before continuing, change the <code>.env</code> file back.</p> <p>Warning</p> <p>Don't forget to change your <code>.env</code> file back to your actual API key!</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#code-review","title":"Code Review","text":"<p>Congratulations, there was a lot of work in this section, but in the end, we now have an Agent that can authenticate with the ShotGrid API using a script-based API key! There are a number of files that have been updated throughout this section, so definitely review the work here.</p>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#apppy","title":"<code>app.py</code>","text":"app.py<pre><code>from dotenv import load_dotenv\nimport os\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nfrom reverse_string_tool import ReverseStringTool\nfrom shotgrid_tool import ShotGridTool\nload_dotenv()\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\noff_prompt=False,\n)\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\n# ReverseStringTool(off_prompt=False),\n],\nstream=True\n)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#env","title":"<code>.env</code>","text":".env<pre><code>OPENAI_API_KEY=OP3NAI4PI-K3Y-1234567890ABCDEFG\nSHOTGRID_API_KEY=SGAPI-K3Y-0987654321ZYXWVUTS\nSHOTGRID_URL=https://your-shotgrid-name.shotgrid.autodesk.com\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#shotgrid_tool__init__py","title":"<code>shotgrid_tool/__init__.py</code>","text":"shotgrid_tool/__init__.py<pre><code>from .tool import ShotGridTool\n__all__ = [\"ShotGridTool\"]\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#shotgrid_toolmanifestyml","title":"<code>shotgrid_tool/manifest.yml</code>","text":"shotgrid_tool/manifest.yml<pre><code>version: \"v1\"\nname: Autodesk ShotGrid Tool\ndescription: Tool for using the Autodesk ShotGrid API\ncontact_email: contact@example.com\nlegal_info_url: https://www.example.com/legal\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#shotgrid_toolrequirementstxt","title":"<code>shotgrid_tool/requirements.txt</code>","text":"shotgrid_tool/requirements.txt<pre><code>git+https://github.com/shotgunsoftware/python-api.git\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#shotgrid_tooltoolpy","title":"<code>shotgrid_tool/tool.py</code>","text":"shotgrid_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define, field\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your your ShotGrid site\n        script_name: The name for your script\n        api_key: The script API key, given to you by ShotGrid\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\n@activity(\nconfig={\n\"description\": \"Can be used to get the active session token from ShotGrid\",\n}\n)\ndef get_session_token(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\ntry:\nsg = shotgun_api3.Shotgun(\nself.base_url,  # ShotGrid url\nscript_name=self.script_name,  # Name of the ShotGrid script\napi_key=self.api_key,  # ShotGrid API key\n)\nreturn TextArtifact(\nsg.get_session_token()\n)  # Return the results of the connection\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/05_shotgrid_tool/#next-steps","title":"Next Steps","text":"<p>You now have the ability to connect to the ShotGrid API using an API key. In the next section, we'll learn how to authenticate using a username/password, giving you the ability to decide how you want your ShotGrid application to be used.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/","title":"User Authentication with ShotGrid","text":""},{"location":"courses/shotgrid-client/06_shotgrid_user/#overview","title":"Overview","text":"<p>We have our ShotGrid Tool that authenticates via API Key. However, there are times when it's more suitable to authenticate via Username/Password. In fact, most of the time you will work with the ShotGrid API, you'll want to do so as a user, since it simulates the user interacting via the UI.</p> <p>In this section, we'll add authentication via Username/Password - and provide an option for you to choose which method of authentication you'd like when you instantiate the class.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#setting-up-user-authentication","title":"Setting up User Authentication","text":"<p>Authenticating as a user for ShotGrid requires a specific step by your users. They need to create a Personal Access Token on their Autodesk profile page{target=\"blank\"}, and then _bind that token to their ShotGrid account.</p> <p>Once they do that, then they can authenticate via the ShotGrid API with their username and password.</p> <p>Both Username/Password and the Personal Access Token must be set up in order for authentication to work.</p> <p>Autodesk has documentation on this on their website, however, I'll go through the steps here.</p> <p>Important</p> <p>These are steps the user must take. You are not able to do this for them - any user you have in your studio must set up their own Personal Access Token and bind it to their ShotGrid account.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#create-a-personal-access-token","title":"Create a Personal Access Token","text":"<p>In this step, you will create a personal access token (PAT) and copy the token code. You will then use this and assign it to your ShotGrid account.</p> <ol> <li> <p>Have the user log into their Autodesk profile page</p> </li> <li> <p>Scroll down to Personal Access tokens**</p> </li> <li> <p>Choose Generate</p> </li> <li> <p>For Product scope choose ShotGrid</p> </li> <li> <p>For the Token name choose griptape-demo</p> </li> <li> <p>Choose Generate</p> </li> <li> <p> Important - Copy the code and save it somewhere safe. This code will only display once. You will take this code and assign it to your ShotGrid account in the next step.</p> </li> <li> <p>Choose Done</p> <p></p> </li> </ol> <p>You now have a personal access token.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#add-pat-to-shotgrid","title":"Add PAT to ShotGrid","text":"<ol> <li> <p>Log into your ShotGrid site.</p> </li> <li> <p>In your User Menu on the upper right of your screen, choose Account Settings.</p> </li> <li> <p>Choose Legacy Login and Personal Access Token in the left-hand sidebar.</p> <p></p> </li> <li> <p>Under Personal Access Token, paste the token code that was generated in the previous step.</p> </li> <li> <p>Choose Bind</p> </li> <li> <p>Once the token has been bound, you'll see the token name, the date it was created, and the status.</p> <p></p> </li> </ol>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#confirm-legacy-login","title":"Confirm Legacy Login","text":"<p>It's also important that the user has a Legacy Login username and password. Those should be set (and listed above the Personal Access Token). If they aren't set, have the user set them as they'll need them to log in.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#add-usernamepassword-to-env","title":"Add Username/Password to <code>.env</code>","text":"<p>In production, you will most likely have a method for having a user log in to ShotGrid, either through the ShotGrid Toolkit, or some other method.</p> <p>For the purposes of this course, we're going to use Environment Variables to store the username and password for simplicity's sake. Please replace this method with your own favorite method at a later date.</p> <p>Open your <code>.env</code> file and add the <code>SHOTGRID_USER</code> and <code>SHOTGRID_PASSWORD</code>.</p> .env<pre><code>OPENAI_API_KEY=OP3NAI4PI-K3Y-1234567890ABCDEFG\nSHOTGRID_API_KEY=SGAPI-K3Y-0987654321ZYXWVUTS\nSHOTGRID_URL=https://your-shotgrid-name.shotgrid.autodesk.com\nSHOTGRID_USER=your_username@email\nSHOTGRID_PASSWORD=supersecretpassword123\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#modify-toolpy","title":"Modify <code>tool.py</code>","text":"<p>Next, we'll modify <code>shotgrid_tool/tool.py</code> to be able to accept the username and password. We'll also add another parameter <code>login_method</code> to determine if we're going to authenticate with an API key, or with a username.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#add-parameters","title":"Add parameters","text":"<p>Add the following three parameters to the <code>ShotGridTool</code> class:</p> <ul> <li>user_login</li> <li>user_password</li> <li>login_method</li> </ul> <p>The new class should look something similar to:</p> <pre><code># ...\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your your ShotGrid site\n        script_name: The name for your script if login_method is \"api_key\"\n        api_key: The script API key, given to you by ShotGrid if login_method is \"api_key\"\n        user_login: The user login name if login_method is \"user\"\n        user_password: The user password if login_method is \"user\"\n        login_method: \"api_key\" or \"user\" - depending on the mode of login we want\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\nuser_login: str = field(default=str, kw_only=True)\nuser_password: str = field(default=str, kw_only=True)\nlogin_method: str = field(default=\"api_key\", kw_only=True)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#add-options","title":"Add options","text":"<p>Next, we'll add the two different methods of instantiating Shotgun - one where we use the api_key as we have been, and the other where we use the username/login.</p> <p>In the <code>try:</code> section of the <code>get_session_token</code> method, let's add an if/then statement, and the resulting logic: At this point, if you run the code, everything should still work the same as before, except you'll see a print statement saying that you're logging in with the API Key. We haven't changed our method of sending data to the Tool yet, and we've set the default <code>login_method</code> to be <code>api_key</code>.</p> <p>Go ahead and give it a try to make sure you're still connecting correctly.</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#update-apppy","title":"Update <code>app.py</code>","text":"<p>In this step, we'll modify <code>app.py</code> to instantiate the <code>ShotGridTool</code> with the user method of logging in. </p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#get-userpassword-env","title":"Get user/password env","text":"<p>First, we'll make sure to grab the username and password environment variables. Add the following two lines to <code>app.py</code>:</p> app.py<pre><code># ...\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\nSHOTGRID_USER = os.getenv(\"SHOTGRID_USER\")\nSHOTGRID_PASSWORD = os.getenv(\"SHOTGRID_PASSWORD\")\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#instantiate-tool","title":"Instantiate Tool","text":"<p>Now we'll add those options to the part of the code where we Instantiate the Tool. Find the part of the code where we call <code>ShotGridTool</code>, and add the login, password, and login_method. Let's set the login method to \"user\" so we can test it's working as expected.</p> app.py<pre><code># ...\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\nuser_login=SHOTGRID_USER,\nuser_password=SHOTGRID_PASSWORD,\nlogin_method=\"user\",\noff_prompt=False,\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#test","title":"Test","text":"<p>Go ahead and run the code - asking again if you are connected to ShotGrid. All working correctly, the answer will be yes, yes you are!</p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#code-review","title":"Code Review","text":"<p>You completed an incredible amount of work in this section - updating your Tool to handle both user and API key login credentials. Well done! Let's take a look at the latest versions of <code>app.py</code>, <code>.env</code>, and <code>shotgrid_tool/tool.py</code>. Note, that we're only displaying files that have been modified in this section. </p>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#apppy","title":"<code>app.py</code>","text":"app.py<pre><code>from dotenv import load_dotenv\nimport os\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nfrom reverse_string_tool import ReverseStringTool\nfrom shotgrid_tool import ShotGridTool\nload_dotenv()\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\nSHOTGRID_USER = os.getenv(\"SHOTGRID_USER\")\nSHOTGRID_PASSWORD = os.getenv(\"SHOTGRID_PASSWORD\")\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\nuser_login=SHOTGRID_USER,\nuser_password=SHOTGRID_PASSWORD,\nlogin_method=\"user\",\noff_prompt=False,\n)\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\n# ReverseStringTool(off_prompt=False),\n],\nstream=True\n)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#env","title":"<code>.env</code>","text":".env<pre><code>OPENAI_API_KEY=OP3NAI4PI-K3Y-1234567890ABCDEFG\nSHOTGRID_API_KEY=SGAPI-K3Y-0987654321ZYXWVUTS\nSHOTGRID_URL=https://your-shotgrid-name.shotgrid.autodesk.com\nSHOTGRID_USER=your_username@email\nSHOTGRID_PASSWORD=supersecretpassword123\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#shotgrid_tooltoolpy","title":"<code>shotgrid_tool/tool.py</code>","text":"shotgrid_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define, field\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your your ShotGrid site\n        script_name: The name for your script\n        api_key: The script API key, given to you by ShotGrid\n        user_login: The user login name if login_method is \"user\"\n        user_password: The user password if login_method is \"user\"\n        login_method: \"api_key\" or \"user\" - depending on the mode of login we want\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\nuser_login: str = field(default=str, kw_only=True)\nuser_password: str = field(default=str, kw_only=True)\nlogin_method: str = field(default=\"api_key\", kw_only=True)\n@activity(\nconfig={\n\"description\": \"Can be used to get the active session token from ShotGrid\",\n}\n)\ndef get_session_token(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\ntry:\nif self.login_method == \"api_key\":\nsg = shotgun_api3.Shotgun(\nprint ('Logging in with API Key')\nself.base_url,  # ShotGrid url\nscript_name=self.script_name,  # Name of the ShotGrid script\napi_key=self.api_key,  # ShotGrid API key\n)\nelse:\nsg = shotgun_api3.Shotgun(\nprint ('Logging in as a User')\nself.base_url,  # ShotGrid url\nlogin=self.user_login,  # User login\npassword=self.user_password,  # User password\n)\nreturn TextArtifact(\nsg.get_session_token()\n)  # Return the results of the connection\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/06_shotgrid_user/#next-steps","title":"Next Steps","text":"<p>You are making fantastic progress. Connecting to the ShotGrid API is exciting - but what would be really exciting would be to be able to start creating assets and manipulating data in ShotGrid. That's what we'll do in the next section - set up our first method to start working with actual data.</p>"},{"location":"courses/shotgrid-client/07_method/","title":"Adding ShotGrid Methods","text":""},{"location":"courses/shotgrid-client/07_method/#overview","title":"Overview","text":"<p>You can now authenticate with ShotGrid via API and by Username/Password. At the moment, your application only verifies that it can connect to ShotGrid, it doesn't do much else. In this section, we will add a method that allows you to do much, much more.</p>"},{"location":"courses/shotgrid-client/07_method/#shotgrid-methods","title":"ShotGrid Methods","text":"<p>ShotGrid comes with a number of methods to create, find, update, delete, and much more. Here's a small list of methods, with the entire list available in their documentation.</p> Method Description <code>Shotgun.create</code> Create a new entity of the specified entity_type <code>Shotgun.find</code> Finds entities matching the given filters <code>Shotgun.update</code> Update the specified entity with the supplied data <code>Shotgun.delete</code> Retire (delete) a specified entity. <code>Shotgun.upload_thumbnail</code> Upload a file from a local path and assign it as a thumbnal for the entity <code>Shotgun.summarize</code> Summarize field data returned by a query. <p>As you can see, there are a number of various methods we can use, and we could create an activity/method for each one of these. However, our Tool would get large, and end up being somewhat difficult to maintain. There would also be quite a lot of repetitive code, with each method importing the ShotGrid library and connecting.</p> <p>Instead, we'll introduce a method to create a more \"generic\" Tool, that will utilize the LLM's knowledge of the ShotGrid API to generate the correct commands.</p>"},{"location":"courses/shotgrid-client/07_method/#create-meta_method","title":"Create <code>meta_method</code>","text":"<p>We're going to call this new method, the Meta Method. This method will allow you to execute any of the methods ShotGrid offers.</p>"},{"location":"courses/shotgrid-client/07_method/#description-and-name","title":"Description and Name","text":"<p>First, in <code>shotgrid_tool/tool.py</code> make the following changes:</p> <ol> <li>Change the description in the activity to \"Can be used to execute ShotGrid methods\"</li> <li>Re-name the method we currently have in the Tool from <code>get_session_token</code> to <code>meta_method</code></li> </ol> shotgrid_tool/tool.py<pre><code># ...\n@activity(\nconfig={\n\"description\": \"Can be used to execute ShotGrid methods.\",\n}\n)\ndef meta_method(self, _: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/07_method/#parameters","title":"Parameters","text":"<p>Next, we'll need to add some parameters to the method. These will be things like - telling <code>meta_method</code> which ShotGrid method to call, and what <code>data</code> to pass it.</p> <p>For example, if we want to call the <code>find</code> method to find all character assets in Project 155, and return the id, the name, and the description, we'd want to call it like this:</p> <pre><code>sg.find(\n\"Asset\", \n[\n['project', 'is', {'type': 'Project', 'id': 155}],\n['sg_asset_type', 'is', 'Character']\n],\n['id', 'code', 'description']\n)\n</code></pre> <p>Or, if we wanted to delete a shot we'd call it this way: <pre><code>sg.delete(\"Shot\", 2557)\n</code></pre></p> <p>So we need to pass the <code>method</code> (<code>find</code>, <code>delete</code>, <code>update</code>, etc), and the <code>data</code>- a dict of various parameters, depending on the type of method.</p> <p>This involves updating the activity schema and telling the method itself to accept a list of <code>params</code>.</p>"},{"location":"courses/shotgrid-client/07_method/#update-schema","title":"Update Schema","text":"<p>Update the schema to accept two different parameters: <code>method</code> and <code>params</code>. We'll make sure we describe them well, giving the LLM proper context as to how to use the parameters.</p> shotgrid_tool/tool.py<pre><code># ...\n@activity(\nconfig={\n\"description\": \"Can be used to execute ShotGrid methods.\",\n\"schema\": Schema(\n{\nLiteral(\n\"method\",\ndescription=\"Shotgrid method to execute. Example: find_one, find, create, update, delete, revive, upload_thumbnail\",\n): str,\nLiteral(\n\"params\",\ndescription=\"Dictionary of parameters to pass to the method.\",\n): list,\n}\n),\n}\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/07_method/#update-the-method","title":"Update the method","text":"<p>Now we'll add the <code>params</code> parameter to <code>meta_method</code>. Replace <code>_: dict</code> with <code>params: dict</code>.</p> shotgrid_tool/tool.py<pre><code># ...\ndef meta_method(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/07_method/#add-method-logic","title":"Add method logic","text":"<p>We can now add the logic to the method that defines how we use the parameters we've just passed. Using a parameter within a Griptape Tool is pretty straightforward, you just access it with <code>params[\"values\"][PARAMATER]</code>. For example, if I want the name of the method we passed, I can do <code>params[\"values\"][\"method\"]</code>. Or if I want the parameters, I can query <code>params[\"values\"][\"params\"]</code>.</p> <p>So in this method, we're going to do the following:</p> <ol> <li>Get the name of the method passed, and use that to find the ShotGrid method object that we will be able to call (<code>sg.find</code>, <code>sg.delete</code>, <code>sg.update</code>, etc). </li> <li>Get the parameters.</li> <li>Execute the method with the given parameters. Because ShotGrid parameters require a <code>dict</code>, we want to \"unpack\" the list of items given into individual arguments. This can be done using the <code>*</code> notation.</li> <li>Return the result as a string.</li> </ol> shotgrid_tool/tool.py<pre><code># ...\ndef meta_method(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\ntry:\nif self.login_method == \"api_key\":\nsg = shotgun_api3.Shotgun(\n# ...\n)\nelse:\nsg = shotgun_api3.Shotgun(\n# ...\n)\n# Get the method name from the params\nsg_method = getattr(sg, params[\"values\"][\"method\"])\n# Get the params from the params\nsg_params = params[\"values\"][\"params\"]\n# Execute the method with the params\nsg_result = sg_method(*sg_params)\nreturn TextArtifact(str(sg_result))  # Return the results of the connection\nexcept Exception as e:\n# ...\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/07_method/#test-it-out-find","title":"Test it out - Find","text":"<p>Let's perform a quick test. One good thing to do is list all the projects available to the current user.</p> <p>Normally you'd have to figure out the filter for the <code>sg.find</code> command, but in our case we can simply ask the chatbot - \"What projects do I have access to?\"</p> <p>Quote</p> <p>What projects do I have access to?</p> <pre><code>Q: What projects do I have access to?\nprocessing...\n[12/06/23 06:15:23] INFO     ToolkitTask 974a92cff534416ea06eda9c21519461                                            \n                             Input: What projects do I have access to?                                               \n[12/06/23 06:15:36] INFO     Subtask c6d98edf1bab48e9a7fc0e4f7e151f73                                                \n                             Thought: To find out what projects the user has access to, I need to use the            \n                             ShotGridTool action with the \"find\" method. The \"find\" method will return all the       \n                             projects that the user has access to.                                                   \n\n                             Action:                                                                                 \n                             {                                                                                       \n                               \"name\": \"ShotGridTool\",                                                               \n                               \"path\": \"meta_method\",                                                                \n                               \"input\": {                                                                            \n                                 \"values\": {                                                                         \n                                   \"method\": \"find\",                                                                 \n                                   \"params\": [\"Project\", [], [\"id\", \"name\"]]                                         \n                                 }                                                                                   \n                               }                                                                                     \n                             }                                                                                       \n[12/06/23 06:15:56] INFO     Subtask c6d98edf1bab48e9a7fc0e4f7e151f73                                                \n                             Response: [{'type': 'Project', 'id': 63, 'name': 'Start From Scratch'}, {'type':        \n                             'Project', 'id': 69, 'name': 'Motion Capture Template'}, {'type': 'Project', 'id': 70,  \n                             'name': 'Demo: Animation'}, {'type': 'Project', 'id': 72, 'name': 'Demo: Game'},        \n                             {'type': 'Project', 'id': 78, 'name': 'Game Template'}, {'type': 'Project', 'id': 82,   \n                             'name': 'Film VFX Template'}, {'type': 'Project', 'id': 83, 'name': 'Episodic TV        \n                             Template'}, {'type': 'Project', 'id': 85, 'name': 'Demo: Animation with Cuts'}, {'type':\n                             'Project', 'id': 86, 'name': 'Game Outsourcing Template'}, {'type': 'Project', 'id': 87,\n                             'name': 'Demo: Automotive'}, {'type': 'Project', 'id': 88, 'name': 'Automotive Design   \n                             Template'}, {'type': 'Project', 'id': 89, 'name': 'Animation Template'}]                \n[12/06/23 06:16:05] INFO     ToolkitTask 974a92cff534416ea06eda9c21519461                                            \n                             Output: You have access to the following projects:                                      \n                             1. Start From Scratch                                                                   \n                             2. Motion Capture Template                                                              \n                             3. Demo: Animation                                                                      \n                             4. Demo: Game                                                                           \n                             5. Game Template                                                                        \n                             6. Film VFX Template                                                                    \n                             7. Episodic TV Template                                                                 \n                             8. Demo: Animation with Cuts                                                            \n                             9. Game Outsourcing Template                                                            \n                             10. Demo: Automotive                                                                    \n                             11. Automotive Design Template                                                          \n                             12. Animation Template                                                                  \nA: You have access to the following projects: \n1. Start From Scratch\n2. Motion Capture Template\n3. Demo: Animation\n4. Demo: Game\n5. Game Template\n6. Film VFX Template\n7. Episodic TV Template\n8. Demo: Animation with Cuts\n9. Game Outsourcing Template\n10. Demo: Automotive\n11. Automotive Design Template\n12. Animation Template\n</code></pre> <p>Notice how you didn't need to know how to build the filter, figure out which ShotGrid method to use, or anything. The LLM figured it out for you.</p> <p>Let's look at this section of the output:</p> <pre><code>Thought: To find out what projects the user has access to, I need to use the            ShotGridTool action with the \"find\" method. The \"find\" method will return all the       projects that the user has access to.                                                   Action:                                                                                 {                                                                                       \"name\": \"ShotGridTool\",                                                               \"path\": \"meta_method\",                                                                \"input\": {                                                                            \"values\": {                                                                         \"method\": \"find\",                                                                 \"params\": [\"Project\", [], [\"id\", \"name\"]]                                         }                                                                                   }                                                                                     }                                                                                       </code></pre> <p>See how the LLM realized it needed to use the <code>find</code> method, and it created its own list of parameters to pass!</p>"},{"location":"courses/shotgrid-client/07_method/#test-it-out-create","title":"Test it out - Create","text":"<p>Let's run through another example. In this case, we're going to create a new asset in one of our projects. I'll call this one \"Bob\" and give him a description. Be creative - come up with your own character name.</p> <p>The prompt we'll give will simply be to tell it what project we want to add the asset in, what to name the character and a bit of a description.</p> <p>Quote</p> <p>Create a new character asset for me in \"Demo: Animation with Cuts\". Make it named \"Bob\" and give it a description \"Bob is a legendary hula-hoop dancer\"</p> <pre><code>Q: Create a new character asset for me in \"Demo: Animation with Cuts\". Make it named \"bob\" and give it a description \"bob is a legendary hula-hoop dancer\"\nprocessing...\n[12/06/23 06:35:33] INFO     ToolkitTask 974a92cff534416ea06eda9c21519461                                            \n                             Input: Create a new character asset for me in \"Demo: Animation with Cuts\". Make it named\n                             \"bob\" and give it a description \"bob is a legendary hula-hoop dancer\"                   \n[12/06/23 06:35:44] INFO     Subtask ae5a4f62df2c4b24b99170350fcd5cd8                                                \n                             Thought: To create a new character asset, I need to use the ShotGridTool action with the\n                             \"create\" method. But first, I need to find the id of the \"Demo: Animation with Cuts\"    \n                             project.                                                                                \n\n                             Action: {\"name\": \"ShotGridTool\", \"path\": \"meta_method\", \"input\": {\"values\": {\"method\":  \n                             \"find_one\", \"params\": [\"Project\", [[\"name\", \"is\", \"Demo: Animation with Cuts\"]],        \n                             [\"id\"]]}}}                                                                              \n[12/06/23 06:35:47] INFO     Subtask ae5a4f62df2c4b24b99170350fcd5cd8                                                \n                             Response: {'type': 'Project', 'id': 85}                                                 \n[12/06/23 06:36:02] INFO     Subtask b8e1809356864a68a11144692e6823a4                                                \n                             Thought: Now that I have the project id, I can use it to create a new character asset   \n                             named \"bob\" with the description \"bob is a legendary hula-hoop dancer\".                 \n                             Action: {\"name\": \"ShotGridTool\", \"path\": \"meta_method\", \"input\": {\"values\": {\"method\":  \n                             \"create\", \"params\": [\"Asset\", {\"project\": {\"type\": \"Project\", \"id\": 85}, \"code\": \"bob\", \n                             \"description\": \"bob is a legendary hula-hoop dancer\", \"sg_asset_type\": \"Character\"}]}}} \n[12/06/23 06:36:04] INFO     Subtask b8e1809356864a68a11144692e6823a4                                                \n                             Response: {'id': 1412, 'project': {'id': 85, 'name': 'Demo: Animation with Cuts',       \n                             'type': 'Project'}, 'code': 'bob', 'description': 'bob is a legendary hula-hoop dancer',\n                             'sg_asset_type': 'Character', 'type': 'Asset'}                                          \n[12/06/23 06:36:10] INFO     ToolkitTask 974a92cff534416ea06eda9c21519461                                            \n                             Output: I have created a new character asset named \"bob\" with the description \"bob is a \n                             legendary hula-hoop dancer\" in the \"Demo: Animation with Cuts\" project. The asset id is \n                             1412.                                                                                   \nA: I have created a new character asset named \"bob\" with the description \"bob is a legendary hula-hoop dancer\" in the \"Demo: Animation with Cuts\" project. The asset id is 1412.\n</code></pre> <p>There were some really interesting things that happened in this test!</p> <p>First, the LLM realized it needed the project ID to create a new asset - but it wasn't provided with the ID. So it performed a <code>find_one</code> method first to get the ID.</p> <pre><code>Thought: To create a new character asset, I need to use the ShotGridTool action with the\n\"create\" method. But first, I need to find the id of the \"Demo: Animation with Cuts\"    project.                                                                                Action: {\n\"name\": \"ShotGridTool\", \"path\": \"meta_method\", \"input\": {\n\"values\": {\n\"method\":  \"find_one\",\n\"params\": [\n\"Project\", [[\"name\", \"is\", \"Demo: Animation with Cuts\"]],\n[\"id\"]\n]\n}\n}\n}                                                                              </code></pre> <p>Then, once it had the ID it could use the <code>create</code> method. Of course, it also returned valuable information we could then use to perform more actions, including the asset ID. Also, if you check on the frontend you can see the asset was indeed created with the description and the name of the person who created it.</p> <p></p>"},{"location":"courses/shotgrid-client/07_method/#code-review","title":"Code Review","text":"<p>This was a short, but powerful step. We've modified our ShotGridTool to be able to use the ShotGrid API to execute any method available to it! Let's review the changes in <code>shotgrid_tool/tool.py</code>.</p> shotgrid_tool/tool.py<pre><code>from __future__ import annotations\nfrom griptape.artifacts import TextArtifact, ErrorArtifact\nfrom griptape.tools import BaseTool\nfrom griptape.utils.decorators import activity\nfrom schema import Schema, Literal\nfrom attr import define, field\n@define\nclass ShotGridTool(BaseTool):\n\"\"\"\n    Parameters:\n        base_url: Base URL for your your ShotGrid site\n        script_name: The name for your script\n        api_key: The script API key, given to you by ShotGrid\n        user_login: The user login name if login_method is \"user\"\n        user_password: The user password if login_method is \"user\"\n        login_method: \"api_key\" or \"user\" - depending on the mode of login we want\n    \"\"\"\nbase_url: str = field(default=str, kw_only=True)\nscript_name: str = field(default=str, kw_only=True)\napi_key: str = field(default=str, kw_only=True)\nuser_login: str = field(default=str, kw_only=True)\nuser_password: str = field(default=str, kw_only=True)\nlogin_method: str = field(default=\"api_key\", kw_only=True)\n@activity(\nconfig={\n\"description\": \"Can be used to execute ShotGrid methods.\",\n\"schema\": Schema(\n{\nLiteral(\n\"method\",\ndescription=\"Shotgrid method to execute. Example: find_one, find, create, update, delete, revive, upload_thumbnail\",\n): str,\nLiteral(\n\"params\",\ndescription=\"Dictionary of parameters to pass to the method.\",\n): list,\n}\n),\n}\n)\ndef meta_method(self, params: dict) -&gt; TextArtifact | ErrorArtifact:\nimport shotgun_api3\ntry:\nif self.login_method == \"api_key\":\nsg = shotgun_api3.Shotgun(\nself.base_url,  # ShotGrid url\nscript_name=self.script_name,  # Name of the ShotGrid script\napi_key=self.api_key,  # ShotGrid API key\n)\nelse:\nsg = shotgun_api3.Shotgun(\nself.base_url,  # ShotGrid url\nlogin=self.user_login,  # User login\npassword=self.user_password,  # User password\n)\n# Get the method name from the params\nsg_method = getattr(sg, params[\"values\"][\"method\"])\n# Get the params from the params\nsg_params = params[\"values\"][\"params\"]\n# Execute the method with the params\nsg_result = sg_method(*sg_params)\nreturn TextArtifact(str(sg_result))  # Return the results of the connection\nexcept Exception as e:\nreturn ErrorArtifact(str(e))\n</code></pre>"},{"location":"courses/shotgrid-client/07_method/#next-steps","title":"Next Steps","text":"<p>This has been a powerful step - we can do so much now! However, the current implementation relies on the LLM having been trained on data about the ShotGrid API. What if there wasn't much knowledge about it, or if the API has been updated? In the next section, we'll provide the Agent access to the current API docs for it to use as a reference to enhance its abilities.</p>"},{"location":"courses/shotgrid-client/08_vectorized_docs/","title":"Vectorizing API Docs","text":""},{"location":"courses/shotgrid-client/08_vectorized_docs/#overview","title":"Overview","text":"<p>We have the ability to connect to the ShotGrid API and execute commands, but the knowledge the LLM has is restricted to what it was trained on. Let's provide the LLM with access to the most recent documentation, so it can use that to get more data.</p> <p>The trick is that we want to allow the LLM to get access to this data quickly. We want it to be able to know how to find the right commands for the types of tasks we want to execute without needing to know exactly what the method is <code>find</code> or <code>create</code> or <code>find_one</code>.</p> <p>Well, luckily Autodesk has provided pretty extensive API documentation available here: https://developers.shotgridsoftware.com/python-api/reference.html#. There are additional pages available as well.</p> <p>We can provide this documentation to the LLM by creating a Vector Store of docs.</p>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#what-is-vector-storage","title":"What is \"Vector Storage\"","text":"<p>You can think of vector storage as a huge, organized bookshelf in a library where each book represents a piece of information or data. In this library, instead of books being sorted by author or title, they're organized based on their content's \"features\" or \"characteristics\".</p> <p>Now imagine each book has a summary that describes its key points, and these summaries are used to arrange the books on the shelves. In vector storage, this summary is like a 'vector' - a list of numbers that represent the key features of the data. These vectors help in quickly finding the right book (or data) that you need.</p> <p>When you want to find information related to a specific topic, the librarian quickly scans through these summaries and finds the books that closely match what you're looking for. This is much faster than reading all the books in their entirety or going through them in random order.</p> <p>In technical terms, the data is converted into vectors (numerical representations) allowing for quick and accurate searches based on similarities in the vectors.</p> <p>This means I can ask for \"ways to filter asset creation\" \"asset creation, filtering methods\" and \"Hey, can you filter the results for creating assets?\" and get the same helpful information back!</p>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#vector-storage-process","title":"Vector Storage Process","text":"<p>The process for providing the docs to the LLM looks like this:</p> <ol> <li>Create a Vector Database where we can store the documents. In this example, we'll use a simple Local Vector Store Driver.</li> <li>Create a Vector Query Engine - an engine that's really good at searching Vector Databases</li> <li>Create a list of URLs to vectorize. For each URL, load the data using a WebLoader.</li> <li>For each bit of website data, upsert (update/insert) it into the Vector Store.</li> <li>Create a Vector Store Client (Tool) that has access to the data and the query engine.</li> <li>Give the Vector Store Client to the Agent.</li> </ol> <pre><code>graph TB\n    A(Create Vector DB)\n    B(Create Vector Query Engine)\n    C(Gather URLs)\n    D(URL 1)\n    E(URL 2)\n    F(URL 3)\n    G(Load Data)\n    H(Load Data)\n    I(Load Data)\n    J(Upsert)\n    K(Upsert)\n    L(Upsert)\n    M(Vector Store Client)\n    N(Agent)\n    A --&gt; B --&gt; C\n    C --&gt; D --&gt; G --&gt; J --&gt; M\n    C --&gt; E --&gt; H --&gt; K --&gt; M\n    C --&gt; F --&gt; I --&gt; L --&gt; M\n    M --&gt; N\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#vector-database","title":"Vector Database","text":"<p>Let's start by creating the Vector Database. We're going to use Griptape's LocalVectorStoreDriver. </p> <p>Tip</p> <p>You could also use Pinecone, Marqo, MongoDB, Redis, OpenSearch, or PGVector - all are available as drivers for Griptape as described in the documentation.</p> <p>Modify <code>app.py</code> to import the required drivers. In the case of the Local Vector Store Driver, we also need an Embedding Driver. We'll use the one from OpenAI, but you could also use one of the other drivers available for Griptape.</p> app.py<pre><code># ...\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime\nfrom griptape.drivers import LocalVectorStoreDriver, OpenAiEmbeddingDriver\n# ...\n</code></pre> <p>Now after the <code>load_dotenv()</code> line in <code>app.py</code>, create the vector database by instantiating <code>LocalVectorStoreDriver</code> and passing it an <code>embedding_driver</code>.</p> app.py<pre><code># ...\nload_dotenv()\n# Create the vector database\nvector_store_driver = LocalVectorStoreDriver(embedding_driver=OpenAiEmbeddingDriver())\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#vector-query-engine","title":"Vector Query Engine","text":"<p>Now that we have a database, we need a way to query it. This will be done using Griptape's VectorQueryEngine which takes a <code>vector_store_driver</code>. Luckily we just created one!</p> <p>First, import the engine into Gritpape by adding it to the imports section of your app.</p> app.py<pre><code># ...\nfrom griptape.drivers import LocalVectorStoreDriver, OpenAiEmbeddingDriver\nfrom griptape.engines import VectorQueryEngine\n# ...\n</code></pre> <p>Next, create the engine. Add the following lines after the creation of the <code>vector_store_driver</code>.</p> app.py<pre><code># ...\n# Create the vector database\nvector_store_driver = LocalVectorStoreDriver(embedding_driver=OpenAiEmbeddingDriver())\n# Create the query engine\nquery_engine = VectorQueryEngine(vector_store_driver=vector_store_driver)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#gather-urls","title":"Gather URLs","text":"<p>The relevant ShotGrid API documentation is available split over six web pages. The first is a general API reference page, and the rest are in their \"cookbook\". We'll create a list of these.</p> <p>Add the following lines after creating the query engine.</p> app.py<pre><code># ...\n# Create the query engine\nquery_engine = VectorQueryEngine(vector_store_driver=vector_store_driver)\n# API Documentation\nshotgrid_api_urls = [\n\"https://developers.shotgridsoftware.com/python-api/reference.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/usage_tips.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/attachments.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/updating_tasks.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/task_dependencies.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/split_tasks.html\",\n]\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#load-url-content","title":"Load URL Content","text":"<p>There are a number of Loaders available for Griptape to allow you to load textual data. You can load from the web, from pdf, SQL, CSV, and more. Review all the details in our Loader documentation.</p> <p>In this case, we will be using the WebLoader to load the data from the HTML pages.</p> <p>First import the WebLoader from <code>griptape.loaders</code> by adding the <code>import</code> statement in the <code>import</code> section of your app.</p> app.py<pre><code># ...\nfrom griptape.engines import VectorQueryEngine\nfrom griptape.loaders import WebLoader\n# ...\n</code></pre> <p>Then add the following lines to create a list of \"artifacts\" - loaded chunks of data.</p> app.py<pre><code># ...\n# API Documentation\nshotgrid_api_urls = [\n# ...\n]\n# Load the API documentation\nartifacts = []\nfor url in shotgrid_api_urls:\nartifacts.append(WebLoader().load(url))\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#upsert-content","title":"Upsert Content","text":"<p>Now we'll upsert the data into the database.</p> <p>What's an 'upsert?'</p> <p>Upsert is a great word - it is a combination of \"insert\" and \"update\". It's used frequently in databases to mean \"Hey.. here's some data. Insert a new record into the database if doesn't exist, or update the record if it does.\"</p> <p>Not only is it a great concept because it simplifies the process of ensuring the database contains a specific record, but it also is an awesome word to pull out at dinner parties.</p> <p>In order to give the database the right information, we'll need to provide a namespace to operate in, then we can upsert into that namespace.</p> app.py<pre><code># ...\n# Load the API documentation\nartifacts = []\nfor url in shotgrid_api_urls:\nartifacts.append(WebLoader().load(url))\n# Upsert documentation  into the vector database\nnamespace = \"shotgrid_api\"\nfor artifact in artifacts:\nquery_engine.vector_store_driver.upsert_text_artifacts({namespace: artifact})\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#vector-store-client","title":"Vector Store Client","text":"<p>Now we need to create the VectorStoreClient. This will be the Tool we provide to the Agent that tells it how to access the vector database. Much like the ShotGridTool, the VectorStoreClient has a method that allows it to search vector databases.</p> <p>Because the VectorStoreClient is a Griptape Tool, you can add it to the <code>import</code> line where we're already importing <code>DateTime</code></p> app.py<pre><code># ...\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime, VectorStoreClient\n# ...\n</code></pre> <p>We can instantiate the Tool in <code>app.py</code> after upserting the data. We'll provide a <code>description</code> so the LLM knows when to use it, and also access to the <code>query_engine</code> and <code>namespace</code>. </p> app.py<pre><code># ...\n# Upsert documentation  into the vector database\nnamespace = \"shotgrid_api\"\nfor artifact in artifacts:\nquery_engine.vector_store_driver.upsert_text_artifacts({namespace: artifact})\n# Instantiate the Vector Store Client\nvector_store_tool = VectorStoreClient(\ndescription=\"Contains information about ShotGrid api. Use it to help with ShotGrid client requests.\",\nquery_engine=query_engine,\nnamespace=namespace,\noff_prompt=False,\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#give-to-agent","title":"Give to Agent","text":"<p>Lastly, let's give the <code>vector_store_tool</code> to the Agent so it can use it.</p> app.py<pre><code># ...\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\nvector_store_tool\n# ReverseStringTool(off_prompt=False),\n],\nstream=True\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#try-it-out","title":"Try it out","text":"<p>A great way to test is to ask a specific question that the Agent would do better at when reading the supplied documentation.</p> <p>For example, there is documentation on how ShotGrid Thinks when updating task dates.</p> <p>If you ask the question: \"Tell me how ShotGrid thinks about updating task dates and what are the general rules?\"</p> <p>When provided with the API documentation, the Agent will do the following: <pre><code>Thought: To answer this question, I need to search the ShotGrid API documentation for   information about updating task dates. I will use the VectorStoreClient action to do    this.                                                                                   Action:                                                                                 {                                                                                       \"name\": \"VectorStoreClient\",\n\"path\": \"search\",\n\"input\": {\n\"values\": {\n\"query\": \"ShotGrid API update task dates\" }\n}                                                         }                                                                                       </code></pre></p> <p>... and then proceed to return a bunch of extremely helpful information.</p> <p>If you don't provide the API documentation and ask the same question, it gets confused and doesn't provide the right answer. It even hallucinates the ShotGrid method that doesn't exist:</p> <pre><code>Thought: To answer this question, I need to use the ShotGridTool action to execute the  ShotGrid method that provides information about updating task dates.\nAction:\n{\n\"name\": \"ShotGridTool\",\n\"path\": \"meta_method\",\n\"input\": { \"values\":{\n\"method\": \"get_task_date_update_rules\", \"params\":[]\n}        }   }                                                                                       Subtask 6688154d58ab4dd687680ff1c3081ca4\nResponse: 'Shotgun' object has no attribute 'get_task_date_update_rules'                </code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#code-review","title":"Code Review","text":"<p>We have certainly improved our Agent in this example - providing it with greater context and knowledge about how to interact with the ShotGridTool. Let's review <code>app.py</code> and see all the changes that were made.</p> app.py<pre><code>from dotenv import load_dotenv\nimport os\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime, VectorStoreClient\nfrom griptape.drivers import LocalVectorStoreDriver, OpenAiEmbeddingDriver\nfrom griptape.engines import VectorQueryEngine\nfrom griptape.loaders import WebLoader\nfrom reverse_string_tool import ReverseStringTool\nfrom shotgrid_tool import ShotGridTool\nload_dotenv()\n# Create the vector database\nvector_store_driver = LocalVectorStoreDriver(embedding_driver=OpenAiEmbeddingDriver())\n# Create the query engine\nquery_engine = VectorQueryEngine(vector_store_driver=vector_store_driver)\n# API Documentation\nshotgrid_api_urls = [\n\"https://developers.shotgridsoftware.com/python-api/reference.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/usage_tips.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/attachments.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/updating_tasks.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/task_dependencies.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/split_tasks.html\",\n]\n# Load the API documentation\nartifacts = []\nfor url in shotgrid_api_urls:\nartifacts.append(WebLoader().load(url))\n# Upsert documentation  into the vector database\nnamespace = \"shotgrid_api\"\nfor artifact in artifacts:\nquery_engine.vector_store_driver.upsert_text_artifacts({namespace: artifact})\n# Instantiate the Vector Store Client\nvector_store_tool = VectorStoreClient(\ndescription=\"Contains information about ShotGrid api. Use it to help with ShotGrid client requests.\",\nquery_engine=query_engine,\nnamespace=namespace,\noff_prompt=False,\n)\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\nSHOTGRID_USER = os.getenv(\"SHOTGRID_USER\")\nSHOTGRID_PASSWORD = os.getenv(\"SHOTGRID_PASSWORD\")\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\nuser_login=SHOTGRID_USER,\nuser_password=SHOTGRID_PASSWORD,\nlogin_method=\"user\",\noff_prompt=False,\n)\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\nvector_store_tool\n# ReverseStringTool(off_prompt=False),\n],\nstream=True\n)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/08_vectorized_docs/#next-steps","title":"Next Steps","text":"<p>While adding access to the API documentation has improved the performance of the agent significantly, we can keep improving it by providing some Rules and Rulesets, ensuring the agent knows when to use the VectorStore, and also giving it hints as to how to use the API more efficiently. That will be coming up in the next section.</p>"},{"location":"courses/shotgrid-client/09_rules/","title":"Creating Rules for Success","text":""},{"location":"courses/shotgrid-client/09_rules/#overview","title":"Overview","text":"<p>In the Chatbot - Rulesets course you learned all about creating Griptape Rules and Rulesets and how to use them to give an Agent directions. In that case, it was mostly about providing personality and making sure the output was in JSON format. In this course, we'll use rules to help direct the Agent to use <code>ShotGridTool</code> and Vector Database when appropriate.</p> <p>If you haven't viewed that course before, I highly recommend doing so - especially the section on creating Personality as it provides a wonderful overview of creating and using Rulesets, what they're used for, and why Griptape has them.</p>"},{"location":"courses/shotgrid-client/09_rules/#importing","title":"Importing","text":"<p>In order to use Rules and Rulesets, we need to import them into our app first. In the <code>imports</code> section of <code>app.py</code>, add the following import statement:</p> app.py<pre><code># ...\nfrom griptape.rules import Rule, Ruleset\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#create-the-ruleset","title":"Create the Ruleset","text":"<p>Our first step will be to create the Ruleset for the agent. This ruleset will contain all the rules we will give it.</p> <p>In <code>app.py</code> find the area of the code where you instantiate the agent, and insert the ruleset before it.</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\"\n)\n# Instantiate the agent\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#rules","title":"Rules","text":""},{"location":"courses/shotgrid-client/09_rules/#act-as","title":"Act as...","text":"<p>We want the agent to have the correct context for its work, so the first ruleset will tell it to act as a studio coordinator who is an expert in Autodesk ShotGrid</p> <p>Create a parameter for <code>rules</code>, and then add this first rule to the list of rules:</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\nRule(\"Act as a studio coordinator who is an expert with Autodesk ShotGrid\"),\n],\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#main-objective","title":"Main objective","text":"<p>Sometimes it's helpful to remind the LLM what its main objective is. In this case, we want to remind it that we want it to update ShotGrid using the ShotGridTool.</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\nRule(\"Act as a studio coordinator who is an expert with Autodesk ShotGrid\"),\nRule(\n\"Your main objective is to find and update information in ShotGrid using the ShotGridTool\"\n),\n],\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#vector-database","title":"Vector Database","text":"<p>Now let's remind it that it should use the VectorStoreClient when it needs information about how to use the API. This will ensure the most up-to-date and accurate use of the API.</p> <p>Note: This rule is multiple lines long, so we're going to use a Python function <code>dedent</code> that will allow us to keep the code looking nice.</p> <p>First, import <code>dedent</code> in your <code>imports</code> section of the code.</p> app.py<pre><code># ...\nfrom textwrap import dedent\n# ...\n</code></pre> <p>Then, add the new rule:</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\n# ...\nRule(\ndedent(\n\"\"\"\n            For specific information about how to use ShotGrid API activities, the \n            VectorStoreClient should be used. Take the necessary time to consult the \n            VectorStoreClient to ensure the most accurate and context-aware decisions \n            when interacting with the ShotGridTool and API.\n            \"\"\"\n)\n),\n],\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#batch-mode","title":"Batch mode","text":"<p>ShotGrid provides access to a <code>batch</code> method that allows you to perform multiple create, update, and delete operations in a single request. Each operation in the batch is specified as a dictionary, and the operations are performed in the order they are provided.</p> <p>We would like to ensure the Agent uses batch mode when appropriate. </p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\n# ...\nRule(\ndedent(\n\"\"\"\n            Always use the ShotGrid batch() method when performing multiple create, update, or delete operations in ShotGrid.\n            This should be done in a single request to improve efficiency and speed. \n            Batch method uses \"request_type\", \"entity_type\", and \"entity_id\".\n            Failure to use the batch() method in these instances will be considered a violation of the rules.\"\"\"\n)\n),\n],\n)\n</code></pre> <p>Tip</p> <p>While working on the rule for batch mode, I found that the LLM was sometimes not using it and would jump to just using create or update methods instead. I asked the agent for a good rule to enforce using the <code>batch</code> method, and it came up with this very strict rule.</p> <p>And .. it worked! Sometimes just asking the LLM for the best rule provides excellent results.</p>"},{"location":"courses/shotgrid-client/09_rules/#every-task","title":"Every task","text":"<p>Lastly, one final rule is to ensure the Agent uses the ShotGrid and doesn't just pretend to use it.</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\n# ...\nRule(\ndedent(\n\"\"\"\n            When asked to find, list, create, update, delete, retrieve details of entities, \n            update task status, update task data, list task assignments, retrieve the history of changes to \n            entities, manage versions of assets, manage project timelines, track project \n            progress, manage notes and reviews, manage user roles and permissions, or \n            integrate with other tools and workflows, the ShotGrid Client API is always used.\"\"\"\n)\n)\n]\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#full-list-of-rules","title":"Full list of rules","text":"<p>Here are all the rules.</p> app.py<pre><code># ...\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\nRule(\"Act as a studio coordinator who is an expert with Autodesk ShotGrid\"),\nRule(\n\"Your main objective is to find and update information in ShotGrid using the ShotGridTool\"\n),\nRule(\ndedent(\n\"\"\"\n            For specific information about how to use ShotGrid API activities, the \n            VectorStoreClient should be used. Take the necessary time to consult the \n            VectorStoreClient to ensure the most accurate and context-aware decisions \n            when interacting with the ShotGridTool and API.\n            \"\"\"\n)\n),\nRule(\ndedent(\n\"\"\"\n            Always use the ShotGrid batch() method when performing multiple create, update, or delete operations in ShotGrid.\n            This should be done in a single request to improve efficiency and speed. \n            Batch method uses \"request_type\", \"entity_type\", and \"entity_id\".\n            Failure to use the batch() method in these instances will be considered a violation of the rules.\"\"\"\n)\n),\nRule(\ndedent(\n\"\"\"\n            When asked to find, list, create, update, delete, retrieve details of entities, \n            update task status, update task data, list task assignments, retrieve the history of changes to \n            entities, manage versions of assets, manage project timelines, track project \n            progress, manage notes and reviews, manage user roles and permissions, or \n            integrate with other tools and workflows, the ShotGrid Client API is always used.\"\"\"\n)\n),\n],\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#giving-the-rules-to-the-agent","title":"Giving the rules to the Agent","text":"<p>The rules won't make any difference if you don't give them to the Agent. Let's do that now.</p> app.py<pre><code># ...\n# Instantiate the agent\nagent = Agent(\ntools=[\nDateTime(off_prompt=False),\nshotgrid_tool,\nvector_store_tool\n# ReverseStringTool(off_prompt=False),\n],\nrulesets=[shotgrid_agent_ruleset],\nstream=True\n)\n# ...\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#try-it-out","title":"Try it out","text":"<p>Go ahead and interact with the agent. Work with different projects, create and update assets, and try and create tasks. As you are working with it, figure out where the agent isn't performing as expected, and update rules and rulesets to do exactly what you want it to do. Refine and iterate until you're happy with the results.</p>"},{"location":"courses/shotgrid-client/09_rules/#clean-up","title":"Clean up","text":"<p>Before moving on to the next section, let's remove some unused code from our app. We are no longer using the ReverseStringTool, so you can happily remove it from the <code>imports</code> section, and also remove it from your Agent.</p>"},{"location":"courses/shotgrid-client/09_rules/#code-review","title":"Code Review","text":"<p>Nice work in this section - we've added rules to ensure the agent behaves as expected, using the Tools we've given it. Let's take a look at the current state of the app.</p> app.py<pre><code>from dotenv import load_dotenv\nfrom textwrap import dedent\nimport os\nfrom griptape.structures import Agent\nfrom griptape.utils import Chat\nfrom griptape.tools import DateTime, VectorStoreClient\nfrom griptape.drivers import LocalVectorStoreDriver, OpenAiEmbeddingDriver\nfrom griptape.engines import VectorQueryEngine\nfrom griptape.loaders import WebLoader\nfrom griptape.rules import Rule, Ruleset\nfrom shotgrid_tool import ShotGridTool\nload_dotenv()\n# Create the vector database\nvector_store_driver = LocalVectorStoreDriver(embedding_driver=OpenAiEmbeddingDriver())\n# Create the query engine\nquery_engine = VectorQueryEngine(vector_store_driver=vector_store_driver)\n# API Documentation\nshotgrid_api_urls = [\n\"https://developers.shotgridsoftware.com/python-api/reference.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/usage_tips.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/attachments.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/updating_tasks.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/task_dependencies.html\",\n\"https://developers.shotgridsoftware.com/python-api/cookbook/tasks/split_tasks.html\",\n]\n# Load the API documentation\nartifacts = []\nfor url in shotgrid_api_urls:\nartifacts.append(WebLoader().load(url))\n# Upsert documentation  into the vector database\nnamespace = \"shotgrid_api\"\nfor artifact in artifacts:\nquery_engine.vector_store_driver.upsert_text_artifacts({namespace: artifact})\n# Instantiate the Vector Store Client\nvector_store_tool = VectorStoreClient(\ndescription=\"Contains information about ShotGrid api. Use it to help with ShotGrid client requests.\",\nquery_engine=query_engine,\nnamespace=namespace,\noff_prompt=False,\n)\nSHOTGRID_URL = os.getenv(\"SHOTGRID_URL\")\nSHOTGRID_API_KEY = os.getenv(\"SHOTGRID_API_KEY\")\nSHOTGRID_SCRIPT = \"Griptape API\"\nSHOTGRID_USER = os.getenv(\"SHOTGRID_USER\")\nSHOTGRID_PASSWORD = os.getenv(\"SHOTGRID_PASSWORD\")\n# Instantiate the tool\nshotgrid_tool = ShotGridTool(\nbase_url=SHOTGRID_URL,\napi_key=SHOTGRID_API_KEY,\nscript_name=SHOTGRID_SCRIPT,\nuser_login=SHOTGRID_USER,\nuser_password=SHOTGRID_PASSWORD,\nlogin_method=\"user\",\noff_prompt=False,\n)\n# Create the ruleset\nshotgrid_agent_ruleset = Ruleset(\nname=\"ShotGrid Agent\",\nrules=[\nRule(\"Act as a studio coordinator who is an expert with Autodesk ShotGrid\"),\nRule(\n\"Your main objective is to find and update information in ShotGrid using the ShotGridTool\"\n),\nRule(\ndedent(\n\"\"\"\n            For specific information about how to use ShotGrid API activities, the \n            VectorStoreClient should be used. Take the necessary time to consult the \n            VectorStoreClient to ensure the most accurate and context-aware decisions \n            when interacting with the ShotGridTool and API.\n            \"\"\"\n)\n),\nRule(\ndedent(\n\"\"\"\n            Always use the ShotGrid batch() method when performing multiple create, update, or delete operations in ShotGrid.\n            This should be done in a single request to improve efficiency and speed. Batch method uses \"request_type\", \"entity_type\", and \"entity_id\".\n            Failure to use the batch() method in these instances will be considered a violation of the rules.\"\"\"\n)\n),\nRule(\ndedent(\n\"\"\"\n            When asked to find, list, create, update, delete, retrieve details of entities, \n            update task status, update task data, list task assignments, retrieve the history of changes to \n            entities, manage versions of assets, manage project timelines, track project \n            progress, manage notes and reviews, manage user roles and permissions, or \n            integrate with other tools and workflows, the ShotGrid Client API is always used.\"\"\"\n)\n),\n],\n)\n# Instantiate the agent\nagent = Agent(\ntools=[DateTime(off_prompt=False), shotgrid_tool, vector_store_tool],\nrulesets=[shotgrid_agent_ruleset],\nstream=True\n)\n# Start chatting\nChat(agent).start()\n</code></pre>"},{"location":"courses/shotgrid-client/09_rules/#finished","title":"Finished","text":"<p>Success</p> <p>Congratulations! You have created a Griptape ShotGrid Tool!</p> <p>Well done, you've successfully created a Griptape Tool that allows you to connect to and work with external applications.</p> <p>You have learned:</p> <ul> <li>How Griptape Tools work.</li> <li>How to build your own Tools.</li> <li>How to handle user authentication with external tools.</li> <li>How to vectorize and provide extra documentation to asset Griptape Agents.</li> <li>How to craft Rules and Rulesets to sculpt the Agent's performance.</li> </ul> <p>We hope you enjoyed this course, please head over to Discord and share your results!</p>"},{"location":"courses/shotgrid-client/10_pipeline/","title":"Tools with Pipelines","text":""},{"location":"courses/shotgrid-client/10_pipeline/#overview","title":"Overview","text":"<p>Interacting with the ShotGrid Tool via a chatbot is one way of working with it, but frequently you'll want to run tasks in a more directed flow. For example, what if you wanted to generate a thumbnail image for a newly created asset?</p> <p>Using a Griptape Pipeline, you can execute a series of tasks consistently, instead of trying to direct an Agent. For example, you can build a Pipeline that will:</p> <ol> <li>When given an asset ID, look up the name and description from ShotGrid using the ShotGrid Tool.</li> <li>Generate a prompt for an Image Generation engine to create a thumbnail image in a particular style.</li> <li>Create the thumbnail.</li> <li>Use the ShotGrid Tool to upload the thumbnail back to the asset.</li> </ol> <p>In this section, we'll build this exact flow. Note, that this is a bit more of an advanced flow.</p>"},{"location":"courses/shotgrid-client/10_pipeline/#importing","title":"Importing","text":"<p>We will need some of the following Gritpape Classes for this to work</p>"},{"location":"courses/shotgrid-client/10_pipeline/#code-review","title":"Code Review","text":""},{"location":"courses/shotgrid-client/10_pipeline/#next-steps","title":"Next Steps","text":"<p>...</p>"},{"location":"setup/","title":"Setting Up Your Python Environment for Griptape","text":""},{"location":"setup/#kickoff-and-foundations","title":"Kickoff and Foundations","text":"<p>Welcome to the getting started course for Griptape. We'll be using Visual Studio Code and the Griptape library, which make a great combo for coding with Large Language Models (LLMs).</p>"},{"location":"setup/#what-will-i-learn","title":"What will I learn?","text":"<p>By the end of the course you will have the ability to use Griptape to work with Large Language Models. You will be setting up your Python environment, install a code editor, install Griptape, and be ready to go.</p> griptape_developer.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nload_dotenv()\n# Create an agent\nagent = Agent()\n# Run the agent\nagent.run(\"Hello! I'm a new Griptape Developer!\")\n</code></pre>"},{"location":"setup/#who-is-this-course-for","title":"Who is this course for?","text":"<p>This course is aimed at beginners to intermediate level Python developers who are interested in setting up a Python environment to develop tools and applications with Griptape.</p>"},{"location":"setup/#why-visual-studio-code","title":"Why Visual Studio Code?","text":"<p>Using the right coding software (or Integrated Development Environment - IDE) can make your coding sessions a breeze... or not (if you choose the wrong one).</p> <p>Visual Studio Code (VS Code for short) is our IDE of choice for a few reasons. It's lightweight, highly customizable, and has a vast range of extensions.</p>"},{"location":"setup/#griptape-and-python","title":"Griptape and Python","text":"<p>Griptape provides a simple, Pythonic interface to interact with these models, taking care of the complexities so we can focus on coding our applications.</p> <p>In the next stages, we will be going through:</p> <ul> <li> <p>Setting Up: Here, we will install and set up the basic tools we need: Visual Studio Code, Python, and create our directory structure. We'll also ensure that you have the right Python environment in place.</p> </li> <li> <p>OpenAI API Key: Before jumping into Griptape, we need to get our OpenAI API Key and set up our environment so it's ready.</p> </li> <li> <p>Griptape: We'll install the Griptape library and send our first message to the LLM!</p> </li> </ul> <p>Are you ready to get started? Let's move on to Setting up your environment!</p>"},{"location":"setup/01_setting_up_environment/","title":"Software","text":""},{"location":"setup/01_setting_up_environment/#overview","title":"Overview","text":"<p>Setting up our development environment correctly is vital for smooth and successful coding. In this stage, we'll go through all the necessary installations and configurations.</p>"},{"location":"setup/01_setting_up_environment/#installing-python","title":"Installing Python","text":"<p> Before getting started with Griptape, you'll need to install Python. We currently recommend a Python version greater than 3.9.</p>"},{"location":"setup/01_setting_up_environment/#windows-or-linux","title":"Windows or Linux","text":"<ol> <li>Head over to the official Python downloads page</li> <li>Click on the button that says \"Python 3.12.x\" (or the most recent 3.12 version) to download the installer</li> <li>Run the installer, and make sure to check the box that says \"Add Python to environment variables\" before you click \"Install\"</li> </ol>"},{"location":"setup/01_setting_up_environment/#macos","title":"macOS","text":"<p>If you have Homebrew installed:</p> <ol> <li>Open your terminal</li> <li>Run the <code>command brew install python@3.12</code></li> <li>After the installation is complete, run <code>brew link python@3.12</code></li> </ol> <p>Info</p> <p>If you don't have Homebrew, you can install Python from the official website as mentioned above.</p> <p>You did it!</p> <p>Congratulations, you've got Python!</p>"},{"location":"setup/01_setting_up_environment/#visual-studio-code","title":"Visual Studio Code","text":""},{"location":"setup/01_setting_up_environment/#installing","title":"Installing","text":"<p>Visual Studio Code (VS Code) provides the perfect environment for our Python coding.</p> <ol> <li>Go to the VS Code download page</li> <li>Download the version appropriate for your OS (Windows, Linux, or macOS)</li> <li>Run the installer and follow the prompts</li> </ol> <p>Success</p> <p>VS Code is now installed!</p>"},{"location":"setup/01_setting_up_environment/#creating-the-project-folder","title":"Creating the Project Folder","text":"<p>Before we dive into coding, let's create a dedicated space for our project. Having a clean organized directory structure makes coding and managing your projects much easier.</p> <p>First, you'll want to create a new folder on your computer where all the code for this project will live. You can create this folder anywhere you like. Here's how you can do it via your Terminal:</p> <pre><code>mkdir griptape-starter\ncd griptape-starter\n</code></pre> <p>This creates a new folder called \"griptape_intro\" and moves into it.</p> <p>Alternatively, feel free to open up Visual Studio Code and create a new folder:</p> <ol> <li>Choose File -&gt; Open Folder..</li> <li>Choose New Folder</li> <li>Enter the name of your new folder. Example: <code>griptape-starter</code></li> <li>Choose Create</li> <li>Double-click on the newly created folder to open it.</li> </ol>"},{"location":"setup/01_setting_up_environment/#python","title":"Python","text":""},{"location":"setup/01_setting_up_environment/#installing-vs-code-python-extension","title":"Installing VS Code Python Extension","text":"<p>The Python extension for Visual Studio Code provides rich support for the Python language, including features like IntelliSence, linting, debugging, code formatting, and more. It really makes life easier for Python developers.</p> <ol> <li>With VS Code open, go to the Extensions tab, or choose View --&gt; Extensions</li> <li>Search for <code>Python</code>, or go to [Python]((https://marketplace.visualstudio.com/items?itemName=ms-python.python){target=\"_blank\"} in your web browser.</li> <li>Choose <code>Install</code>.</li> <li>Open the command Palette (<code>Ctrl</code>+<code>Shift</code>+<code>P</code> on Windows/Linux, <code>Cmd</code>+<code>Shift</code>+<code>P</code> on macOS), or choose View --&gt; Command Palette..</li> <li>Type <code>Python</code> and you should see a list of specific commands for Python. This will confirm that the install was sucessful.</li> </ol> <p></p>"},{"location":"setup/01_setting_up_environment/#virtual-environments","title":"Virtual Environments","text":""},{"location":"setup/01_setting_up_environment/#using-vs-codes-python-environment-manager","title":"Using VS Code's Python Environment Manager","text":"<p>Python virtual environments are essential tools for keeping your projects organized and isolated. They allow each project to have its own set of dependencies, ensuring that different projects won't interfere with each other, which is vital when different projects require different versions of the same library. By using virtual environments, you can maintain a clean, conflict-free workspace for each project, making it easier to manage your code and troubleshoot any issues.</p> <p>Many developers use their terminal to manage their Python virtual environments. As this is a beginner level course, we'll use an Extension inside VS Code instead because it makes this a little bit easier.</p> <ol> <li>With VS Code open, go to the Extensions tab, or choose View --&gt; Extensions</li> <li>Search for <code>Python Environment Manager</code>, or go to Python Environment Manager in your web browser.</li> <li>Choose <code>Install</code>.</li> <li>Open the Command Palette (<code>Ctrl</code>+<code>Shift</code>+<code>P</code> on Windows/Linux, <code>Cmd</code>+<code>Shift</code>+<code>P</code> on macOS), or choose View --&gt; Command Palette..</li> <li> <p>Search for <code>Python: Create Environment</code> and you should see it come up at the top of the command list.    </p> </li> <li> <p>Hit return with that item selected and choose <code>.Venv: Creates a '.venv' virtual environment in the current workspace</code></p> </li> </ol> <p></p> <ol> <li>Then choose a python version.</li> </ol> <p></p> <p>Note: This will create the virtual environment for you within the current directory.</p> <ul> <li>This creates a new virtual environment in a folder called <code>.venv</code> and activates the environment for you.</li> </ul> <p>Now you've set up your Python environment for this project. This way, anything you install or change in Python won't affect other projects.</p>"},{"location":"setup/01_setting_up_environment/#confirm-its-working","title":"Confirm it's working","text":"<p>To be sure that your virtual environment is set up correctly, we'll check by opening a Terminal. If everything is set correctly, you'll see <code>.venv</code> in your terminal prompt.</p> <ol> <li>Open the terminal in VS Code by clicking on <code>Terminal -&gt; New Terminal</code></li> </ol> <p></p> <p>Note</p> <p>You should see <code>.venv</code> in your prompt. If you don't see it, please run through the previous documentation to try again, or check out the TroubleShooting section of this tutorial.</p>"},{"location":"setup/01_setting_up_environment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"setup/01_setting_up_environment/#execution-policy","title":"Execution Policy","text":"<p>On some Windows systems, you may get an error that says something similar to:</p> <p>Failure</p> <p>.venv\\Scripts\\Activate.ps1 cannot be loaded because running scripts is disabled on this system.</p> <p>This is due to an execution policy. Don't worry, it's pretty easy to resolve.</p> <ol> <li>With the Terminal open, execute the following command:</li> </ol> <pre><code>Set-ExecutionPolicy -Scope CurrentUser Unrestricted\n</code></pre> <ul> <li> <p>This will give the current user the ability to run scripts from within Visual Studio Code.</p> </li> <li> <p>Verify this worked by closing the Terminal and re-opening it. You should be able to execute scripts now without any errors.</p> </li> </ul> <p>Info</p> <p>You can learn more about Windows Execution Policies in the Set-ExecutionPolicy documentation.</p>"},{"location":"setup/01_setting_up_environment/#next-step","title":"Next Step","text":"<p>You now have Python and VS Code installed, and you've got a working virtual environment! In the next section, we'll set up your OpenAI API key so you can communicate with their large language model.</p>"},{"location":"setup/02_openai/","title":"OpenAI","text":""},{"location":"setup/02_openai/#overview","title":"Overview","text":""},{"location":"setup/02_openai/#openai","title":"OpenAI","text":""},{"location":"setup/02_openai/#obtaining-the-api-key","title":"Obtaining the API Key","text":"<p>In order to communicate with an LLM using Griptape, we'll need a key. To do this, we'll grab an API key from OpenAI.</p> <p>Tip</p> <p>Griptape can work with many large language models, but to keep things simple for now, we'll just focus on OpenAI's gpt model.</p> <ol> <li>Go to the OpenAI website and sign up for an account if you don't have one already.</li> <li> <p>After logging in, navigate to the API section of your dashboard.</p> <p></p> </li> <li> <p>Choose Create a new secret key in order to create a key for your use.</p> </li> <li> <p>Give your key a name. Example: <code>griptape</code></p> <p></p> </li> <li> <p>Choose Create secret key</p> </li> <li> <p>You will see a window with your new key highlighted. You will not be able to view this key again so it's very important to copy the key and save it somewhere safe.</p> <p></p> </li> <li> <p>Choose Done</p> </li> </ol> <p>Warning</p> <p>Remember, this API key is like your secret key to the city of LLMs. Don't share it with anyone!</p>"},{"location":"setup/02_openai/#installing-python-dotenv","title":"Installing python-dotenv","text":"<p>Understanding and using environment variables is a key aspect of programming. In order to use the API key we just received, we will need to be able to access it from with our python script. We'll use a package called python-dotenv to handle environment variables in our project.</p> <p>In the terminal, run the command <code>pip install python-dotenv</code> to install the package. </p> <p>Info</p> <p>You can learn more about pip and python-dotenv by visiting their PyPi page: https://pypi.org/project/python-dotenv/.</p> <p></p>"},{"location":"setup/02_openai/#creating-the-env-file-and-setting-the-openai-api-key","title":"Creating the .env File and Setting the OpenAI API Key","text":"<p>Now that we have our OpenAI API key, we need to make it available for our Python code to use. The best and safest way to do this is using a <code>.env</code> file, which allows us to define environment variables. We can then use the <code>load_dotenv</code> library to access any of those environment variables..</p> <ol> <li>In the root of your project folder (<code>griptape-starter</code>), create a new file and name it <code>.env</code>.</li> <li>Open the <code>.env</code> file and write <code>OPENAI_API_KEY=your_openai_api_key_here</code>, replacing <code>your_openai_api_key_here</code> with your actual OpenAI API key.</li> <li>Save the file.</li> </ol> .env<pre><code>OPENAI_API_KEY=your_openai_api_key_here \n</code></pre>"},{"location":"setup/02_openai/#your-first-app","title":"Your first app","text":""},{"location":"setup/02_openai/#creating-apppy","title":"Creating app.py","text":"<p>Now we're going to create our Python file and use the <code>python-dotenv</code> library to load the <code>OPENAI_API_KEY</code> environment variable. First things first, let's create a Python file where we will write our code.</p> <ol> <li>In your project directory (<code>griptape-starter</code>), create a new file called <code>app.py</code>. You can do this in VS Code by clicking <code>File -&gt; New File</code></li> <li>Save the file by choosing <code>File -&gt; Save As...</code></li> <li>Entering <code>app.py</code> as the filename.</li> </ol> <p>Success</p> <p>Nice, you've created your first Python file! </p>"},{"location":"setup/02_openai/#importing-the-library","title":"Importing the Library","text":"<p>Next, we're going to import the <code>load_dotenv</code> function from the <code>dotenv</code> library we installed earlier.</p> <p>Enter the following code in app.py.</p> app.py<pre><code>from dotenv import load_dotenv\n</code></pre>"},{"location":"setup/02_openai/#loading-the-variables","title":"Loading the variables","text":"<p>Now we'll use the <code>load_dotenv</code> function. Update your <code>app.py</code> with the highlighted line: app.py<pre><code>from dotenv import load_dotenv\nload_dotenv() # Load the environment variables\n</code></pre></p> <p>If you save and run your script, you shouldn't get any errors in your Terminal. If you received no errors.. you win! You've loaded your environment variable that was specified in the <code>.env</code> file!</p>"},{"location":"setup/02_openai/#next-steps","title":"Next Steps","text":"<p>Congratulations! Your environment is set, and your application is ready. You're ready to start using Griptape! In the next section, we'll install Griptape and send our first message to the LLM. I wonder what it'll say...</p>"},{"location":"setup/03_griptape/","title":"Griptape","text":""},{"location":"setup/03_griptape/#overview","title":"Overview","text":"<p>Now that you've got your environment all set up, it's time to actually start moving. In this stage, we'll put together a basic Griptape application and see it in action. </p>"},{"location":"setup/03_griptape/#our-application","title":"Our Application","text":"<p>We are going to build a very simple application. It's going to simply take in a prompt, and return the result of that prompt. For example, we will be able to ask: \"What's a good place to visit in New Zealand?\" and it will give us an answer like \"Abel Tasman\" or \"All of it\".</p>"},{"location":"setup/03_griptape/#griptape","title":"Griptape","text":""},{"location":"setup/03_griptape/#agents","title":"Agents","text":"<p>There are multiple ways communicate with LLMs via Griptape, but the one we'll use in this example is an Agent. You can learn more about Agents in documentation, but here's a simple way to understand them:</p> <p>Abstract</p> <p>Agents can do one task.</p> <p>You give the Agent a prompt, it thinks for a bit, figures things out, and then returns a result. While that sounds relatively simple, it's actually quite cool. You can give the agent tools (WebScraper, Calculator, EmailClient, to name a few), you can give it rules about how to behave, and more. Agents can actually do quite a lot - but they're still one of the more simple ways of interacting with Griptape, which is why we'll use them to start with in this course.</p> <p>Speaking of interacting with Griptape... we need to install it!</p>"},{"location":"setup/03_griptape/#installing-griptape","title":"Installing Griptape","text":"<p>Just like we installed the <code>python_dotenv</code> library, we need to do the same with Griptape. </p> <p>Navigate to Terminal in VSCode and use <code>pip</code> to install <code>griptape</code>:</p> <pre><code>pip install griptape\n</code></pre> <p>Info</p> <p>This will take a minute to install. Another chance to enjoy a !</p>"},{"location":"setup/03_griptape/#import-griptape","title":"Import Griptape","text":"<p>Now comes the moment you've all been waiting for! Actually, it's the moment before the moment. In this moment, we're going to import the Agent from the Griptape library. The moment after that is probably the one you're really waiting for. But we have to do this moment first. Live in the now.</p> <p>Modify your <code>app.py</code> to import the agent</p> app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nload_dotenv() # Load the environment variables\n</code></pre> <p>As you can see, we're importing the Agent from <code>griptape.structures</code>. There are other structures we can work with, but again.. this is just setting up your environment. We'll talk about those in another course.</p>"},{"location":"setup/03_griptape/#the-fun-part","title":"The fun part","text":""},{"location":"setup/03_griptape/#create-the-agent","title":"Create the Agent","text":"<p>To create the Agent, we'll instantiate the class. </p> app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nload_dotenv() # Load the environment variables\n# Create the Agent\nagent = Agent()\n</code></pre>"},{"location":"setup/03_griptape/#run-the-agent","title":"Run the Agent","text":"<p>Now you get to tell the Agent what to do. Use the Agent's <code>run</code> method to execute a prompt.</p> app.py<pre><code>from dotenv import load_dotenv\nfrom griptape.structures import Agent\nload_dotenv() # Load the environment variables\n# Create the Agent\nagent = Agent()\n# Run the agent\nagent.run(\"Give me a haiku about skateboarding\")\n</code></pre>"},{"location":"setup/03_griptape/#test-the-agent","title":"Test the Agent","text":"<p>Let's see if our application works.</p> <ol> <li>Save your file.</li> <li>Use the Run icon in the upper right corner of VS Code, or open your terminal and type <code>python app.py</code>.</li> </ol> <p>If everything has been set up correctly, you should see the result of the <code>agent.run()</code> command printed in the terminal. The exact output will depend on the current configuration and performance of the OpenAI API, but it should be a haiku about skateboarding.</p> <pre><code>[07/21/23 05:39:22] INFO     Task 801254fc5df64cda8930917a8afbc5bc                                              Input: Create me a haiku about skateboarding                                       [07/21/23 05:39:24] INFO     Task 801254fc5df64cda8930917a8afbc5bc                                              Output: Skateboard glides swiftly,                                                 Tricks and flips in the air, high,                                                 Thrilling ride, pure bliss.      </code></pre> <p>Success<p>Congrats! You've taken the first push and created your first Python script that works with a large language model!</p> </p>"},{"location":"setup/03_griptape/#next-steps","title":"Next Steps","text":"<p>You've successfully set up your development environment, installed the necessary packages, obtained your OpenAI API key, and written and run a simple Griptape application. You've done a great job, so don't forget to celebrate your progress. </p> <p>Now that you've successfully completed the course, please check out these Helpful Resources to learn more about Griptape!</p>"},{"location":"setup/04_helpful_resources/","title":"Resources","text":"<p>Congrats on reaching this stage! You've set up your environment, written your first Griptape application, and are ready to embark on your coding journey. However, learning is an ongoing process, and the more resources you have at your disposal, the more empowered you'll be to tackle whatever comes your way.</p> <p>Here's a list of resources to help you gain momentum and build your knowledge:</p>"},{"location":"setup/04_helpful_resources/#griptape","title":"Griptape","text":"<ul> <li> <p>Griptape Documentation: Learn everything you need to know about Griptape from its official documentation. You'll find detailed explanations, ../assets/examples, and tips here. Visit the Griptape Documentation.</p> </li> <li> <p>Griptape GitHub: Check out the official Griptape repository on GitHub. You can look at the source code, report issues, and even contribute. Here's the Griptape GitHub link.</p> </li> <li> <p>Griptape Discord Community: Join the Griptape community on Discord. Here, you can connect with other users, ask questions, share your projects, and keep up-to-date with Griptape developments. Here's the Griptape Discord link.</p> </li> </ul>"},{"location":"setup/04_helpful_resources/#tools","title":"Tools","text":"<ul> <li> <p>Visual Studio Code: Brush up on your VS Code knowledge. Check out the VS Code Documentation to get familiar with its features and functionalities.</p> </li> <li> <p>Python: Python's official documentation is a comprehensive resource that covers all aspects of the language. Visit the Python Documentation.</p> </li> <li> <p>Python-dotenv: Get more information about how to use the python-dotenv package from its Python-dotenv PyPI page.</p> </li> <li> <p>OpenAI API: Understand how OpenAI's API works. The OpenAI API Documentation is a great place to start.</p> </li> </ul> <p>These resources will give you a deeper understanding and greater control as you navigate the landscape of programming with Python and Griptape. Happy coding!</p>"}]}